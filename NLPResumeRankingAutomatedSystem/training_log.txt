2025-05-23 22:53:04,279 - INFO - B\u1eaft \u0111\u1ea7u hu\u1ea5n luy\u1ec7n mô hình LSTM v\u1edbi early stopping...
2025-05-23 22:53:07,669 - INFO - Epoch [1/200], Train Loss: 1979.6011, Val Loss: 1517.7155, Time: 3.22s, Batches: 440
2025-05-23 22:53:10,716 - INFO - Epoch [2/200], Train Loss: 1346.8107, Val Loss: 1160.6173, Time: 2.87s, Batches: 440
2025-05-23 22:53:14,068 - INFO - Epoch [3/200], Train Loss: 1045.4560, Val Loss: 904.4245, Time: 3.19s, Batches: 440
2025-05-23 22:53:17,366 - INFO - Epoch [4/200], Train Loss: 815.1760, Val Loss: 701.7680, Time: 3.12s, Batches: 440
2025-05-23 22:53:20,588 - INFO - Epoch [5/200], Train Loss: 631.0635, Val Loss: 539.4304, Time: 3.06s, Batches: 440
2025-05-23 22:53:24,066 - INFO - Epoch [6/200], Train Loss: 483.5591, Val Loss: 410.3797, Time: 3.28s, Batches: 440
2025-05-23 22:53:26,933 - INFO - Epoch [7/200], Train Loss: 367.0803, Val Loss: 309.7325, Time: 2.71s, Batches: 440
2025-05-23 22:53:29,849 - INFO - Epoch [8/200], Train Loss: 277.1541, Val Loss: 233.6443, Time: 2.77s, Batches: 440
2025-05-23 22:53:32,832 - INFO - Epoch [9/200], Train Loss: 210.1391, Val Loss: 178.5053, Time: 2.81s, Batches: 440
2025-05-23 22:53:36,116 - INFO - Epoch [10/200], Train Loss: 162.3253, Val Loss: 140.6679, Time: 3.10s, Batches: 440
2025-05-23 22:53:39,158 - INFO - Epoch [11/200], Train Loss: 130.4374, Val Loss: 116.7137, Time: 2.89s, Batches: 440
2025-05-23 22:53:41,915 - INFO - Epoch [12/200], Train Loss: 110.7810, Val Loss: 103.0846, Time: 2.62s, Batches: 440
2025-05-23 22:53:44,782 - INFO - Epoch [13/200], Train Loss: 99.9937, Val Loss: 96.5017, Time: 2.72s, Batches: 440
2025-05-23 22:53:47,496 - INFO - Epoch [14/200], Train Loss: 94.9039, Val Loss: 93.8609, Time: 2.53s, Batches: 440
2025-05-23 22:53:50,265 - INFO - Epoch [15/200], Train Loss: 92.8819, Val Loss: 93.1388, Time: 2.64s, Batches: 440
2025-05-23 22:53:53,266 - INFO - Epoch [16/200], Train Loss: 92.2510, Val Loss: 93.0485, Time: 2.83s, Batches: 440
2025-05-23 22:53:55,998 - INFO - Epoch [17/200], Train Loss: 92.1000, Val Loss: 93.0447, Time: 2.60s, Batches: 440
2025-05-23 22:53:58,836 - INFO - Epoch [18/200], Train Loss: 91.9890, Val Loss: 92.8495, Time: 2.69s, Batches: 440
2025-05-23 22:54:01,772 - INFO - Epoch [19/200], Train Loss: 78.4939, Val Loss: 60.3498, Time: 2.77s, Batches: 440
2025-05-23 22:54:04,834 - INFO - Epoch [20/200], Train Loss: 53.1469, Val Loss: 46.9648, Time: 2.91s, Batches: 440
2025-05-23 22:54:07,658 - INFO - Epoch [21/200], Train Loss: 42.8640, Val Loss: 39.3888, Time: 2.66s, Batches: 440
2025-05-23 22:54:10,631 - INFO - Epoch [22/200], Train Loss: 36.5750, Val Loss: 33.8362, Time: 2.80s, Batches: 440
2025-05-23 22:54:13,881 - INFO - Epoch [23/200], Train Loss: 31.5874, Val Loss: 29.0611, Time: 3.04s, Batches: 440
2025-05-23 22:54:17,125 - INFO - Epoch [24/200], Train Loss: 27.7857, Val Loss: 24.8563, Time: 3.07s, Batches: 440
2025-05-23 22:54:20,281 - INFO - Epoch [25/200], Train Loss: 23.8864, Val Loss: 21.4640, Time: 3.00s, Batches: 440
2025-05-23 22:54:23,323 - INFO - Epoch [26/200], Train Loss: 20.6646, Val Loss: 17.7715, Time: 2.87s, Batches: 440
2025-05-23 22:54:26,448 - INFO - Epoch [27/200], Train Loss: 17.4701, Val Loss: 14.9238, Time: 2.95s, Batches: 440
2025-05-23 22:54:30,081 - INFO - Epoch [28/200], Train Loss: 14.8673, Val Loss: 11.7776, Time: 3.45s, Batches: 440
2025-05-23 22:54:32,831 - INFO - Epoch [29/200], Train Loss: 12.2049, Val Loss: 9.3339, Time: 2.61s, Batches: 440
2025-05-23 22:54:35,515 - INFO - Epoch [30/200], Train Loss: 10.2674, Val Loss: 7.5404, Time: 2.53s, Batches: 440
2025-05-23 22:54:38,214 - INFO - Epoch [31/200], Train Loss: 8.6872, Val Loss: 6.5783, Time: 2.56s, Batches: 440
2025-05-23 22:54:40,900 - INFO - Epoch [32/200], Train Loss: 7.3241, Val Loss: 4.7740, Time: 2.52s, Batches: 440
2025-05-23 22:54:43,781 - INFO - Epoch [33/200], Train Loss: 6.3317, Val Loss: 3.8859, Time: 2.74s, Batches: 440
2025-05-23 22:54:46,604 - INFO - Epoch [34/200], Train Loss: 5.3810, Val Loss: 2.9841, Time: 2.65s, Batches: 440
2025-05-23 22:54:49,401 - INFO - Epoch [35/200], Train Loss: 4.7315, Val Loss: 2.5171, Time: 2.62s, Batches: 440
2025-05-23 22:54:52,006 - INFO - Epoch [36/200], Train Loss: 4.0544, Val Loss: 2.2362, Time: 2.47s, Batches: 440
2025-05-23 22:54:54,790 - INFO - Epoch [37/200], Train Loss: 3.4143, Val Loss: 1.5273, Time: 2.63s, Batches: 440
2025-05-23 22:54:57,630 - INFO - Epoch [38/200], Train Loss: 2.9843, Val Loss: 1.2188, Time: 2.66s, Batches: 440
2025-05-23 22:55:00,533 - INFO - Epoch [39/200], Train Loss: 2.6166, Val Loss: 0.9966, Time: 2.75s, Batches: 440
2025-05-23 22:55:03,267 - INFO - Epoch [40/200], Train Loss: 2.3636, Val Loss: 0.8697, Time: 2.61s, Batches: 440
2025-05-23 22:55:06,030 - INFO - Epoch [41/200], Train Loss: 2.1333, Val Loss: 0.7603, Time: 2.62s, Batches: 440
2025-05-23 22:55:09,147 - INFO - Epoch [42/200], Train Loss: 1.9659, Val Loss: 0.6698, Time: 2.96s, Batches: 440
2025-05-23 22:55:12,064 - INFO - Epoch [43/200], Train Loss: 1.8400, Val Loss: 0.6297, Time: 2.75s, Batches: 440
2025-05-23 22:55:14,925 - INFO - Epoch [44/200], Train Loss: 1.7522, Val Loss: 0.5140, Time: 2.68s, Batches: 440
2025-05-23 22:55:18,156 - INFO - Epoch [45/200], Train Loss: 1.6287, Val Loss: 0.5513, Time: 3.02s, Batches: 440
2025-05-23 22:55:21,263 - INFO - Epoch [46/200], Train Loss: 1.5004, Val Loss: 0.5299, Time: 2.92s, Batches: 440
2025-05-23 22:55:24,401 - INFO - Epoch [47/200], Train Loss: 1.4749, Val Loss: 0.4085, Time: 2.96s, Batches: 440
2025-05-23 22:55:27,497 - INFO - Epoch [48/200], Train Loss: 1.4004, Val Loss: 0.4124, Time: 2.93s, Batches: 440
2025-05-23 22:55:30,558 - INFO - Epoch [49/200], Train Loss: 1.3367, Val Loss: 0.3823, Time: 2.90s, Batches: 440
2025-05-23 22:55:34,021 - INFO - Epoch [50/200], Train Loss: 1.3338, Val Loss: 0.3678, Time: 3.28s, Batches: 440
2025-05-23 22:55:37,214 - INFO - Epoch [51/200], Train Loss: 1.2343, Val Loss: 0.3937, Time: 3.05s, Batches: 440
2025-05-23 22:55:40,030 - INFO - Epoch [52/200], Train Loss: 1.2143, Val Loss: 0.3705, Time: 2.68s, Batches: 440
2025-05-23 22:55:42,712 - INFO - Epoch [53/200], Train Loss: 1.1754, Val Loss: 0.3642, Time: 2.52s, Batches: 440
2025-05-23 22:55:45,580 - INFO - Epoch [54/200], Train Loss: 1.1420, Val Loss: 0.3680, Time: 2.72s, Batches: 440
2025-05-23 22:55:48,631 - INFO - Epoch [55/200], Train Loss: 1.1003, Val Loss: 0.3070, Time: 2.87s, Batches: 440
2025-05-23 22:55:51,473 - INFO - Epoch [56/200], Train Loss: 1.0867, Val Loss: 0.2965, Time: 2.69s, Batches: 440
2025-05-23 22:55:54,195 - INFO - Epoch [57/200], Train Loss: 1.0485, Val Loss: 0.3398, Time: 2.58s, Batches: 440
2025-05-23 22:55:56,905 - INFO - Epoch [58/200], Train Loss: 0.9849, Val Loss: 0.2713, Time: 2.55s, Batches: 440
2025-05-23 22:55:59,584 - INFO - Epoch [59/200], Train Loss: 0.9481, Val Loss: 0.2629, Time: 2.53s, Batches: 440
2025-05-23 22:56:02,312 - INFO - Epoch [60/200], Train Loss: 0.9396, Val Loss: 0.3070, Time: 2.56s, Batches: 440
2025-05-23 22:56:05,295 - INFO - Epoch [61/200], Train Loss: 0.9226, Val Loss: 0.2515, Time: 2.84s, Batches: 440
2025-05-23 22:56:08,265 - INFO - Epoch [62/200], Train Loss: 0.9044, Val Loss: 0.3999, Time: 2.82s, Batches: 440
2025-05-23 22:56:10,996 - INFO - Epoch [63/200], Train Loss: 0.8807, Val Loss: 0.2448, Time: 2.60s, Batches: 440
2025-05-23 22:56:14,099 - INFO - Epoch [64/200], Train Loss: 0.8703, Val Loss: 0.3042, Time: 2.95s, Batches: 440
2025-05-23 22:56:17,135 - INFO - Epoch [65/200], Train Loss: 0.8235, Val Loss: 0.2568, Time: 2.86s, Batches: 440
2025-05-23 22:56:20,095 - INFO - Epoch [66/200], Train Loss: 0.8137, Val Loss: 0.2524, Time: 2.83s, Batches: 440
2025-05-23 22:56:23,237 - INFO - Epoch [67/200], Train Loss: 0.8204, Val Loss: 0.2359, Time: 2.97s, Batches: 440
2025-05-23 22:56:26,463 - INFO - Epoch [68/200], Train Loss: 0.7890, Val Loss: 0.2188, Time: 3.05s, Batches: 440
2025-05-23 22:56:29,766 - INFO - Epoch [69/200], Train Loss: 0.7694, Val Loss: 0.2283, Time: 3.14s, Batches: 440
2025-05-23 22:56:32,951 - INFO - Epoch [70/200], Train Loss: 0.7484, Val Loss: 0.2017, Time: 3.03s, Batches: 440
2025-05-23 22:56:36,139 - INFO - Epoch [71/200], Train Loss: 0.7471, Val Loss: 0.2095, Time: 3.03s, Batches: 440
2025-05-23 22:56:39,602 - INFO - Epoch [72/200], Train Loss: 0.7365, Val Loss: 0.2318, Time: 3.29s, Batches: 440
2025-05-23 22:56:42,985 - INFO - Epoch [73/200], Train Loss: 0.7158, Val Loss: 0.2257, Time: 3.24s, Batches: 440
2025-05-23 22:56:45,812 - INFO - Epoch [74/200], Train Loss: 0.7322, Val Loss: 0.2232, Time: 2.69s, Batches: 440
2025-05-23 22:56:48,640 - INFO - Epoch [75/200], Train Loss: 0.6912, Val Loss: 0.1925, Time: 2.69s, Batches: 440
2025-05-23 22:56:51,361 - INFO - Epoch [76/200], Train Loss: 0.6863, Val Loss: 0.2550, Time: 2.57s, Batches: 440
2025-05-23 22:56:54,407 - INFO - Epoch [77/200], Train Loss: 0.6836, Val Loss: 0.3616, Time: 2.90s, Batches: 440
2025-05-23 22:56:57,311 - INFO - Epoch [78/200], Train Loss: 0.6836, Val Loss: 0.1770, Time: 2.77s, Batches: 440
2025-05-23 22:57:00,194 - INFO - Epoch [79/200], Train Loss: 0.6594, Val Loss: 0.2177, Time: 2.68s, Batches: 440
2025-05-23 22:57:02,965 - INFO - Epoch [80/200], Train Loss: 0.6415, Val Loss: 0.1852, Time: 2.63s, Batches: 440
2025-05-23 22:57:05,711 - INFO - Epoch [81/200], Train Loss: 0.6337, Val Loss: 0.3503, Time: 2.62s, Batches: 440
2025-05-23 22:57:08,752 - INFO - Epoch [82/200], Train Loss: 0.6161, Val Loss: 0.2563, Time: 2.89s, Batches: 440
2025-05-23 22:57:12,011 - INFO - Epoch [83/200], Train Loss: 0.6288, Val Loss: 0.2392, Time: 3.11s, Batches: 440
2025-05-23 22:57:15,327 - INFO - Epoch [84/200], Train Loss: 0.6119, Val Loss: 0.1949, Time: 3.12s, Batches: 440
2025-05-23 22:57:18,294 - INFO - Epoch [85/200], Train Loss: 0.6075, Val Loss: 0.2624, Time: 2.82s, Batches: 440
2025-05-23 22:57:21,535 - INFO - Epoch [86/200], Train Loss: 0.6055, Val Loss: 0.1653, Time: 3.08s, Batches: 440
2025-05-23 22:57:24,705 - INFO - Epoch [87/200], Train Loss: 0.5923, Val Loss: 0.1757, Time: 2.96s, Batches: 440
2025-05-23 22:57:27,868 - INFO - Epoch [88/200], Train Loss: 0.5715, Val Loss: 0.1827, Time: 2.97s, Batches: 440
2025-05-23 22:57:31,258 - INFO - Epoch [89/200], Train Loss: 0.5768, Val Loss: 0.1733, Time: 3.22s, Batches: 440
2025-05-23 22:57:34,710 - INFO - Epoch [90/200], Train Loss: 0.5890, Val Loss: 0.2244, Time: 3.26s, Batches: 440
2025-05-23 22:57:38,160 - INFO - Epoch [91/200], Train Loss: 0.5493, Val Loss: 0.1954, Time: 3.27s, Batches: 440
2025-05-23 22:57:41,261 - INFO - Epoch [92/200], Train Loss: 0.5478, Val Loss: 0.2314, Time: 2.90s, Batches: 440
2025-05-23 22:57:44,700 - INFO - Epoch [93/200], Train Loss: 0.5507, Val Loss: 0.1661, Time: 3.25s, Batches: 440
2025-05-23 22:57:48,402 - INFO - Epoch [94/200], Train Loss: 0.5324, Val Loss: 0.3442, Time: 3.52s, Batches: 440
2025-05-23 22:57:51,594 - INFO - Epoch [95/200], Train Loss: 0.5526, Val Loss: 0.3776, Time: 3.04s, Batches: 440
2025-05-23 22:57:54,892 - INFO - Epoch [96/200], Train Loss: 0.5366, Val Loss: 0.1723, Time: 3.14s, Batches: 440
2025-05-23 22:59:03,171 - INFO - Optimized LSTM MSE: 0.1713, R2: 0.9981
2025-05-23 22:59:19,049 - INFO - B\u1eaft \u0111\u1ea7u hu\u1ea5n luy\u1ec7n mô hình LSTM v\u1edbi early stopping...
2025-05-23 22:59:20,564 - INFO - Epoch [1/200], Train Loss: 2389.9174, Val Loss: 2291.7254, Time: 1.44s, Batches: 110
2025-05-23 22:59:21,747 - INFO - Epoch [2/200], Train Loss: 2105.7187, Val Loss: 1860.8527, Time: 1.10s, Batches: 110
2025-05-23 22:59:22,728 - INFO - Epoch [3/200], Train Loss: 1754.3706, Val Loss: 1625.8005, Time: 0.89s, Batches: 110
2025-05-23 22:59:23,745 - INFO - Epoch [4/200], Train Loss: 1577.0696, Val Loss: 1489.3282, Time: 0.95s, Batches: 110
2025-05-23 22:59:24,691 - INFO - Epoch [5/200], Train Loss: 1457.0158, Val Loss: 1383.7430, Time: 0.85s, Batches: 110
2025-05-23 22:59:25,626 - INFO - Epoch [6/200], Train Loss: 1358.5006, Val Loss: 1293.1026, Time: 0.87s, Batches: 110
2025-05-23 22:59:26,592 - INFO - Epoch [7/200], Train Loss: 1271.7381, Val Loss: 1211.7128, Time: 0.89s, Batches: 110
2025-05-23 22:59:27,490 - INFO - Epoch [8/200], Train Loss: 1192.9849, Val Loss: 1137.0966, Time: 0.82s, Batches: 110
2025-05-23 22:59:28,460 - INFO - Epoch [9/200], Train Loss: 1120.2288, Val Loss: 1067.7256, Time: 0.88s, Batches: 110
2025-05-23 22:59:29,328 - INFO - Epoch [10/200], Train Loss: 1052.4903, Val Loss: 1002.9447, Time: 0.79s, Batches: 110
2025-05-23 22:59:30,187 - INFO - Epoch [11/200], Train Loss: 988.9280, Val Loss: 942.1066, Time: 0.79s, Batches: 110
2025-05-23 22:59:31,044 - INFO - Epoch [12/200], Train Loss: 929.1607, Val Loss: 884.7697, Time: 0.78s, Batches: 110
2025-05-23 22:59:32,038 - INFO - Epoch [13/200], Train Loss: 872.7084, Val Loss: 830.6457, Time: 0.90s, Batches: 110
2025-05-23 22:59:33,061 - INFO - Epoch [14/200], Train Loss: 819.3673, Val Loss: 779.4912, Time: 0.94s, Batches: 110
2025-05-23 22:59:34,107 - INFO - Epoch [15/200], Train Loss: 769.0133, Val Loss: 731.1610, Time: 0.96s, Batches: 110
2025-05-23 22:59:35,043 - INFO - Epoch [16/200], Train Loss: 721.2965, Val Loss: 685.4142, Time: 0.87s, Batches: 110
2025-05-23 22:59:35,991 - INFO - Epoch [17/200], Train Loss: 676.1502, Val Loss: 642.1459, Time: 0.87s, Batches: 110
2025-05-23 22:59:36,920 - INFO - Epoch [18/200], Train Loss: 633.4444, Val Loss: 601.2372, Time: 0.86s, Batches: 110
2025-05-23 22:59:37,922 - INFO - Epoch [19/200], Train Loss: 593.0692, Val Loss: 562.6057, Time: 0.93s, Batches: 110
2025-05-23 22:59:38,971 - INFO - Epoch [20/200], Train Loss: 554.8848, Val Loss: 526.0788, Time: 0.97s, Batches: 110
2025-05-23 22:59:40,026 - INFO - Epoch [21/200], Train Loss: 518.8554, Val Loss: 491.6661, Time: 0.99s, Batches: 110
2025-05-23 22:59:41,044 - INFO - Epoch [22/200], Train Loss: 484.8128, Val Loss: 459.2179, Time: 0.93s, Batches: 110
2025-05-23 22:59:41,989 - INFO - Epoch [23/200], Train Loss: 452.7316, Val Loss: 428.6598, Time: 0.87s, Batches: 110
2025-05-23 22:59:42,974 - INFO - Epoch [24/200], Train Loss: 422.5339, Val Loss: 399.9418, Time: 0.90s, Batches: 110
2025-05-23 22:59:43,988 - INFO - Epoch [25/200], Train Loss: 394.1628, Val Loss: 372.9978, Time: 0.93s, Batches: 110
2025-05-23 22:59:44,939 - INFO - Epoch [26/200], Train Loss: 367.4784, Val Loss: 347.7275, Time: 0.88s, Batches: 110
2025-05-23 22:59:45,865 - INFO - Epoch [27/200], Train Loss: 342.5160, Val Loss: 324.0903, Time: 0.85s, Batches: 110
2025-05-23 22:59:46,822 - INFO - Epoch [28/200], Train Loss: 319.1787, Val Loss: 302.0557, Time: 0.88s, Batches: 110
2025-05-23 22:59:47,795 - INFO - Epoch [29/200], Train Loss: 297.3812, Val Loss: 281.5098, Time: 0.89s, Batches: 110
2025-05-23 22:59:48,825 - INFO - Epoch [30/200], Train Loss: 277.0461, Val Loss: 262.4122, Time: 0.97s, Batches: 110
2025-05-23 22:59:49,814 - INFO - Epoch [31/200], Train Loss: 258.1815, Val Loss: 244.7736, Time: 0.92s, Batches: 110
2025-05-23 22:59:50,745 - INFO - Epoch [32/200], Train Loss: 240.7107, Val Loss: 228.4540, Time: 0.86s, Batches: 110
2025-05-23 22:59:51,747 - INFO - Epoch [33/200], Train Loss: 224.5654, Val Loss: 213.3938, Time: 0.93s, Batches: 110
2025-05-23 22:59:52,693 - INFO - Epoch [34/200], Train Loss: 209.6903, Val Loss: 199.5687, Time: 0.88s, Batches: 110
2025-05-23 22:59:53,743 - INFO - Epoch [35/200], Train Loss: 196.0275, Val Loss: 186.9597, Time: 0.99s, Batches: 110
2025-05-23 22:59:54,731 - INFO - Epoch [36/200], Train Loss: 183.5511, Val Loss: 175.4789, Time: 0.90s, Batches: 110
2025-05-23 22:59:55,708 - INFO - Epoch [37/200], Train Loss: 172.1498, Val Loss: 165.0418, Time: 0.90s, Batches: 110
2025-05-23 22:59:56,689 - INFO - Epoch [38/200], Train Loss: 161.8075, Val Loss: 155.6513, Time: 0.92s, Batches: 110
2025-05-23 22:59:57,626 - INFO - Epoch [39/200], Train Loss: 152.4573, Val Loss: 147.1402, Time: 0.87s, Batches: 110
2025-05-23 22:59:58,750 - INFO - Epoch [40/200], Train Loss: 144.0609, Val Loss: 139.5635, Time: 1.05s, Batches: 110
2025-05-23 22:59:59,722 - INFO - Epoch [41/200], Train Loss: 136.5412, Val Loss: 132.8714, Time: 0.90s, Batches: 110
2025-05-23 23:00:00,801 - INFO - Epoch [42/200], Train Loss: 129.8543, Val Loss: 126.9305, Time: 0.97s, Batches: 110
2025-05-23 23:00:01,801 - INFO - Epoch [43/200], Train Loss: 123.9475, Val Loss: 121.7041, Time: 0.91s, Batches: 110
2025-05-23 23:00:02,836 - INFO - Epoch [44/200], Train Loss: 118.7307, Val Loss: 117.1959, Time: 0.96s, Batches: 110
2025-05-23 23:00:03,809 - INFO - Epoch [45/200], Train Loss: 114.2065, Val Loss: 113.2746, Time: 0.90s, Batches: 110
2025-05-23 23:00:04,724 - INFO - Epoch [46/200], Train Loss: 110.2868, Val Loss: 109.9192, Time: 0.85s, Batches: 110
2025-05-23 23:00:05,548 - INFO - Epoch [47/200], Train Loss: 106.9284, Val Loss: 107.1111, Time: 0.76s, Batches: 110
2025-05-23 23:00:06,375 - INFO - Epoch [48/200], Train Loss: 104.0696, Val Loss: 104.7313, Time: 0.76s, Batches: 110
2025-05-23 23:00:07,224 - INFO - Epoch [49/200], Train Loss: 101.6446, Val Loss: 102.7857, Time: 0.77s, Batches: 110
2025-05-23 23:00:08,127 - INFO - Epoch [50/200], Train Loss: 99.6312, Val Loss: 101.1811, Time: 0.81s, Batches: 110
2025-05-23 23:00:09,117 - INFO - Epoch [51/200], Train Loss: 97.9788, Val Loss: 99.8946, Time: 0.90s, Batches: 110
2025-05-23 23:00:10,042 - INFO - Epoch [52/200], Train Loss: 96.6107, Val Loss: 98.8653, Time: 0.84s, Batches: 110
2025-05-23 23:00:10,977 - INFO - Epoch [53/200], Train Loss: 95.5269, Val Loss: 98.0658, Time: 0.88s, Batches: 110
2025-05-23 23:00:11,903 - INFO - Epoch [54/200], Train Loss: 94.6581, Val Loss: 97.4697, Time: 0.83s, Batches: 110
2025-05-23 23:00:12,814 - INFO - Epoch [55/200], Train Loss: 93.9803, Val Loss: 97.0221, Time: 0.83s, Batches: 110
2025-05-23 23:00:13,790 - INFO - Epoch [56/200], Train Loss: 93.4648, Val Loss: 96.7018, Time: 0.92s, Batches: 110
2025-05-23 23:00:14,624 - INFO - Epoch [57/200], Train Loss: 93.0586, Val Loss: 96.4736, Time: 0.77s, Batches: 110
2025-05-23 23:00:15,491 - INFO - Epoch [58/200], Train Loss: 92.7722, Val Loss: 96.3272, Time: 0.78s, Batches: 110
2025-05-23 23:00:16,324 - INFO - Epoch [59/200], Train Loss: 92.5479, Val Loss: 96.2307, Time: 0.77s, Batches: 110
2025-05-23 23:00:17,191 - INFO - Epoch [60/200], Train Loss: 92.3994, Val Loss: 96.1774, Time: 0.82s, Batches: 110
2025-05-23 23:00:18,064 - INFO - Epoch [61/200], Train Loss: 92.2802, Val Loss: 96.1527, Time: 0.80s, Batches: 110
2025-05-23 23:00:18,964 - INFO - Epoch [62/200], Train Loss: 92.2078, Val Loss: 96.1455, Time: 0.81s, Batches: 110
2025-05-23 23:00:19,847 - INFO - Epoch [63/200], Train Loss: 92.1591, Val Loss: 96.1483, Time: 0.81s, Batches: 110
2025-05-23 23:00:20,678 - INFO - Epoch [64/200], Train Loss: 92.1194, Val Loss: 96.1554, Time: 0.78s, Batches: 110
2025-05-23 23:00:21,507 - INFO - Epoch [65/200], Train Loss: 92.0899, Val Loss: 96.1602, Time: 0.78s, Batches: 110
2025-05-23 23:00:22,340 - INFO - Epoch [66/200], Train Loss: 92.0735, Val Loss: 96.1667, Time: 0.78s, Batches: 110
2025-05-23 23:00:23,227 - INFO - Epoch [67/200], Train Loss: 92.0486, Val Loss: 96.1673, Time: 0.83s, Batches: 110
2025-05-23 23:00:24,093 - INFO - Epoch [68/200], Train Loss: 92.0325, Val Loss: 96.1585, Time: 0.81s, Batches: 110
2025-05-23 23:00:24,924 - INFO - Epoch [69/200], Train Loss: 92.0142, Val Loss: 96.1411, Time: 0.78s, Batches: 110
2025-05-23 23:00:25,807 - INFO - Epoch [70/200], Train Loss: 91.9699, Val Loss: 96.0972, Time: 0.82s, Batches: 110
2025-05-23 23:00:26,653 - INFO - Epoch [71/200], Train Loss: 91.9123, Val Loss: 95.9752, Time: 0.77s, Batches: 110
2025-05-23 23:00:27,457 - INFO - Epoch [72/200], Train Loss: 91.6958, Val Loss: 95.2107, Time: 0.74s, Batches: 110
2025-05-23 23:00:28,370 - INFO - Epoch [73/200], Train Loss: 85.8899, Val Loss: 74.0505, Time: 0.85s, Batches: 110
2025-05-23 23:00:29,324 - INFO - Epoch [74/200], Train Loss: 68.1842, Val Loss: 62.6505, Time: 0.88s, Batches: 110
2025-05-23 23:00:30,207 - INFO - Epoch [75/200], Train Loss: 59.8855, Val Loss: 57.0920, Time: 0.83s, Batches: 110
2025-05-23 23:00:31,107 - INFO - Epoch [76/200], Train Loss: 54.4528, Val Loss: 52.0632, Time: 0.85s, Batches: 110
2025-05-23 23:00:32,015 - INFO - Epoch [77/200], Train Loss: 50.0708, Val Loss: 48.4866, Time: 0.83s, Batches: 110
2025-05-23 23:00:32,940 - INFO - Epoch [78/200], Train Loss: 46.6393, Val Loss: 45.3174, Time: 0.84s, Batches: 110
2025-05-23 23:00:33,873 - INFO - Epoch [79/200], Train Loss: 43.5755, Val Loss: 42.4830, Time: 0.89s, Batches: 110
2025-05-23 23:00:34,757 - INFO - Epoch [80/200], Train Loss: 41.0645, Val Loss: 39.9522, Time: 0.82s, Batches: 110
2025-05-23 23:00:35,607 - INFO - Epoch [81/200], Train Loss: 38.4903, Val Loss: 37.5134, Time: 0.78s, Batches: 110
2025-05-23 23:00:36,490 - INFO - Epoch [82/200], Train Loss: 36.3188, Val Loss: 35.3010, Time: 0.80s, Batches: 110
2025-05-23 23:00:37,387 - INFO - Epoch [83/200], Train Loss: 34.4165, Val Loss: 33.3338, Time: 0.83s, Batches: 110
2025-05-23 23:00:38,320 - INFO - Epoch [84/200], Train Loss: 32.3421, Val Loss: 31.5513, Time: 0.86s, Batches: 110
2025-05-23 23:00:39,273 - INFO - Epoch [85/200], Train Loss: 30.5661, Val Loss: 29.4924, Time: 0.88s, Batches: 110
2025-05-23 23:00:40,209 - INFO - Epoch [86/200], Train Loss: 28.6576, Val Loss: 27.6378, Time: 0.85s, Batches: 110
2025-05-23 23:00:41,140 - INFO - Epoch [87/200], Train Loss: 26.9506, Val Loss: 26.0319, Time: 0.87s, Batches: 110
2025-05-23 23:00:42,023 - INFO - Epoch [88/200], Train Loss: 25.4124, Val Loss: 24.2103, Time: 0.83s, Batches: 110
2025-05-23 23:00:42,985 - INFO - Epoch [89/200], Train Loss: 23.7392, Val Loss: 22.7900, Time: 0.87s, Batches: 110
2025-05-23 23:00:44,021 - INFO - Epoch [90/200], Train Loss: 22.0632, Val Loss: 20.9856, Time: 0.96s, Batches: 110
2025-05-23 23:00:45,023 - INFO - Epoch [91/200], Train Loss: 20.6889, Val Loss: 19.7779, Time: 0.92s, Batches: 110
2025-05-23 23:00:45,940 - INFO - Epoch [92/200], Train Loss: 19.2948, Val Loss: 18.0447, Time: 0.84s, Batches: 110
2025-05-23 23:00:46,919 - INFO - Epoch [93/200], Train Loss: 18.0264, Val Loss: 16.5955, Time: 0.88s, Batches: 110
2025-05-23 23:00:47,860 - INFO - Epoch [94/200], Train Loss: 16.7227, Val Loss: 15.2536, Time: 0.86s, Batches: 110
2025-05-23 23:00:48,917 - INFO - Epoch [95/200], Train Loss: 15.5352, Val Loss: 14.0551, Time: 0.99s, Batches: 110
2025-05-23 23:00:49,862 - INFO - Epoch [96/200], Train Loss: 14.4256, Val Loss: 12.9005, Time: 0.85s, Batches: 110
2025-05-23 23:00:50,773 - INFO - Epoch [97/200], Train Loss: 13.5231, Val Loss: 11.9531, Time: 0.85s, Batches: 110
2025-05-23 23:00:51,724 - INFO - Epoch [98/200], Train Loss: 12.6576, Val Loss: 11.3669, Time: 0.87s, Batches: 110
2025-05-23 23:00:52,602 - INFO - Epoch [99/200], Train Loss: 11.9041, Val Loss: 10.1679, Time: 0.79s, Batches: 110
2025-05-23 23:00:53,572 - INFO - Epoch [100/200], Train Loss: 10.9802, Val Loss: 9.4361, Time: 0.89s, Batches: 110
2025-05-23 23:00:54,504 - INFO - Epoch [101/200], Train Loss: 10.2644, Val Loss: 8.6282, Time: 0.87s, Batches: 110
2025-05-23 23:00:55,396 - INFO - Epoch [102/200], Train Loss: 9.6225, Val Loss: 7.9495, Time: 0.82s, Batches: 110
2025-05-23 23:00:56,306 - INFO - Epoch [103/200], Train Loss: 9.0441, Val Loss: 7.1938, Time: 0.84s, Batches: 110
2025-05-23 23:00:57,223 - INFO - Epoch [104/200], Train Loss: 8.3980, Val Loss: 6.6390, Time: 0.85s, Batches: 110
2025-05-23 23:00:58,189 - INFO - Epoch [105/200], Train Loss: 7.9056, Val Loss: 6.0811, Time: 0.89s, Batches: 110
2025-05-23 23:00:59,244 - INFO - Epoch [106/200], Train Loss: 7.4123, Val Loss: 5.5940, Time: 0.96s, Batches: 110
2025-05-23 23:01:00,241 - INFO - Epoch [107/200], Train Loss: 6.9587, Val Loss: 5.0353, Time: 0.92s, Batches: 110
2025-05-23 23:01:01,206 - INFO - Epoch [108/200], Train Loss: 6.4118, Val Loss: 4.7105, Time: 0.90s, Batches: 110
2025-05-23 23:01:02,106 - INFO - Epoch [109/200], Train Loss: 6.0209, Val Loss: 4.2250, Time: 0.84s, Batches: 110
2025-05-23 23:01:03,074 - INFO - Epoch [110/200], Train Loss: 5.6004, Val Loss: 3.8605, Time: 0.88s, Batches: 110
2025-05-23 23:01:04,156 - INFO - Epoch [111/200], Train Loss: 5.1195, Val Loss: 3.4682, Time: 0.99s, Batches: 110
2025-05-23 23:01:05,291 - INFO - Epoch [112/200], Train Loss: 4.7913, Val Loss: 3.0927, Time: 1.06s, Batches: 110
2025-05-23 23:01:06,326 - INFO - Epoch [113/200], Train Loss: 4.3314, Val Loss: 2.8761, Time: 0.95s, Batches: 110
2025-05-23 23:01:07,357 - INFO - Epoch [114/200], Train Loss: 4.0653, Val Loss: 2.7361, Time: 0.96s, Batches: 110
2025-05-23 23:01:08,440 - INFO - Epoch [115/200], Train Loss: 3.7955, Val Loss: 2.3940, Time: 1.02s, Batches: 110
2025-05-23 23:01:09,356 - INFO - Epoch [116/200], Train Loss: 3.4913, Val Loss: 2.0541, Time: 0.85s, Batches: 110
2025-05-23 23:01:10,253 - INFO - Epoch [117/200], Train Loss: 3.2577, Val Loss: 1.8881, Time: 0.80s, Batches: 110
2025-05-23 23:01:11,155 - INFO - Epoch [118/200], Train Loss: 3.0286, Val Loss: 1.7134, Time: 0.83s, Batches: 110
2025-05-23 23:01:12,025 - INFO - Epoch [119/200], Train Loss: 2.8693, Val Loss: 1.5962, Time: 0.81s, Batches: 110
2025-05-23 23:01:12,891 - INFO - Epoch [120/200], Train Loss: 2.7628, Val Loss: 1.4551, Time: 0.81s, Batches: 110
2025-05-23 23:01:13,873 - INFO - Epoch [121/200], Train Loss: 2.5866, Val Loss: 1.3766, Time: 0.90s, Batches: 110
2025-05-23 23:01:14,841 - INFO - Epoch [122/200], Train Loss: 2.4777, Val Loss: 1.3192, Time: 0.90s, Batches: 110
2025-05-23 23:01:15,805 - INFO - Epoch [123/200], Train Loss: 2.3559, Val Loss: 1.1718, Time: 0.89s, Batches: 110
2025-05-23 23:01:16,706 - INFO - Epoch [124/200], Train Loss: 2.2538, Val Loss: 1.1651, Time: 0.83s, Batches: 110
2025-05-23 23:01:17,610 - INFO - Epoch [125/200], Train Loss: 2.2245, Val Loss: 1.0737, Time: 0.83s, Batches: 110
2025-05-23 23:01:18,640 - INFO - Epoch [126/200], Train Loss: 2.0968, Val Loss: 1.0152, Time: 0.95s, Batches: 110
2025-05-23 23:01:19,551 - INFO - Epoch [127/200], Train Loss: 2.1017, Val Loss: 0.9576, Time: 0.83s, Batches: 110
2025-05-23 23:01:20,435 - INFO - Epoch [128/200], Train Loss: 2.0060, Val Loss: 0.9265, Time: 0.81s, Batches: 110
2025-05-23 23:01:21,331 - INFO - Epoch [129/200], Train Loss: 1.9177, Val Loss: 0.8596, Time: 0.82s, Batches: 110
2025-05-23 23:01:22,267 - INFO - Epoch [130/200], Train Loss: 1.8500, Val Loss: 0.8119, Time: 0.81s, Batches: 110
2025-05-23 23:01:23,140 - INFO - Epoch [131/200], Train Loss: 1.8218, Val Loss: 0.7581, Time: 0.80s, Batches: 110
2025-05-23 23:01:24,106 - INFO - Epoch [132/200], Train Loss: 1.7571, Val Loss: 0.8171, Time: 0.86s, Batches: 110
2025-05-23 23:01:24,971 - INFO - Epoch [133/200], Train Loss: 1.7103, Val Loss: 0.7236, Time: 0.81s, Batches: 110
2025-05-23 23:01:25,842 - INFO - Epoch [134/200], Train Loss: 1.6771, Val Loss: 0.6690, Time: 0.81s, Batches: 110
2025-05-23 23:01:26,725 - INFO - Epoch [135/200], Train Loss: 1.6480, Val Loss: 0.6939, Time: 0.82s, Batches: 110
2025-05-23 23:01:27,607 - INFO - Epoch [136/200], Train Loss: 1.6537, Val Loss: 0.7402, Time: 0.83s, Batches: 110
2025-05-23 23:01:28,505 - INFO - Epoch [137/200], Train Loss: 1.5524, Val Loss: 0.6050, Time: 0.83s, Batches: 110
2025-05-23 23:01:29,404 - INFO - Epoch [138/200], Train Loss: 1.5535, Val Loss: 0.5960, Time: 0.82s, Batches: 110
2025-05-23 23:01:30,255 - INFO - Epoch [139/200], Train Loss: 1.5009, Val Loss: 0.5595, Time: 0.79s, Batches: 110
2025-05-23 23:01:31,157 - INFO - Epoch [140/200], Train Loss: 1.4621, Val Loss: 0.5512, Time: 0.83s, Batches: 110
2025-05-23 23:01:32,006 - INFO - Epoch [141/200], Train Loss: 1.4287, Val Loss: 0.5361, Time: 0.79s, Batches: 110
2025-05-23 23:01:32,860 - INFO - Epoch [142/200], Train Loss: 1.3858, Val Loss: 0.5225, Time: 0.80s, Batches: 110
2025-05-23 23:01:33,818 - INFO - Epoch [143/200], Train Loss: 1.4093, Val Loss: 0.5055, Time: 0.87s, Batches: 110
2025-05-23 23:01:34,680 - INFO - Epoch [144/200], Train Loss: 1.3250, Val Loss: 0.4936, Time: 0.79s, Batches: 110
2025-05-23 23:01:35,622 - INFO - Epoch [145/200], Train Loss: 1.3176, Val Loss: 0.4748, Time: 0.88s, Batches: 110
2025-05-23 23:01:36,568 - INFO - Epoch [146/200], Train Loss: 1.2804, Val Loss: 0.4941, Time: 0.85s, Batches: 110
2025-05-23 23:01:37,556 - INFO - Epoch [147/200], Train Loss: 1.2646, Val Loss: 0.4350, Time: 0.91s, Batches: 110
2025-05-23 23:01:38,555 - INFO - Epoch [148/200], Train Loss: 1.2264, Val Loss: 0.4290, Time: 0.92s, Batches: 110
2025-05-23 23:01:39,455 - INFO - Epoch [149/200], Train Loss: 1.2284, Val Loss: 0.4373, Time: 0.85s, Batches: 110
2025-05-23 23:01:40,289 - INFO - Epoch [150/200], Train Loss: 1.2144, Val Loss: 0.4368, Time: 0.79s, Batches: 110
2025-05-23 23:01:41,155 - INFO - Epoch [151/200], Train Loss: 1.1837, Val Loss: 0.4021, Time: 0.80s, Batches: 110
2025-05-23 23:01:42,039 - INFO - Epoch [152/200], Train Loss: 1.1764, Val Loss: 0.4172, Time: 0.82s, Batches: 110
2025-05-23 23:01:42,890 - INFO - Epoch [153/200], Train Loss: 1.1240, Val Loss: 0.4652, Time: 0.80s, Batches: 110
2025-05-23 23:01:43,846 - INFO - Epoch [154/200], Train Loss: 1.1517, Val Loss: 0.5180, Time: 0.88s, Batches: 110
2025-05-23 23:01:44,842 - INFO - Epoch [155/200], Train Loss: 1.1335, Val Loss: 0.3985, Time: 0.94s, Batches: 110
2025-05-23 23:01:45,833 - INFO - Epoch [156/200], Train Loss: 1.0714, Val Loss: 0.3719, Time: 0.90s, Batches: 110
2025-05-23 23:01:46,752 - INFO - Epoch [157/200], Train Loss: 1.0748, Val Loss: 0.3690, Time: 0.85s, Batches: 110
2025-05-23 23:01:47,708 - INFO - Epoch [158/200], Train Loss: 1.0698, Val Loss: 0.3993, Time: 0.84s, Batches: 110
2025-05-23 23:01:48,694 - INFO - Epoch [159/200], Train Loss: 1.0374, Val Loss: 0.3580, Time: 0.91s, Batches: 110
2025-05-23 23:01:49,582 - INFO - Epoch [160/200], Train Loss: 1.0346, Val Loss: 0.3511, Time: 0.81s, Batches: 110
2025-05-23 23:01:50,588 - INFO - Epoch [161/200], Train Loss: 1.0079, Val Loss: 0.3363, Time: 0.94s, Batches: 110
2025-05-23 23:01:51,610 - INFO - Epoch [162/200], Train Loss: 1.0166, Val Loss: 0.3215, Time: 0.94s, Batches: 110
2025-05-23 23:01:52,555 - INFO - Epoch [163/200], Train Loss: 0.9653, Val Loss: 0.3157, Time: 0.85s, Batches: 110
2025-05-23 23:01:53,581 - INFO - Epoch [164/200], Train Loss: 0.9640, Val Loss: 0.3280, Time: 0.94s, Batches: 110
2025-05-23 23:01:54,552 - INFO - Epoch [165/200], Train Loss: 0.9787, Val Loss: 0.3296, Time: 0.90s, Batches: 110
2025-05-23 23:01:55,569 - INFO - Epoch [166/200], Train Loss: 0.9373, Val Loss: 0.3075, Time: 0.95s, Batches: 110
2025-05-23 23:01:56,522 - INFO - Epoch [167/200], Train Loss: 0.9091, Val Loss: 0.3312, Time: 0.88s, Batches: 110
2025-05-23 23:01:57,489 - INFO - Epoch [168/200], Train Loss: 0.9274, Val Loss: 0.2899, Time: 0.91s, Batches: 110
2025-05-23 23:01:58,464 - INFO - Epoch [169/200], Train Loss: 0.9119, Val Loss: 0.3068, Time: 0.91s, Batches: 110
2025-05-23 23:01:59,479 - INFO - Epoch [170/200], Train Loss: 0.9186, Val Loss: 0.2806, Time: 0.94s, Batches: 110
2025-05-23 23:02:00,532 - INFO - Epoch [171/200], Train Loss: 0.8790, Val Loss: 0.2851, Time: 0.96s, Batches: 110
2025-05-23 23:02:01,516 - INFO - Epoch [172/200], Train Loss: 0.8638, Val Loss: 0.2968, Time: 0.90s, Batches: 110
2025-05-23 23:02:02,486 - INFO - Epoch [173/200], Train Loss: 0.8571, Val Loss: 0.2695, Time: 0.90s, Batches: 110
2025-05-23 23:02:03,504 - INFO - Epoch [174/200], Train Loss: 0.8261, Val Loss: 0.3495, Time: 0.94s, Batches: 110
2025-05-23 23:02:04,427 - INFO - Epoch [175/200], Train Loss: 0.8437, Val Loss: 0.2674, Time: 0.85s, Batches: 110
2025-05-23 23:02:05,466 - INFO - Epoch [176/200], Train Loss: 0.8278, Val Loss: 0.2580, Time: 0.95s, Batches: 110
2025-05-23 23:02:06,422 - INFO - Epoch [177/200], Train Loss: 0.8155, Val Loss: 0.2797, Time: 0.90s, Batches: 110
2025-05-23 23:02:07,371 - INFO - Epoch [178/200], Train Loss: 0.7886, Val Loss: 0.2861, Time: 0.91s, Batches: 110
2025-05-23 23:02:08,388 - INFO - Epoch [179/200], Train Loss: 0.7925, Val Loss: 0.2734, Time: 0.96s, Batches: 110
2025-05-23 23:02:09,442 - INFO - Epoch [180/200], Train Loss: 0.7681, Val Loss: 0.2559, Time: 0.99s, Batches: 110
2025-05-23 23:02:10,505 - INFO - Epoch [181/200], Train Loss: 0.7843, Val Loss: 0.2534, Time: 0.97s, Batches: 110
2025-05-23 23:02:11,519 - INFO - Epoch [182/200], Train Loss: 0.7622, Val Loss: 0.2331, Time: 0.94s, Batches: 110
2025-05-23 23:02:12,545 - INFO - Epoch [183/200], Train Loss: 0.7519, Val Loss: 0.2795, Time: 0.95s, Batches: 110
2025-05-23 23:02:13,626 - INFO - Epoch [184/200], Train Loss: 0.7540, Val Loss: 0.2854, Time: 1.01s, Batches: 110
2025-05-23 23:02:14,608 - INFO - Epoch [185/200], Train Loss: 0.7487, Val Loss: 0.2359, Time: 0.92s, Batches: 110
2025-05-23 23:02:15,466 - INFO - Epoch [186/200], Train Loss: 0.7481, Val Loss: 0.3556, Time: 0.80s, Batches: 110
2025-05-23 23:02:16,321 - INFO - Epoch [187/200], Train Loss: 0.7266, Val Loss: 0.2450, Time: 0.79s, Batches: 110
2025-05-23 23:02:17,171 - INFO - Epoch [188/200], Train Loss: 0.7102, Val Loss: 0.2286, Time: 0.81s, Batches: 110
2025-05-23 23:02:18,021 - INFO - Epoch [189/200], Train Loss: 0.7176, Val Loss: 0.2301, Time: 0.78s, Batches: 110
2025-05-23 23:02:19,006 - INFO - Epoch [190/200], Train Loss: 0.7175, Val Loss: 0.2274, Time: 0.92s, Batches: 110
2025-05-23 23:02:19,933 - INFO - Epoch [191/200], Train Loss: 0.7079, Val Loss: 0.2286, Time: 0.85s, Batches: 110
2025-05-23 23:02:20,893 - INFO - Epoch [192/200], Train Loss: 0.7094, Val Loss: 0.2248, Time: 0.89s, Batches: 110
2025-05-23 23:02:21,847 - INFO - Epoch [193/200], Train Loss: 0.7129, Val Loss: 0.2220, Time: 0.87s, Batches: 110
2025-05-23 23:02:22,804 - INFO - Epoch [194/200], Train Loss: 0.6859, Val Loss: 0.2277, Time: 0.83s, Batches: 110
2025-05-23 23:02:23,804 - INFO - Epoch [195/200], Train Loss: 0.6744, Val Loss: 0.2414, Time: 0.94s, Batches: 110
2025-05-23 23:02:24,709 - INFO - Epoch [196/200], Train Loss: 0.6693, Val Loss: 0.2134, Time: 0.86s, Batches: 110
2025-05-23 23:02:25,632 - INFO - Epoch [197/200], Train Loss: 0.6821, Val Loss: 0.2066, Time: 0.85s, Batches: 110
2025-05-23 23:02:26,534 - INFO - Epoch [198/200], Train Loss: 0.6622, Val Loss: 0.1968, Time: 0.83s, Batches: 110
2025-05-23 23:02:27,468 - INFO - Epoch [199/200], Train Loss: 0.6469, Val Loss: 0.2069, Time: 0.87s, Batches: 110
2025-05-23 23:02:28,405 - INFO - Epoch [200/200], Train Loss: 0.6319, Val Loss: 0.2060, Time: 0.87s, Batches: 110
2025-05-23 23:02:47,112 - INFO - Optimized LSTM MSE: 0.1777, R2: 0.9981
2025-05-23 23:03:14,976 - INFO - B\u1eaft \u0111\u1ea7u hu\u1ea5n luy\u1ec7n mô hình LSTM v\u1edbi early stopping...
2025-05-23 23:03:19,132 - INFO - Epoch [1/200], Train Loss: 1996.1763, Val Loss: 1540.8526, Time: 3.94s, Batches: 440
2025-05-23 23:03:22,711 - INFO - Epoch [2/200], Train Loss: 1369.0588, Val Loss: 1181.5256, Time: 3.37s, Batches: 440
2025-05-23 23:03:26,173 - INFO - Epoch [3/200], Train Loss: 1065.5884, Val Loss: 922.9164, Time: 3.27s, Batches: 440
2025-05-23 23:03:29,572 - INFO - Epoch [4/200], Train Loss: 832.5103, Val Loss: 717.6793, Time: 3.22s, Batches: 440
2025-05-23 23:03:32,808 - INFO - Epoch [5/200], Train Loss: 645.7711, Val Loss: 552.6509, Time: 3.07s, Batches: 440
2025-05-23 23:03:35,851 - INFO - Epoch [6/200], Train Loss: 495.6426, Val Loss: 420.9335, Time: 2.87s, Batches: 440
2025-05-23 23:03:38,904 - INFO - Epoch [7/200], Train Loss: 376.8045, Val Loss: 318.1231, Time: 2.85s, Batches: 440
2025-05-23 23:03:41,968 - INFO - Epoch [8/200], Train Loss: 284.7670, Val Loss: 240.0607, Time: 2.83s, Batches: 440
2025-05-23 23:03:44,943 - INFO - Epoch [9/200], Train Loss: 215.7732, Val Loss: 183.0751, Time: 2.80s, Batches: 440
2025-05-23 23:03:47,870 - INFO - Epoch [10/200], Train Loss: 166.3195, Val Loss: 143.7278, Time: 2.78s, Batches: 440
2025-05-23 23:03:51,214 - INFO - Epoch [11/200], Train Loss: 133.0013, Val Loss: 118.5760, Time: 3.18s, Batches: 440
2025-05-23 23:03:54,552 - INFO - Epoch [12/200], Train Loss: 112.3339, Val Loss: 104.1428, Time: 3.18s, Batches: 440
2025-05-23 23:03:57,923 - INFO - Epoch [13/200], Train Loss: 100.8056, Val Loss: 96.9419, Time: 3.18s, Batches: 440
2025-05-23 23:04:01,460 - INFO - Epoch [14/200], Train Loss: 95.2469, Val Loss: 94.0350, Time: 3.35s, Batches: 440
2025-05-23 23:04:04,936 - INFO - Epoch [15/200], Train Loss: 92.9705, Val Loss: 93.1607, Time: 3.30s, Batches: 440
2025-05-23 23:04:08,022 - INFO - Epoch [16/200], Train Loss: 92.2684, Val Loss: 93.0586, Time: 2.90s, Batches: 440
2025-05-23 23:04:11,076 - INFO - Epoch [17/200], Train Loss: 92.0886, Val Loss: 93.0804, Time: 2.88s, Batches: 440
2025-05-23 23:04:14,306 - INFO - Epoch [18/200], Train Loss: 92.0228, Val Loss: 92.9704, Time: 3.09s, Batches: 440
2025-05-23 23:04:17,218 - INFO - Epoch [19/200], Train Loss: 82.6818, Val Loss: 63.2324, Time: 2.76s, Batches: 440
2025-05-23 23:04:20,370 - INFO - Epoch [20/200], Train Loss: 55.2589, Val Loss: 48.2400, Time: 3.01s, Batches: 440
2025-05-23 23:04:23,669 - INFO - Epoch [21/200], Train Loss: 44.1234, Val Loss: 40.2786, Time: 3.10s, Batches: 440
2025-05-23 23:04:26,819 - INFO - Epoch [22/200], Train Loss: 37.2235, Val Loss: 34.0905, Time: 3.01s, Batches: 440
2025-05-23 23:04:29,752 - INFO - Epoch [23/200], Train Loss: 32.1659, Val Loss: 29.2224, Time: 2.77s, Batches: 440
2025-05-23 23:04:32,486 - INFO - Epoch [24/200], Train Loss: 27.9287, Val Loss: 25.1170, Time: 2.58s, Batches: 440
2025-05-23 23:04:35,485 - INFO - Epoch [25/200], Train Loss: 24.2226, Val Loss: 21.3682, Time: 2.84s, Batches: 440
2025-05-23 23:04:38,281 - INFO - Epoch [26/200], Train Loss: 20.8617, Val Loss: 18.1541, Time: 2.63s, Batches: 440
2025-05-23 23:04:41,001 - INFO - Epoch [27/200], Train Loss: 17.7286, Val Loss: 14.8327, Time: 2.58s, Batches: 440
2025-05-23 23:04:43,785 - INFO - Epoch [28/200], Train Loss: 14.9860, Val Loss: 11.9329, Time: 2.61s, Batches: 440
2025-05-23 23:04:46,518 - INFO - Epoch [29/200], Train Loss: 12.3297, Val Loss: 9.7117, Time: 2.58s, Batches: 440
2025-05-23 23:04:49,268 - INFO - Epoch [30/200], Train Loss: 10.4112, Val Loss: 8.0661, Time: 2.63s, Batches: 440
2025-05-23 23:04:51,935 - INFO - Epoch [31/200], Train Loss: 8.7239, Val Loss: 5.9553, Time: 2.52s, Batches: 440
2025-05-23 23:04:54,818 - INFO - Epoch [32/200], Train Loss: 7.2837, Val Loss: 4.8783, Time: 2.70s, Batches: 440
2025-05-23 23:04:57,630 - INFO - Epoch [33/200], Train Loss: 6.1020, Val Loss: 3.8442, Time: 2.68s, Batches: 440
2025-05-23 23:05:00,445 - INFO - Epoch [34/200], Train Loss: 5.1298, Val Loss: 2.8764, Time: 2.67s, Batches: 440
2025-05-23 23:05:03,168 - INFO - Epoch [35/200], Train Loss: 4.2556, Val Loss: 2.1483, Time: 2.58s, Batches: 440
2025-05-23 23:05:06,101 - INFO - Epoch [36/200], Train Loss: 3.5081, Val Loss: 1.8409, Time: 2.81s, Batches: 440
2025-05-23 23:05:09,401 - INFO - Epoch [37/200], Train Loss: 2.9963, Val Loss: 1.3241, Time: 3.15s, Batches: 440
2025-05-23 23:05:12,567 - INFO - Epoch [38/200], Train Loss: 2.5688, Val Loss: 1.8113, Time: 2.98s, Batches: 440
2025-05-23 23:05:15,651 - INFO - Epoch [39/200], Train Loss: 2.3626, Val Loss: 0.8831, Time: 2.94s, Batches: 440
2025-05-23 23:05:18,721 - INFO - Epoch [40/200], Train Loss: 2.1598, Val Loss: 0.8859, Time: 2.87s, Batches: 440
2025-05-23 23:05:21,817 - INFO - Epoch [41/200], Train Loss: 1.9658, Val Loss: 0.7018, Time: 2.95s, Batches: 440
2025-05-23 23:05:24,999 - INFO - Epoch [42/200], Train Loss: 1.9180, Val Loss: 0.6343, Time: 3.03s, Batches: 440
2025-05-23 23:05:28,206 - INFO - Epoch [43/200], Train Loss: 1.6953, Val Loss: 0.6076, Time: 3.05s, Batches: 440
2025-05-23 23:05:31,692 - INFO - Epoch [44/200], Train Loss: 1.6255, Val Loss: 0.5348, Time: 3.29s, Batches: 440
2025-05-23 23:05:34,733 - INFO - Epoch [45/200], Train Loss: 1.5826, Val Loss: 0.5292, Time: 2.90s, Batches: 440
2025-05-23 23:05:37,554 - INFO - Epoch [46/200], Train Loss: 1.4784, Val Loss: 0.8848, Time: 2.62s, Batches: 440
2025-05-23 23:05:40,723 - INFO - Epoch [47/200], Train Loss: 1.4399, Val Loss: 0.4237, Time: 2.99s, Batches: 440
2025-05-23 23:05:43,734 - INFO - Epoch [48/200], Train Loss: 1.3807, Val Loss: 0.4096, Time: 2.83s, Batches: 440
2025-05-23 23:05:46,585 - INFO - Epoch [49/200], Train Loss: 1.3276, Val Loss: 0.3750, Time: 2.66s, Batches: 440
2025-05-23 23:05:49,456 - INFO - Epoch [50/200], Train Loss: 1.2161, Val Loss: 0.3781, Time: 2.71s, Batches: 440
2025-05-23 23:05:52,224 - INFO - Epoch [51/200], Train Loss: 1.1880, Val Loss: 0.3489, Time: 2.63s, Batches: 440
2025-05-23 23:05:55,047 - INFO - Epoch [52/200], Train Loss: 1.1715, Val Loss: 0.3902, Time: 2.65s, Batches: 440
2025-05-23 23:05:57,753 - INFO - Epoch [53/200], Train Loss: 1.1244, Val Loss: 0.3500, Time: 2.57s, Batches: 440
2025-05-23 23:06:00,686 - INFO - Epoch [54/200], Train Loss: 1.0821, Val Loss: 0.4265, Time: 2.78s, Batches: 440
2025-05-23 23:06:03,665 - INFO - Epoch [55/200], Train Loss: 1.0412, Val Loss: 0.3629, Time: 2.78s, Batches: 440
2025-05-23 23:06:06,550 - INFO - Epoch [56/200], Train Loss: 1.0048, Val Loss: 0.3135, Time: 2.70s, Batches: 440
2025-05-23 23:06:09,464 - INFO - Epoch [57/200], Train Loss: 0.9969, Val Loss: 0.2799, Time: 2.73s, Batches: 440
2025-05-23 23:06:12,621 - INFO - Epoch [58/200], Train Loss: 0.9443, Val Loss: 0.2616, Time: 2.97s, Batches: 440
2025-05-23 23:06:16,019 - INFO - Epoch [59/200], Train Loss: 0.9267, Val Loss: 0.2715, Time: 3.17s, Batches: 440
2025-05-23 23:06:19,221 - INFO - Epoch [60/200], Train Loss: 0.8959, Val Loss: 0.2681, Time: 3.03s, Batches: 440
2025-05-23 23:06:22,330 - INFO - Epoch [61/200], Train Loss: 0.8659, Val Loss: 0.4579, Time: 2.98s, Batches: 440
2025-05-23 23:06:25,606 - INFO - Epoch [62/200], Train Loss: 0.8793, Val Loss: 0.2392, Time: 3.12s, Batches: 440
2025-05-23 23:06:28,881 - INFO - Epoch [63/200], Train Loss: 0.8461, Val Loss: 0.3188, Time: 3.08s, Batches: 440
2025-05-23 23:06:32,236 - INFO - Epoch [64/200], Train Loss: 0.8006, Val Loss: 0.2306, Time: 3.12s, Batches: 440
2025-05-23 23:06:35,691 - INFO - Epoch [65/200], Train Loss: 0.8005, Val Loss: 0.2166, Time: 3.28s, Batches: 440
2025-05-23 23:06:39,198 - INFO - Epoch [66/200], Train Loss: 0.8177, Val Loss: 0.3544, Time: 3.30s, Batches: 440
2025-05-23 23:06:42,083 - INFO - Epoch [67/200], Train Loss: 0.7572, Val Loss: 0.2460, Time: 2.73s, Batches: 440
2025-05-23 23:06:45,316 - INFO - Epoch [68/200], Train Loss: 0.7344, Val Loss: 0.2501, Time: 3.09s, Batches: 440
2025-05-23 23:06:48,386 - INFO - Epoch [69/200], Train Loss: 0.7486, Val Loss: 0.2184, Time: 2.90s, Batches: 440
2025-05-23 23:06:51,390 - INFO - Epoch [70/200], Train Loss: 0.7416, Val Loss: 0.2700, Time: 2.86s, Batches: 440
2025-05-23 23:06:54,433 - INFO - Epoch [71/200], Train Loss: 0.7308, Val Loss: 0.2232, Time: 2.86s, Batches: 440
2025-05-23 23:06:57,266 - INFO - Epoch [72/200], Train Loss: 0.7117, Val Loss: 0.2093, Time: 2.68s, Batches: 440
2025-05-23 23:07:00,249 - INFO - Epoch [73/200], Train Loss: 0.6809, Val Loss: 0.3536, Time: 2.82s, Batches: 440
2025-05-23 23:07:03,170 - INFO - Epoch [74/200], Train Loss: 0.6695, Val Loss: 0.3146, Time: 2.75s, Batches: 440
2025-05-23 23:07:06,217 - INFO - Epoch [75/200], Train Loss: 0.6682, Val Loss: 0.1819, Time: 2.88s, Batches: 440
2025-05-23 23:07:09,438 - INFO - Epoch [76/200], Train Loss: 0.6565, Val Loss: 0.2251, Time: 3.01s, Batches: 440
2025-05-23 23:07:12,452 - INFO - Epoch [77/200], Train Loss: 0.6372, Val Loss: 0.3084, Time: 2.87s, Batches: 440
2025-05-23 23:07:15,497 - INFO - Epoch [78/200], Train Loss: 0.6281, Val Loss: 0.1898, Time: 2.86s, Batches: 440
2025-05-23 23:07:18,667 - INFO - Epoch [79/200], Train Loss: 0.6185, Val Loss: 0.1847, Time: 2.98s, Batches: 440
2025-05-23 23:07:22,163 - INFO - Epoch [80/200], Train Loss: 0.6195, Val Loss: 0.1922, Time: 3.33s, Batches: 440
2025-05-23 23:07:25,518 - INFO - Epoch [81/200], Train Loss: 0.6198, Val Loss: 0.2017, Time: 3.17s, Batches: 440
2025-05-23 23:07:28,767 - INFO - Epoch [82/200], Train Loss: 0.6064, Val Loss: 0.1860, Time: 3.05s, Batches: 440
2025-05-23 23:07:32,185 - INFO - Epoch [83/200], Train Loss: 0.5951, Val Loss: 0.1699, Time: 3.24s, Batches: 440
2025-05-23 23:07:35,515 - INFO - Epoch [84/200], Train Loss: 0.5750, Val Loss: 0.1930, Time: 3.11s, Batches: 440
2025-05-23 23:07:39,001 - INFO - Epoch [85/200], Train Loss: 0.5678, Val Loss: 0.1988, Time: 3.25s, Batches: 440
2025-05-23 23:07:42,599 - INFO - Epoch [86/200], Train Loss: 0.5801, Val Loss: 0.1592, Time: 3.44s, Batches: 440
2025-05-23 23:07:45,739 - INFO - Epoch [87/200], Train Loss: 0.5752, Val Loss: 0.1443, Time: 2.97s, Batches: 440
2025-05-23 23:07:48,700 - INFO - Epoch [88/200], Train Loss: 0.5822, Val Loss: 0.1872, Time: 2.78s, Batches: 440
2025-05-23 23:07:51,834 - INFO - Epoch [89/200], Train Loss: 0.5554, Val Loss: 0.2628, Time: 3.00s, Batches: 440
2025-05-23 23:07:54,963 - INFO - Epoch [90/200], Train Loss: 0.5491, Val Loss: 0.2357, Time: 3.00s, Batches: 440
2025-05-23 23:07:57,918 - INFO - Epoch [91/200], Train Loss: 0.5295, Val Loss: 0.1896, Time: 2.82s, Batches: 440
2025-05-23 23:08:00,928 - INFO - Epoch [92/200], Train Loss: 0.5377, Val Loss: 0.1422, Time: 2.86s, Batches: 440
2025-05-23 23:08:03,811 - INFO - Epoch [93/200], Train Loss: 0.5342, Val Loss: 0.2058, Time: 2.72s, Batches: 440
2025-05-23 23:08:06,686 - INFO - Epoch [94/200], Train Loss: 0.5240, Val Loss: 0.4554, Time: 2.69s, Batches: 440
2025-05-23 23:08:09,745 - INFO - Epoch [95/200], Train Loss: 0.5152, Val Loss: 0.2471, Time: 2.87s, Batches: 440
2025-05-23 23:08:12,751 - INFO - Epoch [96/200], Train Loss: 0.5200, Val Loss: 0.1634, Time: 2.84s, Batches: 440
2025-05-23 23:08:15,664 - INFO - Epoch [97/200], Train Loss: 0.4976, Val Loss: 0.2155, Time: 2.79s, Batches: 440
2025-05-23 23:08:18,548 - INFO - Epoch [98/200], Train Loss: 0.4855, Val Loss: 0.1299, Time: 2.73s, Batches: 440
2025-05-23 23:08:21,464 - INFO - Epoch [99/200], Train Loss: 0.4873, Val Loss: 0.1142, Time: 2.79s, Batches: 440
2025-05-23 23:08:24,731 - INFO - Epoch [100/200], Train Loss: 0.4777, Val Loss: 0.1274, Time: 3.10s, Batches: 440
2025-05-23 23:08:28,218 - INFO - Epoch [101/200], Train Loss: 0.4867, Val Loss: 0.1227, Time: 3.30s, Batches: 440
2025-05-23 23:08:31,513 - INFO - Epoch [102/200], Train Loss: 0.4778, Val Loss: 0.2262, Time: 3.13s, Batches: 440
2025-05-23 23:08:34,646 - INFO - Epoch [103/200], Train Loss: 0.4779, Val Loss: 0.2639, Time: 2.92s, Batches: 440
2025-05-23 23:08:37,753 - INFO - Epoch [104/200], Train Loss: 0.4751, Val Loss: 0.1194, Time: 2.95s, Batches: 440
2025-05-23 23:08:41,057 - INFO - Epoch [105/200], Train Loss: 0.4735, Val Loss: 0.1167, Time: 3.13s, Batches: 440
2025-05-23 23:08:44,611 - INFO - Epoch [106/200], Train Loss: 0.4712, Val Loss: 0.1148, Time: 3.38s, Batches: 440
2025-05-23 23:08:48,167 - INFO - Epoch [107/200], Train Loss: 0.4650, Val Loss: 0.1447, Time: 3.37s, Batches: 440
2025-05-23 23:08:51,482 - INFO - Epoch [108/200], Train Loss: 0.4758, Val Loss: 0.1234, Time: 3.13s, Batches: 440
2025-05-23 23:08:54,379 - INFO - Epoch [109/200], Train Loss: 0.4475, Val Loss: 0.1170, Time: 2.76s, Batches: 440
2025-05-23 23:09:37,853 - INFO - Optimized LSTM MSE: 0.1194, R2: 0.9987
2025-05-23 23:10:09,300 - INFO - B\u1eaft \u0111\u1ea7u hu\u1ea5n luy\u1ec7n mô hình LSTM v\u1edbi early stopping...
2025-05-23 23:10:12,315 - INFO - Epoch [1/200], Train Loss: 1978.2521, Val Loss: 1517.5496, Time: 2.89s, Batches: 440
2025-05-23 23:10:15,066 - INFO - Epoch [2/200], Train Loss: 1346.7347, Val Loss: 1160.5549, Time: 2.62s, Batches: 440
2025-05-23 23:10:17,693 - INFO - Epoch [3/200], Train Loss: 1045.7525, Val Loss: 904.8425, Time: 2.49s, Batches: 440
2025-05-23 23:10:20,291 - INFO - Epoch [4/200], Train Loss: 815.5665, Val Loss: 702.2196, Time: 2.46s, Batches: 440
2025-05-23 23:10:23,011 - INFO - Epoch [5/200], Train Loss: 631.3097, Val Loss: 539.5642, Time: 2.58s, Batches: 440
2025-05-23 23:10:25,943 - INFO - Epoch [6/200], Train Loss: 483.8007, Val Loss: 410.5352, Time: 2.79s, Batches: 440
2025-05-23 23:10:28,494 - INFO - Epoch [7/200], Train Loss: 367.2009, Val Loss: 309.8357, Time: 2.42s, Batches: 440
2025-05-23 23:10:31,227 - INFO - Epoch [8/200], Train Loss: 277.2582, Val Loss: 233.7533, Time: 2.61s, Batches: 440
2025-05-23 23:10:33,832 - INFO - Epoch [9/200], Train Loss: 210.1705, Val Loss: 178.5211, Time: 2.45s, Batches: 440
2025-05-23 23:10:36,928 - INFO - Epoch [10/200], Train Loss: 162.4044, Val Loss: 140.6113, Time: 2.91s, Batches: 440
2025-05-23 23:10:40,261 - INFO - Epoch [11/200], Train Loss: 130.4155, Val Loss: 116.7013, Time: 3.17s, Batches: 440
2025-05-23 23:10:43,418 - INFO - Epoch [12/200], Train Loss: 110.7936, Val Loss: 103.1497, Time: 2.99s, Batches: 440
2025-05-23 23:10:46,547 - INFO - Epoch [13/200], Train Loss: 100.0077, Val Loss: 96.4751, Time: 2.95s, Batches: 440
2025-05-23 23:10:49,802 - INFO - Epoch [14/200], Train Loss: 94.8990, Val Loss: 93.8719, Time: 3.08s, Batches: 440
2025-05-23 23:10:52,944 - INFO - Epoch [15/200], Train Loss: 92.8864, Val Loss: 93.1414, Time: 2.98s, Batches: 440
2025-05-23 23:10:56,193 - INFO - Epoch [16/200], Train Loss: 92.2577, Val Loss: 93.0501, Time: 3.09s, Batches: 440
2025-05-23 23:10:59,744 - INFO - Epoch [17/200], Train Loss: 92.0788, Val Loss: 93.0630, Time: 3.37s, Batches: 440
2025-05-23 23:11:02,804 - INFO - Epoch [18/200], Train Loss: 91.9916, Val Loss: 92.8303, Time: 2.92s, Batches: 440
2025-05-23 23:11:05,563 - INFO - Epoch [19/200], Train Loss: 77.7288, Val Loss: 59.6247, Time: 2.61s, Batches: 440
2025-05-23 23:11:08,527 - INFO - Epoch [20/200], Train Loss: 52.7299, Val Loss: 45.9808, Time: 2.80s, Batches: 440
2025-05-23 23:11:11,561 - INFO - Epoch [21/200], Train Loss: 42.6193, Val Loss: 38.4805, Time: 2.90s, Batches: 440
2025-05-23 23:11:14,396 - INFO - Epoch [22/200], Train Loss: 36.0914, Val Loss: 32.8188, Time: 2.67s, Batches: 440
2025-05-23 23:11:17,092 - INFO - Epoch [23/200], Train Loss: 31.2825, Val Loss: 28.3250, Time: 2.55s, Batches: 440
2025-05-23 23:11:19,925 - INFO - Epoch [24/200], Train Loss: 27.0856, Val Loss: 24.8333, Time: 2.68s, Batches: 440
2025-05-23 23:11:22,694 - INFO - Epoch [25/200], Train Loss: 23.5663, Val Loss: 20.6706, Time: 2.63s, Batches: 440
2025-05-23 23:11:25,504 - INFO - Epoch [26/200], Train Loss: 20.1825, Val Loss: 17.3823, Time: 2.66s, Batches: 440
2025-05-23 23:11:28,409 - INFO - Epoch [27/200], Train Loss: 17.1266, Val Loss: 14.4866, Time: 2.70s, Batches: 440
2025-05-23 23:11:31,376 - INFO - Epoch [28/200], Train Loss: 14.3724, Val Loss: 11.9244, Time: 2.82s, Batches: 440
2025-05-23 23:11:34,203 - INFO - Epoch [29/200], Train Loss: 11.9886, Val Loss: 9.3721, Time: 2.65s, Batches: 440
2025-05-23 23:11:37,033 - INFO - Epoch [30/200], Train Loss: 10.0589, Val Loss: 7.4121, Time: 2.67s, Batches: 440
2025-05-23 23:11:40,056 - INFO - Epoch [31/200], Train Loss: 8.5271, Val Loss: 5.8310, Time: 2.85s, Batches: 440
2025-05-23 23:11:43,360 - INFO - Epoch [32/200], Train Loss: 7.3337, Val Loss: 4.8593, Time: 3.13s, Batches: 440
2025-05-23 23:11:46,581 - INFO - Epoch [33/200], Train Loss: 6.4110, Val Loss: 3.8627, Time: 3.06s, Batches: 440
2025-05-23 23:11:49,793 - INFO - Epoch [34/200], Train Loss: 5.7463, Val Loss: 3.2279, Time: 3.01s, Batches: 440
2025-05-23 23:11:52,712 - INFO - Epoch [35/200], Train Loss: 5.0393, Val Loss: 2.6549, Time: 2.75s, Batches: 440
2025-05-23 23:11:55,859 - INFO - Epoch [36/200], Train Loss: 4.4574, Val Loss: 2.1933, Time: 2.95s, Batches: 440
2025-05-23 23:11:59,128 - INFO - Epoch [37/200], Train Loss: 3.9391, Val Loss: 2.2300, Time: 3.07s, Batches: 440
2025-05-23 23:12:02,433 - INFO - Epoch [38/200], Train Loss: 3.5358, Val Loss: 1.4874, Time: 3.11s, Batches: 440
2025-05-23 23:12:05,859 - INFO - Epoch [39/200], Train Loss: 3.0602, Val Loss: 1.1903, Time: 3.25s, Batches: 440
2025-05-23 23:12:08,742 - INFO - Epoch [40/200], Train Loss: 2.6776, Val Loss: 0.9550, Time: 2.73s, Batches: 440
2025-05-23 23:12:11,475 - INFO - Epoch [41/200], Train Loss: 2.4463, Val Loss: 1.0368, Time: 2.61s, Batches: 440
2025-05-23 23:12:14,425 - INFO - Epoch [42/200], Train Loss: 2.1989, Val Loss: 0.9914, Time: 2.80s, Batches: 440
2025-05-23 23:12:17,261 - INFO - Epoch [43/200], Train Loss: 2.0164, Val Loss: 0.6188, Time: 2.70s, Batches: 440
2025-05-23 23:12:20,042 - INFO - Epoch [44/200], Train Loss: 1.9011, Val Loss: 0.5335, Time: 2.65s, Batches: 440
2025-05-23 23:12:22,864 - INFO - Epoch [45/200], Train Loss: 1.7410, Val Loss: 0.4615, Time: 2.66s, Batches: 440
2025-05-23 23:12:25,650 - INFO - Epoch [46/200], Train Loss: 1.6337, Val Loss: 0.4702, Time: 2.63s, Batches: 440
2025-05-23 23:12:28,439 - INFO - Epoch [47/200], Train Loss: 1.5813, Val Loss: 0.5348, Time: 2.63s, Batches: 440
2025-05-23 23:12:31,242 - INFO - Epoch [48/200], Train Loss: 1.4873, Val Loss: 0.4997, Time: 2.67s, Batches: 440
2025-05-23 23:12:34,036 - INFO - Epoch [49/200], Train Loss: 1.4401, Val Loss: 0.4545, Time: 2.65s, Batches: 440
2025-05-23 23:12:36,992 - INFO - Epoch [50/200], Train Loss: 1.3833, Val Loss: 0.4283, Time: 2.79s, Batches: 440
2025-05-23 23:12:39,940 - INFO - Epoch [51/200], Train Loss: 1.3109, Val Loss: 0.3267, Time: 2.75s, Batches: 440
2025-05-23 23:12:42,594 - INFO - Epoch [52/200], Train Loss: 1.2539, Val Loss: 0.3412, Time: 2.51s, Batches: 440
2025-05-23 23:12:45,592 - INFO - Epoch [53/200], Train Loss: 1.1779, Val Loss: 0.3892, Time: 2.84s, Batches: 440
2025-05-23 23:12:48,895 - INFO - Epoch [54/200], Train Loss: 1.1399, Val Loss: 0.3051, Time: 3.08s, Batches: 440
2025-05-23 23:12:52,175 - INFO - Epoch [55/200], Train Loss: 1.0845, Val Loss: 0.4848, Time: 3.14s, Batches: 440
2025-05-23 23:12:55,398 - INFO - Epoch [56/200], Train Loss: 1.0778, Val Loss: 0.2645, Time: 3.06s, Batches: 440
2025-05-23 23:12:58,612 - INFO - Epoch [57/200], Train Loss: 1.0421, Val Loss: 0.3421, Time: 3.04s, Batches: 440
2025-05-23 23:13:01,958 - INFO - Epoch [58/200], Train Loss: 1.0140, Val Loss: 0.2693, Time: 3.17s, Batches: 440
2025-05-23 23:13:05,199 - INFO - Epoch [59/200], Train Loss: 0.9734, Val Loss: 0.2620, Time: 3.08s, Batches: 440
2025-05-23 23:13:08,610 - INFO - Epoch [60/200], Train Loss: 0.9958, Val Loss: 0.2820, Time: 3.21s, Batches: 440
2025-05-23 23:13:12,240 - INFO - Epoch [61/200], Train Loss: 0.9305, Val Loss: 0.2667, Time: 3.43s, Batches: 440
2025-05-23 23:13:15,574 - INFO - Epoch [62/200], Train Loss: 0.9293, Val Loss: 0.2920, Time: 3.17s, Batches: 440
2025-05-23 23:13:18,741 - INFO - Epoch [63/200], Train Loss: 0.8902, Val Loss: 0.2609, Time: 3.02s, Batches: 440
2025-05-23 23:13:21,866 - INFO - Epoch [64/200], Train Loss: 0.8827, Val Loss: 0.2244, Time: 2.97s, Batches: 440
2025-05-23 23:13:24,907 - INFO - Epoch [65/200], Train Loss: 0.8381, Val Loss: 0.2328, Time: 2.88s, Batches: 440
2025-05-23 23:13:27,807 - INFO - Epoch [66/200], Train Loss: 0.8219, Val Loss: 0.2227, Time: 2.73s, Batches: 440
2025-05-23 23:13:30,843 - INFO - Epoch [67/200], Train Loss: 0.7961, Val Loss: 0.2457, Time: 2.88s, Batches: 440
2025-05-23 23:13:34,118 - INFO - Epoch [68/200], Train Loss: 0.8118, Val Loss: 0.2563, Time: 3.10s, Batches: 440
2025-05-23 23:13:37,043 - INFO - Epoch [69/200], Train Loss: 0.7713, Val Loss: 0.5121, Time: 2.79s, Batches: 440
2025-05-23 23:13:40,149 - INFO - Epoch [70/200], Train Loss: 0.7736, Val Loss: 0.2179, Time: 2.93s, Batches: 440
2025-05-23 23:13:43,078 - INFO - Epoch [71/200], Train Loss: 0.7501, Val Loss: 0.1904, Time: 2.78s, Batches: 440
2025-05-23 23:13:45,932 - INFO - Epoch [72/200], Train Loss: 0.7435, Val Loss: 0.2820, Time: 2.72s, Batches: 440
2025-05-23 23:13:48,627 - INFO - Epoch [73/200], Train Loss: 0.7253, Val Loss: 0.2137, Time: 2.58s, Batches: 440
2025-05-23 23:13:51,780 - INFO - Epoch [74/200], Train Loss: 0.7154, Val Loss: 0.2713, Time: 2.97s, Batches: 440
2025-05-23 23:13:55,073 - INFO - Epoch [75/200], Train Loss: 0.7065, Val Loss: 0.2308, Time: 3.13s, Batches: 440
2025-05-23 23:13:58,285 - INFO - Epoch [76/200], Train Loss: 0.6869, Val Loss: 0.2029, Time: 3.05s, Batches: 440
2025-05-23 23:14:01,512 - INFO - Epoch [77/200], Train Loss: 0.6560, Val Loss: 0.1952, Time: 3.04s, Batches: 440
2025-05-23 23:14:04,773 - INFO - Epoch [78/200], Train Loss: 0.6658, Val Loss: 0.1926, Time: 3.08s, Batches: 440
2025-05-23 23:14:07,870 - INFO - Epoch [79/200], Train Loss: 0.6798, Val Loss: 0.2075, Time: 2.95s, Batches: 440
2025-05-23 23:14:11,260 - INFO - Epoch [80/200], Train Loss: 0.6492, Val Loss: 0.1678, Time: 3.23s, Batches: 440
2025-05-23 23:14:14,574 - INFO - Epoch [81/200], Train Loss: 0.6466, Val Loss: 0.1641, Time: 3.11s, Batches: 440
2025-05-23 23:14:18,158 - INFO - Epoch [82/200], Train Loss: 0.6398, Val Loss: 0.3166, Time: 3.42s, Batches: 440
2025-05-23 23:14:21,333 - INFO - Epoch [83/200], Train Loss: 0.6522, Val Loss: 0.1833, Time: 3.02s, Batches: 440
2025-05-23 23:14:24,224 - INFO - Epoch [84/200], Train Loss: 0.6266, Val Loss: 0.1910, Time: 2.74s, Batches: 440
2025-05-23 23:14:27,170 - INFO - Epoch [85/200], Train Loss: 0.6096, Val Loss: 0.1576, Time: 2.80s, Batches: 440
2025-05-23 23:14:30,226 - INFO - Epoch [86/200], Train Loss: 0.6157, Val Loss: 0.1552, Time: 2.92s, Batches: 440
2025-05-23 23:14:32,999 - INFO - Epoch [87/200], Train Loss: 0.5884, Val Loss: 0.1466, Time: 2.63s, Batches: 440
2025-05-23 23:14:35,947 - INFO - Epoch [88/200], Train Loss: 0.5771, Val Loss: 0.1739, Time: 2.78s, Batches: 440
2025-05-23 23:14:38,675 - INFO - Epoch [89/200], Train Loss: 0.5969, Val Loss: 0.1969, Time: 2.61s, Batches: 440
2025-05-23 23:14:41,787 - INFO - Epoch [90/200], Train Loss: 0.5685, Val Loss: 0.1529, Time: 2.93s, Batches: 440
2025-05-23 23:14:44,819 - INFO - Epoch [91/200], Train Loss: 0.5600, Val Loss: 0.1412, Time: 2.88s, Batches: 440
2025-05-23 23:14:47,852 - INFO - Epoch [92/200], Train Loss: 0.5665, Val Loss: 0.1511, Time: 2.88s, Batches: 440
2025-05-23 23:14:50,948 - INFO - Epoch [93/200], Train Loss: 0.5490, Val Loss: 0.2020, Time: 2.95s, Batches: 440
2025-05-23 23:14:53,909 - INFO - Epoch [94/200], Train Loss: 0.5523, Val Loss: 0.1639, Time: 2.84s, Batches: 440
2025-05-23 23:14:57,053 - INFO - Epoch [95/200], Train Loss: 0.5485, Val Loss: 0.2002, Time: 2.99s, Batches: 440
2025-05-23 23:15:00,546 - INFO - Epoch [96/200], Train Loss: 0.5412, Val Loss: 0.1347, Time: 3.32s, Batches: 440
2025-05-23 23:15:03,873 - INFO - Epoch [97/200], Train Loss: 0.5341, Val Loss: 0.1281, Time: 3.15s, Batches: 440
2025-05-23 23:15:07,103 - INFO - Epoch [98/200], Train Loss: 0.5343, Val Loss: 0.1572, Time: 3.03s, Batches: 440
2025-05-23 23:15:10,305 - INFO - Epoch [99/200], Train Loss: 0.5517, Val Loss: 0.1587, Time: 3.06s, Batches: 440
2025-05-23 23:15:13,577 - INFO - Epoch [100/200], Train Loss: 0.5127, Val Loss: 0.1486, Time: 3.11s, Batches: 440
2025-05-23 23:15:16,921 - INFO - Epoch [101/200], Train Loss: 0.5094, Val Loss: 0.1372, Time: 3.13s, Batches: 440
2025-05-23 23:15:20,452 - INFO - Epoch [102/200], Train Loss: 0.5155, Val Loss: 0.1482, Time: 3.35s, Batches: 440
2025-05-23 23:15:23,908 - INFO - Epoch [103/200], Train Loss: 0.4974, Val Loss: 0.1368, Time: 3.29s, Batches: 440
2025-05-23 23:15:27,088 - INFO - Epoch [104/200], Train Loss: 0.4990, Val Loss: 0.1269, Time: 3.04s, Batches: 440
2025-05-23 23:15:30,140 - INFO - Epoch [105/200], Train Loss: 0.4972, Val Loss: 0.1595, Time: 2.90s, Batches: 440
2025-05-23 23:15:33,160 - INFO - Epoch [106/200], Train Loss: 0.5035, Val Loss: 0.1288, Time: 2.86s, Batches: 440
2025-05-23 23:15:36,243 - INFO - Epoch [107/200], Train Loss: 0.4976, Val Loss: 0.1230, Time: 2.93s, Batches: 440
2025-05-23 23:15:39,188 - INFO - Epoch [108/200], Train Loss: 0.4992, Val Loss: 0.1378, Time: 2.79s, Batches: 440
2025-05-23 23:15:42,172 - INFO - Epoch [109/200], Train Loss: 0.4869, Val Loss: 0.2114, Time: 2.85s, Batches: 440
2025-05-23 23:15:45,158 - INFO - Epoch [110/200], Train Loss: 0.4754, Val Loss: 0.1168, Time: 2.84s, Batches: 440
2025-05-23 23:15:48,137 - INFO - Epoch [111/200], Train Loss: 0.4747, Val Loss: 0.3768, Time: 2.80s, Batches: 440
2025-05-23 23:15:51,188 - INFO - Epoch [112/200], Train Loss: 0.4795, Val Loss: 0.1783, Time: 2.90s, Batches: 440
2025-05-23 23:15:54,174 - INFO - Epoch [113/200], Train Loss: 0.4753, Val Loss: 0.1112, Time: 2.82s, Batches: 440
2025-05-23 23:15:57,187 - INFO - Epoch [114/200], Train Loss: 0.4799, Val Loss: 0.1160, Time: 2.86s, Batches: 440
2025-05-23 23:16:00,214 - INFO - Epoch [115/200], Train Loss: 0.4639, Val Loss: 0.1242, Time: 2.87s, Batches: 440
2025-05-23 23:16:03,321 - INFO - Epoch [116/200], Train Loss: 0.4699, Val Loss: 0.1276, Time: 2.96s, Batches: 440
2025-05-23 23:16:06,767 - INFO - Epoch [117/200], Train Loss: 0.4734, Val Loss: 0.1128, Time: 3.25s, Batches: 440
2025-05-23 23:16:10,103 - INFO - Epoch [118/200], Train Loss: 0.4460, Val Loss: 0.2141, Time: 3.17s, Batches: 440
2025-05-23 23:16:13,278 - INFO - Epoch [119/200], Train Loss: 0.4555, Val Loss: 0.1083, Time: 2.99s, Batches: 440
2025-05-23 23:16:16,653 - INFO - Epoch [120/200], Train Loss: 0.4450, Val Loss: 0.1303, Time: 3.20s, Batches: 440
2025-05-23 23:16:20,137 - INFO - Epoch [121/200], Train Loss: 0.4440, Val Loss: 0.1231, Time: 3.30s, Batches: 440
2025-05-23 23:16:23,555 - INFO - Epoch [122/200], Train Loss: 0.4360, Val Loss: 0.1125, Time: 3.23s, Batches: 440
2025-05-23 23:16:27,423 - INFO - Epoch [123/200], Train Loss: 0.4295, Val Loss: 0.1972, Time: 3.64s, Batches: 440
2025-05-23 23:16:30,975 - INFO - Epoch [124/200], Train Loss: 0.4434, Val Loss: 0.1770, Time: 3.38s, Batches: 440
2025-05-23 23:16:34,124 - INFO - Epoch [125/200], Train Loss: 0.4165, Val Loss: 0.1131, Time: 2.98s, Batches: 440
2025-05-23 23:16:37,303 - INFO - Epoch [126/200], Train Loss: 0.4261, Val Loss: 0.1216, Time: 3.00s, Batches: 440
2025-05-23 23:16:40,486 - INFO - Epoch [127/200], Train Loss: 0.4152, Val Loss: 0.1315, Time: 3.04s, Batches: 440
2025-05-23 23:16:43,553 - INFO - Epoch [128/200], Train Loss: 0.4206, Val Loss: 0.1076, Time: 2.93s, Batches: 440
2025-05-23 23:16:46,654 - INFO - Epoch [129/200], Train Loss: 0.4276, Val Loss: 0.1060, Time: 2.94s, Batches: 440
2025-05-23 23:16:49,683 - INFO - Epoch [130/200], Train Loss: 0.4144, Val Loss: 0.1108, Time: 2.82s, Batches: 440
2025-05-23 23:16:52,652 - INFO - Epoch [131/200], Train Loss: 0.4274, Val Loss: 0.1019, Time: 2.79s, Batches: 440
2025-05-23 23:16:55,703 - INFO - Epoch [132/200], Train Loss: 0.4155, Val Loss: 0.1143, Time: 2.88s, Batches: 440
2025-05-23 23:16:58,886 - INFO - Epoch [133/200], Train Loss: 0.4171, Val Loss: 0.1050, Time: 3.00s, Batches: 440
2025-05-23 23:17:02,120 - INFO - Epoch [134/200], Train Loss: 0.3893, Val Loss: 0.1013, Time: 3.07s, Batches: 440
2025-05-23 23:17:05,162 - INFO - Epoch [135/200], Train Loss: 0.3966, Val Loss: 0.1274, Time: 2.88s, Batches: 440
2025-05-23 23:17:08,250 - INFO - Epoch [136/200], Train Loss: 0.4148, Val Loss: 0.1219, Time: 2.92s, Batches: 440
2025-05-23 23:17:11,747 - INFO - Epoch [137/200], Train Loss: 0.3999, Val Loss: 0.1075, Time: 3.30s, Batches: 440
2025-05-23 23:17:15,251 - INFO - Epoch [138/200], Train Loss: 0.4050, Val Loss: 0.1103, Time: 3.32s, Batches: 440
2025-05-23 23:17:18,456 - INFO - Epoch [139/200], Train Loss: 0.3939, Val Loss: 0.0969, Time: 3.04s, Batches: 440
2025-05-23 23:17:21,868 - INFO - Epoch [140/200], Train Loss: 0.3885, Val Loss: 0.1228, Time: 3.21s, Batches: 440
2025-05-23 23:17:25,305 - INFO - Epoch [141/200], Train Loss: 0.3985, Val Loss: 0.1086, Time: 3.27s, Batches: 440
2025-05-23 23:17:28,853 - INFO - Epoch [142/200], Train Loss: 0.4068, Val Loss: 0.0943, Time: 3.37s, Batches: 440
2025-05-23 23:17:32,619 - INFO - Epoch [143/200], Train Loss: 0.3874, Val Loss: 0.1055, Time: 3.53s, Batches: 440
2025-05-23 23:17:36,224 - INFO - Epoch [144/200], Train Loss: 0.3818, Val Loss: 0.1045, Time: 3.46s, Batches: 440
2025-05-23 23:17:39,231 - INFO - Epoch [145/200], Train Loss: 0.3895, Val Loss: 0.0946, Time: 2.85s, Batches: 440
2025-05-23 23:17:42,418 - INFO - Epoch [146/200], Train Loss: 0.3957, Val Loss: 0.0895, Time: 2.98s, Batches: 440
2025-05-23 23:17:45,770 - INFO - Epoch [147/200], Train Loss: 0.3877, Val Loss: 0.0841, Time: 3.15s, Batches: 440
2025-05-23 23:17:48,853 - INFO - Epoch [148/200], Train Loss: 0.3873, Val Loss: 0.2037, Time: 2.91s, Batches: 440
2025-05-23 23:17:51,905 - INFO - Epoch [149/200], Train Loss: 0.3718, Val Loss: 0.0879, Time: 2.89s, Batches: 440
2025-05-23 23:17:55,001 - INFO - Epoch [150/200], Train Loss: 0.3782, Val Loss: 0.0996, Time: 2.91s, Batches: 440
2025-05-23 23:17:58,004 - INFO - Epoch [151/200], Train Loss: 0.3851, Val Loss: 0.1473, Time: 2.85s, Batches: 440
2025-05-23 23:18:01,082 - INFO - Epoch [152/200], Train Loss: 0.3808, Val Loss: 0.1177, Time: 2.91s, Batches: 440
2025-05-23 23:18:04,234 - INFO - Epoch [153/200], Train Loss: 0.3675, Val Loss: 0.0818, Time: 2.99s, Batches: 440
2025-05-23 23:18:07,552 - INFO - Epoch [154/200], Train Loss: 0.3663, Val Loss: 0.0819, Time: 3.14s, Batches: 440
2025-05-23 23:18:10,571 - INFO - Epoch [155/200], Train Loss: 0.3763, Val Loss: 0.0899, Time: 2.88s, Batches: 440
2025-05-23 23:18:13,689 - INFO - Epoch [156/200], Train Loss: 0.3705, Val Loss: 0.1786, Time: 2.94s, Batches: 440
2025-05-23 23:18:17,177 - INFO - Epoch [157/200], Train Loss: 0.3710, Val Loss: 0.1032, Time: 3.32s, Batches: 440
2025-05-23 23:18:20,623 - INFO - Epoch [158/200], Train Loss: 0.3724, Val Loss: 0.1258, Time: 3.28s, Batches: 440
2025-05-23 23:18:23,818 - INFO - Epoch [159/200], Train Loss: 0.3683, Val Loss: 0.1074, Time: 3.07s, Batches: 440
2025-05-23 23:18:27,257 - INFO - Epoch [160/200], Train Loss: 0.3819, Val Loss: 0.0894, Time: 3.28s, Batches: 440
2025-05-23 23:18:30,652 - INFO - Epoch [161/200], Train Loss: 0.3519, Val Loss: 0.1503, Time: 3.23s, Batches: 440
2025-05-23 23:18:34,116 - INFO - Epoch [162/200], Train Loss: 0.3559, Val Loss: 0.0949, Time: 3.29s, Batches: 440
2025-05-23 23:18:37,901 - INFO - Epoch [163/200], Train Loss: 0.3616, Val Loss: 0.0786, Time: 3.58s, Batches: 440
2025-05-23 23:18:41,704 - INFO - Epoch [164/200], Train Loss: 0.3593, Val Loss: 0.0949, Time: 3.57s, Batches: 440
2025-05-23 23:18:44,796 - INFO - Epoch [165/200], Train Loss: 0.3477, Val Loss: 0.1547, Time: 2.95s, Batches: 440
2025-05-23 23:18:48,059 - INFO - Epoch [166/200], Train Loss: 0.3585, Val Loss: 0.0865, Time: 3.08s, Batches: 440
2025-05-23 23:18:51,546 - INFO - Epoch [167/200], Train Loss: 0.3447, Val Loss: 0.0802, Time: 3.30s, Batches: 440
2025-05-23 23:18:54,848 - INFO - Epoch [168/200], Train Loss: 0.3670, Val Loss: 0.0976, Time: 3.08s, Batches: 440
2025-05-23 23:18:58,102 - INFO - Epoch [169/200], Train Loss: 0.3704, Val Loss: 0.0901, Time: 3.09s, Batches: 440
2025-05-23 23:19:01,450 - INFO - Epoch [170/200], Train Loss: 0.3599, Val Loss: 0.0810, Time: 3.18s, Batches: 440
2025-05-23 23:19:04,637 - INFO - Epoch [171/200], Train Loss: 0.3476, Val Loss: 0.1070, Time: 3.01s, Batches: 440
2025-05-23 23:19:07,950 - INFO - Epoch [172/200], Train Loss: 0.3425, Val Loss: 0.1336, Time: 3.14s, Batches: 440
2025-05-23 23:19:11,350 - INFO - Epoch [173/200], Train Loss: 0.3507, Val Loss: 0.0664, Time: 3.19s, Batches: 440
2025-05-23 23:19:14,647 - INFO - Epoch [174/200], Train Loss: 0.3387, Val Loss: 0.0819, Time: 3.09s, Batches: 440
2025-05-23 23:19:17,983 - INFO - Epoch [175/200], Train Loss: 0.3277, Val Loss: 0.0834, Time: 3.17s, Batches: 440
2025-05-23 23:19:21,466 - INFO - Epoch [176/200], Train Loss: 0.3391, Val Loss: 0.0757, Time: 3.30s, Batches: 440
2025-05-23 23:19:25,191 - INFO - Epoch [177/200], Train Loss: 0.3369, Val Loss: 0.1648, Time: 3.51s, Batches: 440
2025-05-23 23:19:28,583 - INFO - Epoch [178/200], Train Loss: 0.3380, Val Loss: 0.0703, Time: 3.23s, Batches: 440
2025-05-23 23:19:32,012 - INFO - Epoch [179/200], Train Loss: 0.3447, Val Loss: 0.0848, Time: 3.23s, Batches: 440
2025-05-23 23:19:35,508 - INFO - Epoch [180/200], Train Loss: 0.3388, Val Loss: 0.1397, Time: 3.29s, Batches: 440
2025-05-23 23:19:38,904 - INFO - Epoch [181/200], Train Loss: 0.3405, Val Loss: 0.0784, Time: 3.22s, Batches: 440
2025-05-23 23:19:42,720 - INFO - Epoch [182/200], Train Loss: 0.3368, Val Loss: 0.1300, Time: 3.56s, Batches: 440
2025-05-23 23:19:46,602 - INFO - Epoch [183/200], Train Loss: 0.3363, Val Loss: 0.0766, Time: 3.61s, Batches: 440
2025-05-23 23:19:49,766 - INFO - Epoch [184/200], Train Loss: 0.3273, Val Loss: 0.0764, Time: 2.98s, Batches: 440
2025-05-23 23:19:52,824 - INFO - Epoch [185/200], Train Loss: 0.3446, Val Loss: 0.0711, Time: 2.90s, Batches: 440
2025-05-23 23:19:56,082 - INFO - Epoch [186/200], Train Loss: 0.3383, Val Loss: 0.1059, Time: 3.07s, Batches: 440
2025-05-23 23:19:59,251 - INFO - Epoch [187/200], Train Loss: 0.3173, Val Loss: 0.0768, Time: 3.03s, Batches: 440
2025-05-23 23:20:02,505 - INFO - Epoch [188/200], Train Loss: 0.3319, Val Loss: 0.0791, Time: 3.05s, Batches: 440
2025-05-23 23:20:13,548 - INFO - Optimized LSTM MSE: 0.0896, R2: 0.9990
2025-05-23 23:23:53,127 - INFO - Mô hình LSTM \u0111ã \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i: D:/BaiDoAnChuyenNganh3/NLPResumeRankingAutomatedSystem/model/lstm_model.pth
2025-05-23 23:25:20,446 - INFO - B\u1eaft \u0111\u1ea7u hu\u1ea5n luy\u1ec7n mô hình Transformer v\u1edbi early stopping...
2025-05-23 23:26:10,517 - INFO - Epoch [1/100], Train Loss: 523.8905, Val Loss: 59.2852, Time: 48.35s, Batches: 3519
2025-05-23 23:27:03,624 - INFO - Epoch [2/100], Train Loss: 26.0069, Val Loss: 9.0480, Time: 51.40s, Batches: 3519
2025-05-23 23:27:57,689 - INFO - Epoch [3/100], Train Loss: 6.7798, Val Loss: 3.4393, Time: 52.22s, Batches: 3519
2025-05-23 23:28:47,412 - INFO - Epoch [4/100], Train Loss: 4.0008, Val Loss: 10.1351, Time: 48.21s, Batches: 3519
2025-05-23 23:29:33,833 - INFO - Epoch [5/100], Train Loss: 3.0819, Val Loss: 1.5655, Time: 45.08s, Batches: 3519
2025-05-23 23:30:12,283 - INFO - Epoch [6/100], Train Loss: 2.3168, Val Loss: 1.5964, Time: 37.42s, Batches: 3519
2025-05-23 23:30:53,120 - INFO - Epoch [7/100], Train Loss: 2.0563, Val Loss: 2.2580, Time: 39.59s, Batches: 3519
2025-05-23 23:31:31,518 - INFO - Epoch [8/100], Train Loss: 1.7575, Val Loss: 1.3590, Time: 37.00s, Batches: 3519
2025-05-23 23:32:15,437 - INFO - Epoch [9/100], Train Loss: 1.5125, Val Loss: 0.7490, Time: 42.29s, Batches: 3519
2025-05-23 23:32:59,840 - INFO - Epoch [10/100], Train Loss: 1.4457, Val Loss: 0.8379, Time: 43.26s, Batches: 3519
2025-05-23 23:33:47,812 - INFO - Epoch [11/100], Train Loss: 1.2531, Val Loss: 0.7246, Time: 46.54s, Batches: 3519
2025-05-23 23:34:31,919 - INFO - Epoch [12/100], Train Loss: 1.1645, Val Loss: 0.9652, Time: 42.79s, Batches: 3519
2025-05-23 23:35:15,377 - INFO - Epoch [13/100], Train Loss: 0.9961, Val Loss: 0.5036, Time: 42.37s, Batches: 3519
2025-05-23 23:35:53,748 - INFO - Epoch [14/100], Train Loss: 0.8796, Val Loss: 0.7976, Time: 37.20s, Batches: 3519
2025-05-23 23:36:36,227 - INFO - Epoch [15/100], Train Loss: 0.8542, Val Loss: 0.5275, Time: 41.26s, Batches: 3519
2025-05-23 23:37:17,610 - INFO - Epoch [16/100], Train Loss: 0.8010, Val Loss: 0.6263, Time: 39.75s, Batches: 3519
2025-05-23 23:37:56,637 - INFO - Epoch [17/100], Train Loss: 0.7430, Val Loss: 0.5133, Time: 37.85s, Batches: 3519
2025-05-23 23:38:39,642 - INFO - Epoch [18/100], Train Loss: 0.6545, Val Loss: 0.4673, Time: 41.84s, Batches: 3519
2025-05-23 23:39:18,108 - INFO - Epoch [19/100], Train Loss: 0.6553, Val Loss: 0.4045, Time: 37.27s, Batches: 3519
2025-05-23 23:39:57,123 - INFO - Epoch [20/100], Train Loss: 0.6023, Val Loss: 0.3139, Time: 37.86s, Batches: 3519
2025-05-23 23:40:37,270 - INFO - Epoch [21/100], Train Loss: 0.5550, Val Loss: 0.3389, Time: 38.71s, Batches: 3519
2025-05-23 23:41:15,950 - INFO - Epoch [22/100], Train Loss: 0.5455, Val Loss: 0.5258, Time: 37.62s, Batches: 3519
2025-05-23 23:41:58,188 - INFO - Epoch [23/100], Train Loss: 0.4788, Val Loss: 1.4514, Time: 41.10s, Batches: 3519
2025-05-23 23:42:37,504 - INFO - Epoch [24/100], Train Loss: 0.4902, Val Loss: 0.4337, Time: 38.15s, Batches: 3519
2025-05-23 23:43:19,737 - INFO - Epoch [25/100], Train Loss: 0.4867, Val Loss: 0.3394, Time: 41.03s, Batches: 3519
2025-05-23 23:44:02,702 - INFO - Epoch [26/100], Train Loss: 0.4393, Val Loss: 0.2635, Time: 41.88s, Batches: 3519
2025-05-23 23:44:42,551 - INFO - Epoch [27/100], Train Loss: 0.4248, Val Loss: 0.3043, Time: 38.52s, Batches: 3519
2025-05-23 23:45:24,069 - INFO - Epoch [28/100], Train Loss: 0.3923, Val Loss: 0.6052, Time: 40.38s, Batches: 3519
2025-05-23 23:46:04,766 - INFO - Epoch [29/100], Train Loss: 0.4177, Val Loss: 0.2384, Time: 39.27s, Batches: 3519
2025-05-23 23:46:45,749 - INFO - Epoch [30/100], Train Loss: 0.3833, Val Loss: 0.2601, Time: 39.93s, Batches: 3519
2025-05-23 23:47:28,830 - INFO - Epoch [31/100], Train Loss: 0.3749, Val Loss: 0.2756, Time: 41.77s, Batches: 3519
2025-05-23 23:48:11,164 - INFO - Epoch [32/100], Train Loss: 0.3444, Val Loss: 0.3081, Time: 41.03s, Batches: 3519
2025-05-23 23:48:52,263 - INFO - Epoch [33/100], Train Loss: 0.3311, Val Loss: 0.2597, Time: 39.89s, Batches: 3519
2025-05-23 23:49:34,579 - INFO - Epoch [34/100], Train Loss: 0.3381, Val Loss: 0.2546, Time: 41.13s, Batches: 3519
2025-05-23 23:50:19,024 - INFO - Epoch [35/100], Train Loss: 0.3241, Val Loss: 0.3071, Time: 43.01s, Batches: 3519
2025-05-23 23:51:03,370 - INFO - Epoch [36/100], Train Loss: 0.3032, Val Loss: 0.3330, Time: 43.02s, Batches: 3519
2025-05-23 23:51:47,208 - INFO - Epoch [37/100], Train Loss: 0.2988, Val Loss: 0.2448, Time: 42.53s, Batches: 3519
2025-05-23 23:52:28,008 - INFO - Epoch [38/100], Train Loss: 0.3020, Val Loss: 0.2363, Time: 39.57s, Batches: 3519
2025-05-23 23:53:10,924 - INFO - Epoch [39/100], Train Loss: 0.2908, Val Loss: 0.2303, Time: 41.85s, Batches: 3519
2025-05-23 23:54:03,108 - INFO - Epoch [40/100], Train Loss: 0.2747, Val Loss: 0.2855, Time: 51.14s, Batches: 3519
2025-05-23 23:54:53,355 - INFO - Epoch [41/100], Train Loss: 0.2894, Val Loss: 0.1977, Time: 49.02s, Batches: 3519
2025-05-23 23:55:43,187 - INFO - Epoch [42/100], Train Loss: 0.2701, Val Loss: 0.3602, Time: 48.64s, Batches: 3519
2025-05-23 23:56:34,341 - INFO - Epoch [43/100], Train Loss: 0.2655, Val Loss: 0.2580, Time: 49.94s, Batches: 3519
2025-05-23 23:57:27,324 - INFO - Epoch [44/100], Train Loss: 0.2622, Val Loss: 0.2784, Time: 51.82s, Batches: 3519
2025-05-23 23:58:19,420 - INFO - Epoch [45/100], Train Loss: 0.2388, Val Loss: 0.1637, Time: 50.83s, Batches: 3519
2025-05-23 23:59:15,950 - INFO - Epoch [46/100], Train Loss: 0.2702, Val Loss: 0.1634, Time: 55.25s, Batches: 3519
2025-05-24 00:00:11,249 - INFO - Epoch [47/100], Train Loss: 0.2448, Val Loss: 0.1754, Time: 53.63s, Batches: 3519
2025-05-24 00:01:10,031 - INFO - Epoch [48/100], Train Loss: 0.2271, Val Loss: 0.1845, Time: 57.42s, Batches: 3519
2025-05-24 00:02:05,580 - INFO - Epoch [49/100], Train Loss: 0.2279, Val Loss: 0.3423, Time: 54.36s, Batches: 3519
2025-05-24 00:03:03,895 - INFO - Epoch [50/100], Train Loss: 0.2442, Val Loss: 0.1237, Time: 57.09s, Batches: 3519
2025-05-24 00:04:00,794 - INFO - Epoch [51/100], Train Loss: 0.2250, Val Loss: 0.1817, Time: 55.77s, Batches: 3519
2025-05-24 00:04:55,076 - INFO - Epoch [52/100], Train Loss: 0.2071, Val Loss: 0.2754, Time: 52.75s, Batches: 3519
2025-05-24 00:05:45,545 - INFO - Epoch [53/100], Train Loss: 0.2135, Val Loss: 0.2395, Time: 49.27s, Batches: 3519
2025-05-24 00:06:41,445 - INFO - Epoch [54/100], Train Loss: 0.2063, Val Loss: 0.3713, Time: 54.54s, Batches: 3519
2025-05-24 00:07:38,645 - INFO - Epoch [55/100], Train Loss: 0.2060, Val Loss: 0.1719, Time: 55.81s, Batches: 3519
2025-05-24 00:08:36,955 - INFO - Epoch [56/100], Train Loss: 0.2055, Val Loss: 0.1995, Time: 57.14s, Batches: 3519
2025-05-24 00:09:36,720 - INFO - Epoch [57/100], Train Loss: 0.1962, Val Loss: 0.1141, Time: 58.53s, Batches: 3519
2025-05-24 00:10:39,073 - INFO - Epoch [58/100], Train Loss: 0.1893, Val Loss: 0.1520, Time: 61.07s, Batches: 3519
2025-05-24 00:11:43,035 - INFO - Epoch [59/100], Train Loss: 0.1935, Val Loss: 0.1538, Time: 62.95s, Batches: 3519
2025-05-24 00:12:47,749 - INFO - Epoch [60/100], Train Loss: 0.1855, Val Loss: 0.2303, Time: 63.48s, Batches: 3519
2025-05-24 00:13:58,437 - INFO - Epoch [61/100], Train Loss: 0.1847, Val Loss: 0.1424, Time: 69.58s, Batches: 3519
2025-05-24 00:15:04,805 - INFO - Epoch [62/100], Train Loss: 0.1854, Val Loss: 0.1332, Time: 65.15s, Batches: 3519
2025-05-24 00:16:04,512 - INFO - Epoch [63/100], Train Loss: 0.1764, Val Loss: 0.1420, Time: 58.38s, Batches: 3519
2025-05-24 00:17:10,611 - INFO - Epoch [64/100], Train Loss: 0.1734, Val Loss: 0.2924, Time: 64.75s, Batches: 3519
2025-05-24 00:18:07,694 - INFO - Epoch [65/100], Train Loss: 0.1670, Val Loss: 0.1784, Time: 55.59s, Batches: 3519
2025-05-24 00:19:08,492 - INFO - Epoch [66/100], Train Loss: 0.1696, Val Loss: 0.3408, Time: 59.53s, Batches: 3519
2025-05-24 00:20:10,739 - INFO - Epoch [67/100], Train Loss: 0.1524, Val Loss: 0.1280, Time: 61.04s, Batches: 3519
2025-05-24 00:21:11,622 - INFO - Epoch [68/100], Train Loss: 0.1632, Val Loss: 0.1459, Time: 59.41s, Batches: 3519
2025-05-24 00:22:17,404 - INFO - Epoch [69/100], Train Loss: 0.1692, Val Loss: 0.1081, Time: 64.25s, Batches: 3519
2025-05-24 00:23:22,517 - INFO - Epoch [70/100], Train Loss: 0.1605, Val Loss: 0.1780, Time: 63.80s, Batches: 3519
2025-05-24 00:24:08,002 - INFO - Epoch [71/100], Train Loss: 0.1453, Val Loss: 0.2863, Time: 44.10s, Batches: 3519
2025-05-24 00:24:58,349 - INFO - Epoch [72/100], Train Loss: 0.1613, Val Loss: 0.2093, Time: 48.98s, Batches: 3519
2025-05-24 00:26:10,200 - INFO - Epoch [73/100], Train Loss: 0.1519, Val Loss: 0.1316, Time: 70.34s, Batches: 3519
2025-05-24 00:27:25,836 - INFO - Epoch [74/100], Train Loss: 0.1405, Val Loss: 0.1073, Time: 73.97s, Batches: 3519
2025-05-24 00:28:42,713 - INFO - Epoch [75/100], Train Loss: 0.1533, Val Loss: 0.1185, Time: 75.30s, Batches: 3519
2025-05-24 00:29:57,416 - INFO - Epoch [76/100], Train Loss: 0.1411, Val Loss: 0.1756, Time: 73.25s, Batches: 3519
2025-05-24 00:31:08,427 - INFO - Epoch [77/100], Train Loss: 0.1365, Val Loss: 0.1135, Time: 69.62s, Batches: 3519
2025-05-24 00:32:21,610 - INFO - Epoch [78/100], Train Loss: 0.1490, Val Loss: 0.3016, Time: 71.66s, Batches: 3519
2025-05-24 00:33:36,468 - INFO - Epoch [79/100], Train Loss: 0.1371, Val Loss: 0.1923, Time: 73.38s, Batches: 3519
2025-05-24 00:34:49,589 - INFO - Epoch [80/100], Train Loss: 0.1392, Val Loss: 0.1296, Time: 71.82s, Batches: 3519
2025-05-24 00:36:01,908 - INFO - Epoch [81/100], Train Loss: 0.1315, Val Loss: 0.1013, Time: 70.89s, Batches: 3519
2025-05-24 00:37:17,335 - INFO - Epoch [82/100], Train Loss: 0.1291, Val Loss: 0.0991, Time: 73.77s, Batches: 3519
2025-05-24 00:38:32,884 - INFO - Epoch [83/100], Train Loss: 0.1297, Val Loss: 0.3921, Time: 74.13s, Batches: 3519
2025-05-24 00:39:44,950 - INFO - Epoch [84/100], Train Loss: 0.1310, Val Loss: 0.1684, Time: 70.49s, Batches: 3519
2025-05-24 00:40:59,081 - INFO - Epoch [85/100], Train Loss: 0.1224, Val Loss: 0.0917, Time: 72.73s, Batches: 3519
2025-05-24 00:42:13,796 - INFO - Epoch [86/100], Train Loss: 0.1355, Val Loss: 0.1204, Time: 73.32s, Batches: 3519
2025-05-24 00:43:30,545 - INFO - Epoch [87/100], Train Loss: 0.1213, Val Loss: 0.2932, Time: 75.38s, Batches: 3519
2025-05-24 00:44:45,226 - INFO - Epoch [88/100], Train Loss: 0.1283, Val Loss: 0.2484, Time: 73.45s, Batches: 3519
2025-05-24 00:45:42,829 - INFO - Epoch [89/100], Train Loss: 0.1268, Val Loss: 0.0831, Time: 55.99s, Batches: 3519
2025-05-24 00:47:04,759 - INFO - Epoch [90/100], Train Loss: 0.1157, Val Loss: 0.1288, Time: 80.47s, Batches: 3519
2025-05-24 00:48:30,415 - INFO - Epoch [91/100], Train Loss: 0.1157, Val Loss: 0.1253, Time: 83.97s, Batches: 3519
2025-05-24 00:49:57,961 - INFO - Epoch [92/100], Train Loss: 0.1198, Val Loss: 0.0879, Time: 85.78s, Batches: 3519
2025-05-24 00:51:18,828 - INFO - Epoch [93/100], Train Loss: 0.1290, Val Loss: 0.2854, Time: 79.47s, Batches: 3519
2025-05-24 00:52:41,237 - INFO - Epoch [94/100], Train Loss: 0.1159, Val Loss: 0.1518, Time: 80.72s, Batches: 3519
2025-05-24 00:54:04,568 - INFO - Epoch [95/100], Train Loss: 0.1091, Val Loss: 0.0923, Time: 81.59s, Batches: 3519
2025-05-24 00:55:29,901 - INFO - Epoch [96/100], Train Loss: 0.1173, Val Loss: 0.0957, Time: 83.98s, Batches: 3519
2025-05-24 00:56:53,086 - INFO - Epoch [97/100], Train Loss: 0.1132, Val Loss: 0.1962, Time: 81.88s, Batches: 3519
2025-05-24 00:58:17,082 - INFO - Epoch [98/100], Train Loss: 0.1080, Val Loss: 0.0926, Time: 82.51s, Batches: 3519
2025-05-24 00:59:28,697 - INFO - Epoch [99/100], Train Loss: 0.1110, Val Loss: 0.1200, Time: 69.79s, Batches: 3519
2025-05-24 01:00:24,362 - INFO - Epoch [100/100], Train Loss: 0.1169, Val Loss: 0.0924, Time: 54.27s, Batches: 3519
2025-05-24 01:01:47,533 - INFO - Transformer MSE: 0.0828, R2: 0.9991
2025-05-24 01:12:01,624 - INFO - Transformer MSE: 0.0828, R2: 0.9991
2025-05-24 01:12:42,133 - INFO - Mô hình TRANSFORMER \u0111ã \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i: D:/BaiDoAnChuyenNganh3/NLPResumeRankingAutomatedSystem/model/transformer_model.pth
2025-05-24 01:38:08,596 - INFO - Mô hình MLP + LSTM \u0111ã \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i: D:/BaiDoAnChuyenNganh3/NLPResumeRankingAutomatedSystem/model/mlp_lstm_model.pth
2025-05-24 02:47:42,511 - INFO - Mô hình RANDOM FOREST + XGBOOST + TRANSFORMER \u0111ã \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i: D:/BaiDoAnChuyenNganh3/NLPResumeRankingAutomatedSystem/model/rf_xgb_transformer_model.pth
2025-05-25 14:30:26,651 - INFO - Use pytorch device_name: cuda:0
2025-05-25 14:30:26,652 - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
2025-05-25 14:30:33,635 - INFO - Loaded SentenceTransformer model: all-mpnet-base-v2
2025-05-25 15:15:21,899 - INFO - B\u1eaft \u0111\u1ea7u hu\u1ea5n luy\u1ec7n mô hình MLP v\u1edbi early stopping...
2025-05-25 15:15:23,738 - INFO - Epoch [1/150], Train Loss: 886.4796, Val Loss: 55.6968, Time: 1.79s, Batches: 220
2025-05-25 15:15:24,958 - INFO - Epoch [2/150], Train Loss: 52.9108, Val Loss: 40.7137, Time: 1.14s, Batches: 220
2025-05-25 15:15:25,968 - INFO - Epoch [3/150], Train Loss: 40.8197, Val Loss: 31.4678, Time: 0.94s, Batches: 220
2025-05-25 15:15:26,963 - INFO - Epoch [4/150], Train Loss: 34.1800, Val Loss: 25.7968, Time: 0.93s, Batches: 220
2025-05-25 15:15:27,974 - INFO - Epoch [5/150], Train Loss: 29.1992, Val Loss: 21.7078, Time: 0.95s, Batches: 220
2025-05-25 15:15:28,985 - INFO - Epoch [6/150], Train Loss: 25.6480, Val Loss: 18.5384, Time: 0.96s, Batches: 220
2025-05-25 15:15:30,140 - INFO - Epoch [7/150], Train Loss: 22.4791, Val Loss: 16.0617, Time: 1.10s, Batches: 220
2025-05-25 15:15:31,153 - INFO - Epoch [8/150], Train Loss: 20.6019, Val Loss: 14.3165, Time: 0.96s, Batches: 220
2025-05-25 15:15:32,218 - INFO - Epoch [9/150], Train Loss: 18.8502, Val Loss: 12.6520, Time: 1.00s, Batches: 220
2025-05-25 15:15:33,176 - INFO - Epoch [10/150], Train Loss: 17.3064, Val Loss: 12.0173, Time: 0.91s, Batches: 220
2025-05-25 15:15:34,170 - INFO - Epoch [11/150], Train Loss: 16.0252, Val Loss: 10.2850, Time: 0.93s, Batches: 220
2025-05-25 15:15:35,282 - INFO - Epoch [12/150], Train Loss: 14.7397, Val Loss: 9.0158, Time: 1.06s, Batches: 220
2025-05-25 15:15:36,246 - INFO - Epoch [13/150], Train Loss: 13.7752, Val Loss: 8.0914, Time: 0.91s, Batches: 220
2025-05-25 15:15:37,219 - INFO - Epoch [14/150], Train Loss: 12.3741, Val Loss: 7.0878, Time: 0.92s, Batches: 220
2025-05-25 15:15:38,196 - INFO - Epoch [15/150], Train Loss: 11.6913, Val Loss: 6.2732, Time: 0.92s, Batches: 220
2025-05-25 15:15:39,187 - INFO - Epoch [16/150], Train Loss: 10.9777, Val Loss: 5.4619, Time: 0.94s, Batches: 220
2025-05-25 15:15:40,294 - INFO - Epoch [17/150], Train Loss: 10.1601, Val Loss: 5.3975, Time: 1.05s, Batches: 220
2025-05-25 15:15:41,291 - INFO - Epoch [18/150], Train Loss: 9.7539, Val Loss: 4.3633, Time: 0.94s, Batches: 220
2025-05-25 15:15:42,264 - INFO - Epoch [19/150], Train Loss: 9.1914, Val Loss: 4.0006, Time: 0.92s, Batches: 220
2025-05-25 15:15:43,241 - INFO - Epoch [20/150], Train Loss: 8.6708, Val Loss: 3.5467, Time: 0.92s, Batches: 220
2025-05-25 15:15:44,247 - INFO - Epoch [21/150], Train Loss: 8.2903, Val Loss: 3.2489, Time: 0.95s, Batches: 220
2025-05-25 15:15:45,363 - INFO - Epoch [22/150], Train Loss: 7.7863, Val Loss: 2.7541, Time: 1.06s, Batches: 220
2025-05-25 15:15:46,375 - INFO - Epoch [23/150], Train Loss: 7.6093, Val Loss: 2.6404, Time: 0.96s, Batches: 220
2025-05-25 15:15:47,355 - INFO - Epoch [24/150], Train Loss: 7.1716, Val Loss: 2.2454, Time: 0.93s, Batches: 220
2025-05-25 15:15:48,347 - INFO - Epoch [25/150], Train Loss: 7.1445, Val Loss: 2.7594, Time: 0.94s, Batches: 220
2025-05-25 15:15:49,342 - INFO - Epoch [26/150], Train Loss: 6.9946, Val Loss: 1.9421, Time: 0.95s, Batches: 220
2025-05-25 15:15:50,492 - INFO - Epoch [27/150], Train Loss: 6.6812, Val Loss: 2.0423, Time: 1.09s, Batches: 220
2025-05-25 15:15:51,460 - INFO - Epoch [28/150], Train Loss: 6.5472, Val Loss: 1.9160, Time: 0.92s, Batches: 220
2025-05-25 15:15:52,450 - INFO - Epoch [29/150], Train Loss: 6.4641, Val Loss: 1.5027, Time: 0.94s, Batches: 220
2025-05-25 15:15:53,469 - INFO - Epoch [30/150], Train Loss: 6.3538, Val Loss: 1.7425, Time: 0.96s, Batches: 220
2025-05-25 15:15:54,492 - INFO - Epoch [31/150], Train Loss: 6.2665, Val Loss: 1.9503, Time: 0.96s, Batches: 220
2025-05-25 15:15:55,739 - INFO - Epoch [32/150], Train Loss: 6.0331, Val Loss: 1.2897, Time: 1.20s, Batches: 220
2025-05-25 15:15:56,844 - INFO - Epoch [33/150], Train Loss: 5.9142, Val Loss: 1.1220, Time: 1.05s, Batches: 220
2025-05-25 15:15:57,955 - INFO - Epoch [34/150], Train Loss: 5.9103, Val Loss: 1.0731, Time: 1.05s, Batches: 220
2025-05-25 15:15:59,022 - INFO - Epoch [35/150], Train Loss: 5.6591, Val Loss: 0.9935, Time: 1.01s, Batches: 220
2025-05-25 15:16:00,314 - INFO - Epoch [36/150], Train Loss: 5.7344, Val Loss: 1.0503, Time: 1.21s, Batches: 220
2025-05-25 15:16:01,332 - INFO - Epoch [37/150], Train Loss: 5.6188, Val Loss: 1.6773, Time: 0.97s, Batches: 220
2025-05-25 15:16:02,360 - INFO - Epoch [38/150], Train Loss: 5.5414, Val Loss: 1.1843, Time: 0.98s, Batches: 220
2025-05-25 15:16:03,379 - INFO - Epoch [39/150], Train Loss: 5.4732, Val Loss: 1.0150, Time: 0.97s, Batches: 220
2025-05-25 15:16:04,429 - INFO - Epoch [40/150], Train Loss: 5.5421, Val Loss: 0.8539, Time: 0.99s, Batches: 220
2025-05-25 15:16:05,637 - INFO - Epoch [41/150], Train Loss: 5.3354, Val Loss: 0.7187, Time: 1.15s, Batches: 220
2025-05-25 15:16:06,693 - INFO - Epoch [42/150], Train Loss: 5.3706, Val Loss: 0.8490, Time: 1.00s, Batches: 220
2025-05-25 15:16:07,710 - INFO - Epoch [43/150], Train Loss: 5.2006, Val Loss: 0.6757, Time: 0.97s, Batches: 220
2025-05-25 15:16:08,770 - INFO - Epoch [44/150], Train Loss: 5.1200, Val Loss: 0.7866, Time: 1.00s, Batches: 220
2025-05-25 15:16:09,967 - INFO - Epoch [45/150], Train Loss: 5.2723, Val Loss: 0.7667, Time: 1.14s, Batches: 220
2025-05-25 15:16:11,048 - INFO - Epoch [46/150], Train Loss: 5.0239, Val Loss: 0.5964, Time: 1.03s, Batches: 220
2025-05-25 15:16:12,065 - INFO - Epoch [47/150], Train Loss: 4.9030, Val Loss: 0.8401, Time: 0.96s, Batches: 220
2025-05-25 15:16:13,085 - INFO - Epoch [48/150], Train Loss: 4.9778, Val Loss: 0.5958, Time: 0.97s, Batches: 220
2025-05-25 15:16:14,098 - INFO - Epoch [49/150], Train Loss: 4.9779, Val Loss: 0.6852, Time: 0.95s, Batches: 220
2025-05-25 15:16:15,276 - INFO - Epoch [50/150], Train Loss: 4.8183, Val Loss: 1.0804, Time: 1.13s, Batches: 220
2025-05-25 15:16:16,279 - INFO - Epoch [51/150], Train Loss: 4.8292, Val Loss: 0.4081, Time: 0.95s, Batches: 220
2025-05-25 15:16:17,300 - INFO - Epoch [52/150], Train Loss: 4.7899, Val Loss: 0.4579, Time: 0.96s, Batches: 220
2025-05-25 15:16:18,360 - INFO - Epoch [53/150], Train Loss: 4.8292, Val Loss: 0.4496, Time: 1.01s, Batches: 220
2025-05-25 15:16:19,366 - INFO - Epoch [54/150], Train Loss: 4.7985, Val Loss: 0.4004, Time: 0.96s, Batches: 220
2025-05-25 15:16:20,528 - INFO - Epoch [55/150], Train Loss: 4.7300, Val Loss: 0.8633, Time: 1.11s, Batches: 220
2025-05-25 15:16:21,580 - INFO - Epoch [56/150], Train Loss: 4.6373, Val Loss: 0.4591, Time: 1.00s, Batches: 220
2025-05-25 15:16:22,603 - INFO - Epoch [57/150], Train Loss: 4.7358, Val Loss: 1.0901, Time: 0.98s, Batches: 220
2025-05-25 15:16:23,613 - INFO - Epoch [58/150], Train Loss: 4.9105, Val Loss: 0.9416, Time: 0.96s, Batches: 220
2025-05-25 15:16:24,751 - INFO - Epoch [59/150], Train Loss: 4.5050, Val Loss: 0.3519, Time: 1.08s, Batches: 220
2025-05-25 15:16:25,809 - INFO - Epoch [60/150], Train Loss: 4.5895, Val Loss: 0.5334, Time: 1.00s, Batches: 220
2025-05-25 15:16:26,847 - INFO - Epoch [61/150], Train Loss: 4.5777, Val Loss: 0.3903, Time: 0.99s, Batches: 220
2025-05-25 15:16:27,902 - INFO - Epoch [62/150], Train Loss: 4.6155, Val Loss: 0.3417, Time: 1.01s, Batches: 220
2025-05-25 15:16:28,939 - INFO - Epoch [63/150], Train Loss: 4.4422, Val Loss: 0.3240, Time: 0.98s, Batches: 220
2025-05-25 15:16:30,128 - INFO - Epoch [64/150], Train Loss: 4.3952, Val Loss: 0.3931, Time: 1.13s, Batches: 220
2025-05-25 15:16:31,228 - INFO - Epoch [65/150], Train Loss: 4.3987, Val Loss: 0.7901, Time: 1.05s, Batches: 220
2025-05-25 15:16:32,251 - INFO - Epoch [66/150], Train Loss: 4.5149, Val Loss: 0.7951, Time: 0.97s, Batches: 220
2025-05-25 15:16:33,272 - INFO - Epoch [67/150], Train Loss: 4.4362, Val Loss: 0.5176, Time: 0.97s, Batches: 220
2025-05-25 15:16:34,354 - INFO - Epoch [68/150], Train Loss: 4.4985, Val Loss: 0.2596, Time: 1.04s, Batches: 220
2025-05-25 15:16:35,537 - INFO - Epoch [69/150], Train Loss: 4.3324, Val Loss: 0.4254, Time: 1.13s, Batches: 220
2025-05-25 15:16:36,775 - INFO - Epoch [70/150], Train Loss: 4.4889, Val Loss: 0.7741, Time: 1.17s, Batches: 220
2025-05-25 15:16:38,380 - INFO - Epoch [71/150], Train Loss: 4.3342, Val Loss: 0.2889, Time: 1.53s, Batches: 220
2025-05-25 15:16:40,045 - INFO - Epoch [72/150], Train Loss: 4.3332, Val Loss: 0.2738, Time: 1.60s, Batches: 220
2025-05-25 15:16:41,589 - INFO - Epoch [73/150], Train Loss: 4.2326, Val Loss: 0.3298, Time: 1.47s, Batches: 220
2025-05-25 15:16:42,966 - INFO - Epoch [74/150], Train Loss: 4.2113, Val Loss: 0.2209, Time: 1.32s, Batches: 220
2025-05-25 15:16:44,258 - INFO - Epoch [75/150], Train Loss: 4.2482, Val Loss: 0.2183, Time: 1.23s, Batches: 220
2025-05-25 15:16:45,653 - INFO - Epoch [76/150], Train Loss: 4.4384, Val Loss: 0.3221, Time: 1.33s, Batches: 220
2025-05-25 15:16:46,902 - INFO - Epoch [77/150], Train Loss: 4.1451, Val Loss: 0.2422, Time: 1.19s, Batches: 220
2025-05-25 15:16:48,155 - INFO - Epoch [78/150], Train Loss: 4.1414, Val Loss: 0.5310, Time: 1.19s, Batches: 220
2025-05-25 15:16:49,372 - INFO - Epoch [79/150], Train Loss: 4.1755, Val Loss: 0.3218, Time: 1.16s, Batches: 220
2025-05-25 15:16:50,805 - INFO - Epoch [80/150], Train Loss: 4.2625, Val Loss: 0.3597, Time: 1.38s, Batches: 220
2025-05-25 15:16:52,016 - INFO - Epoch [81/150], Train Loss: 4.0509, Val Loss: 0.3028, Time: 1.16s, Batches: 220
2025-05-25 15:16:53,198 - INFO - Epoch [82/150], Train Loss: 4.2583, Val Loss: 1.0269, Time: 1.13s, Batches: 220
2025-05-25 15:16:54,598 - INFO - Epoch [83/150], Train Loss: 4.0549, Val Loss: 0.2064, Time: 1.34s, Batches: 220
2025-05-25 15:16:56,030 - INFO - Epoch [84/150], Train Loss: 4.0745, Val Loss: 0.3014, Time: 1.36s, Batches: 220
2025-05-25 15:16:57,457 - INFO - Epoch [85/150], Train Loss: 4.0772, Val Loss: 0.1594, Time: 1.36s, Batches: 220
2025-05-25 15:16:58,991 - INFO - Epoch [86/150], Train Loss: 3.9901, Val Loss: 0.2964, Time: 1.46s, Batches: 220
2025-05-25 15:17:00,398 - INFO - Epoch [87/150], Train Loss: 4.0551, Val Loss: 0.5060, Time: 1.36s, Batches: 220
2025-05-25 15:17:01,513 - INFO - Epoch [88/150], Train Loss: 4.1990, Val Loss: 0.2442, Time: 1.06s, Batches: 220
2025-05-25 15:17:02,765 - INFO - Epoch [89/150], Train Loss: 3.9762, Val Loss: 0.3159, Time: 1.19s, Batches: 220
2025-05-25 15:17:03,968 - INFO - Epoch [90/150], Train Loss: 3.9817, Val Loss: 0.2208, Time: 1.15s, Batches: 220
2025-05-25 15:17:05,364 - INFO - Epoch [91/150], Train Loss: 3.9250, Val Loss: 0.2202, Time: 1.34s, Batches: 220
2025-05-25 15:17:06,537 - INFO - Epoch [92/150], Train Loss: 4.0222, Val Loss: 0.3151, Time: 1.11s, Batches: 220
2025-05-25 15:17:07,672 - INFO - Epoch [93/150], Train Loss: 4.1748, Val Loss: 0.5086, Time: 1.09s, Batches: 220
2025-05-25 15:17:08,809 - INFO - Epoch [94/150], Train Loss: 3.9541, Val Loss: 0.1835, Time: 1.08s, Batches: 220
2025-05-25 15:17:10,118 - INFO - Epoch [95/150], Train Loss: 3.9108, Val Loss: 0.3326, Time: 1.25s, Batches: 220
2025-05-25 15:17:11,259 - INFO - Epoch [96/150], Train Loss: 3.9588, Val Loss: 0.5773, Time: 1.09s, Batches: 220
2025-05-25 15:17:12,420 - INFO - Epoch [97/150], Train Loss: 4.0157, Val Loss: 0.1765, Time: 1.11s, Batches: 220
2025-05-25 15:17:13,522 - INFO - Epoch [98/150], Train Loss: 3.8797, Val Loss: 0.1786, Time: 1.04s, Batches: 220
2025-05-25 15:17:14,641 - INFO - Epoch [99/150], Train Loss: 3.8724, Val Loss: 0.1972, Time: 1.04s, Batches: 220
2025-05-25 15:17:15,844 - INFO - Epoch [100/150], Train Loss: 3.8894, Val Loss: 0.2079, Time: 1.15s, Batches: 220
2025-05-25 15:17:16,118 - INFO - MLP MSE: 0.1656, R2: 0.9980
2025-05-25 15:17:16,418 - INFO - Mô hình MLP \u0111ã \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i: D:/BaiDoAnChuyenNganh3/NLPResumeRankingAutomatedSystem/model/mlp_model.pth
2025-05-25 15:17:16,796 - INFO - B\u1eaft \u0111\u1ea7u hu\u1ea5n luy\u1ec7n mô hình LSTM v\u1edbi early stopping...
2025-05-25 15:17:19,560 - INFO - Epoch [1/200], Train Loss: 1749.6549, Val Loss: 1303.0922, Time: 2.63s, Batches: 440
2025-05-25 15:17:22,228 - INFO - Epoch [2/200], Train Loss: 1152.5544, Val Loss: 974.9667, Time: 2.51s, Batches: 440
2025-05-25 15:17:24,764 - INFO - Epoch [3/200], Train Loss: 877.7730, Val Loss: 744.5205, Time: 2.38s, Batches: 440
2025-05-25 15:17:27,330 - INFO - Epoch [4/200], Train Loss: 671.6849, Val Loss: 565.7329, Time: 2.44s, Batches: 440
2025-05-25 15:17:29,913 - INFO - Epoch [5/200], Train Loss: 510.0006, Val Loss: 425.5567, Time: 2.44s, Batches: 440
2025-05-25 15:17:32,370 - INFO - Epoch [6/200], Train Loss: 383.5609, Val Loss: 317.1779, Time: 2.33s, Batches: 440
2025-05-25 15:17:34,895 - INFO - Epoch [7/200], Train Loss: 286.4871, Val Loss: 235.5461, Time: 2.39s, Batches: 440
2025-05-25 15:17:37,373 - INFO - Epoch [8/200], Train Loss: 214.1729, Val Loss: 176.3334, Time: 2.36s, Batches: 440
2025-05-25 15:17:39,930 - INFO - Epoch [9/200], Train Loss: 162.5597, Val Loss: 135.7724, Time: 2.42s, Batches: 440
2025-05-25 15:17:42,409 - INFO - Epoch [10/200], Train Loss: 127.9351, Val Loss: 110.0086, Time: 2.32s, Batches: 440
2025-05-25 15:17:44,949 - INFO - Epoch [11/200], Train Loss: 106.4262, Val Loss: 95.2431, Time: 2.40s, Batches: 440
2025-05-25 15:17:47,434 - INFO - Epoch [12/200], Train Loss: 94.4355, Val Loss: 87.9232, Time: 2.36s, Batches: 440
2025-05-25 15:17:49,991 - INFO - Epoch [13/200], Train Loss: 88.6258, Val Loss: 85.0353, Time: 2.41s, Batches: 440
2025-05-25 15:17:52,428 - INFO - Epoch [14/200], Train Loss: 86.2942, Val Loss: 84.2711, Time: 2.31s, Batches: 440
2025-05-25 15:17:55,031 - INFO - Epoch [15/200], Train Loss: 85.6284, Val Loss: 84.2189, Time: 2.46s, Batches: 440
2025-05-25 15:17:57,462 - INFO - Epoch [16/200], Train Loss: 85.4230, Val Loss: 84.2636, Time: 2.31s, Batches: 440
2025-05-25 15:17:59,945 - INFO - Epoch [17/200], Train Loss: 85.3599, Val Loss: 84.2286, Time: 2.35s, Batches: 440
2025-05-25 15:18:02,448 - INFO - Epoch [18/200], Train Loss: 84.1916, Val Loss: 73.3316, Time: 2.39s, Batches: 440
2025-05-25 15:18:05,001 - INFO - Epoch [19/200], Train Loss: 59.6874, Val Loss: 49.0801, Time: 2.39s, Batches: 440
2025-05-25 15:18:07,434 - INFO - Epoch [20/200], Train Loss: 45.0319, Val Loss: 40.0403, Time: 2.31s, Batches: 440
2025-05-25 15:18:10,213 - INFO - Epoch [21/200], Train Loss: 37.5801, Val Loss: 34.2844, Time: 2.66s, Batches: 440
2025-05-25 15:18:12,908 - INFO - Epoch [22/200], Train Loss: 32.4537, Val Loss: 29.0407, Time: 2.55s, Batches: 440
2025-05-25 15:18:15,520 - INFO - Epoch [23/200], Train Loss: 28.0981, Val Loss: 25.3069, Time: 2.48s, Batches: 440
2025-05-25 15:18:18,100 - INFO - Epoch [24/200], Train Loss: 24.1096, Val Loss: 21.2024, Time: 2.45s, Batches: 440
2025-05-25 15:18:20,824 - INFO - Epoch [25/200], Train Loss: 20.7508, Val Loss: 17.9332, Time: 2.60s, Batches: 440
2025-05-25 15:18:23,249 - INFO - Epoch [26/200], Train Loss: 17.5299, Val Loss: 14.7113, Time: 2.30s, Batches: 440
2025-05-25 15:18:25,899 - INFO - Epoch [27/200], Train Loss: 14.6722, Val Loss: 11.8725, Time: 2.52s, Batches: 440
2025-05-25 15:18:28,426 - INFO - Epoch [28/200], Train Loss: 12.2154, Val Loss: 9.4230, Time: 2.40s, Batches: 440
2025-05-25 15:18:31,052 - INFO - Epoch [29/200], Train Loss: 10.3374, Val Loss: 7.5786, Time: 2.50s, Batches: 440
2025-05-25 15:18:33,508 - INFO - Epoch [30/200], Train Loss: 8.7485, Val Loss: 6.4246, Time: 2.33s, Batches: 440
2025-05-25 15:18:36,098 - INFO - Epoch [31/200], Train Loss: 7.5405, Val Loss: 5.0499, Time: 2.46s, Batches: 440
2025-05-25 15:18:38,502 - INFO - Epoch [32/200], Train Loss: 6.5764, Val Loss: 4.1621, Time: 2.28s, Batches: 440
2025-05-25 15:18:41,031 - INFO - Epoch [33/200], Train Loss: 5.8617, Val Loss: 3.3572, Time: 2.41s, Batches: 440
2025-05-25 15:18:43,443 - INFO - Epoch [34/200], Train Loss: 5.0185, Val Loss: 2.7165, Time: 2.28s, Batches: 440
2025-05-25 15:18:46,073 - INFO - Epoch [35/200], Train Loss: 4.3606, Val Loss: 2.1843, Time: 2.50s, Batches: 440
2025-05-25 15:18:48,519 - INFO - Epoch [36/200], Train Loss: 3.7810, Val Loss: 2.0510, Time: 2.32s, Batches: 440
2025-05-25 15:18:51,087 - INFO - Epoch [37/200], Train Loss: 3.2545, Val Loss: 1.5089, Time: 2.45s, Batches: 440
2025-05-25 15:18:53,581 - INFO - Epoch [38/200], Train Loss: 2.9048, Val Loss: 1.4397, Time: 2.31s, Batches: 440
2025-05-25 15:18:56,163 - INFO - Epoch [39/200], Train Loss: 2.5228, Val Loss: 1.0992, Time: 2.44s, Batches: 440
2025-05-25 15:18:58,631 - INFO - Epoch [40/200], Train Loss: 2.2513, Val Loss: 0.8109, Time: 2.34s, Batches: 440
2025-05-25 15:19:01,278 - INFO - Epoch [41/200], Train Loss: 2.0212, Val Loss: 0.7001, Time: 2.52s, Batches: 440
2025-05-25 15:19:03,763 - INFO - Epoch [42/200], Train Loss: 1.9266, Val Loss: 0.6071, Time: 2.36s, Batches: 440
2025-05-25 15:19:06,412 - INFO - Epoch [43/200], Train Loss: 1.7758, Val Loss: 0.5683, Time: 2.52s, Batches: 440
2025-05-25 15:19:08,942 - INFO - Epoch [44/200], Train Loss: 1.7010, Val Loss: 0.5073, Time: 2.41s, Batches: 440
2025-05-25 15:19:11,571 - INFO - Epoch [45/200], Train Loss: 1.5895, Val Loss: 0.5582, Time: 2.50s, Batches: 440
2025-05-25 15:19:14,028 - INFO - Epoch [46/200], Train Loss: 1.4469, Val Loss: 0.4697, Time: 2.34s, Batches: 440
2025-05-25 15:19:16,888 - INFO - Epoch [47/200], Train Loss: 1.4209, Val Loss: 0.4603, Time: 2.71s, Batches: 440
2025-05-25 15:19:19,670 - INFO - Epoch [48/200], Train Loss: 1.3961, Val Loss: 0.4192, Time: 2.65s, Batches: 440
2025-05-25 15:19:22,379 - INFO - Epoch [49/200], Train Loss: 1.2728, Val Loss: 0.4060, Time: 2.59s, Batches: 440
2025-05-25 15:19:25,073 - INFO - Epoch [50/200], Train Loss: 1.2091, Val Loss: 0.3723, Time: 2.55s, Batches: 440
2025-05-25 15:19:27,629 - INFO - Epoch [51/200], Train Loss: 1.1916, Val Loss: 0.4045, Time: 2.43s, Batches: 440
2025-05-25 15:19:30,197 - INFO - Epoch [52/200], Train Loss: 1.1296, Val Loss: 0.3309, Time: 2.43s, Batches: 440
2025-05-25 15:19:32,673 - INFO - Epoch [53/200], Train Loss: 1.0838, Val Loss: 0.3529, Time: 2.32s, Batches: 440
2025-05-25 15:19:35,212 - INFO - Epoch [54/200], Train Loss: 1.0982, Val Loss: 0.3987, Time: 2.40s, Batches: 440
2025-05-25 15:19:37,674 - INFO - Epoch [55/200], Train Loss: 1.0329, Val Loss: 0.3975, Time: 2.31s, Batches: 440
2025-05-25 15:19:40,320 - INFO - Epoch [56/200], Train Loss: 0.9767, Val Loss: 0.3647, Time: 2.53s, Batches: 440
2025-05-25 15:19:42,741 - INFO - Epoch [57/200], Train Loss: 0.9783, Val Loss: 0.2918, Time: 2.31s, Batches: 440
2025-05-25 15:19:45,336 - INFO - Epoch [58/200], Train Loss: 0.9460, Val Loss: 0.2659, Time: 2.46s, Batches: 440
2025-05-25 15:19:47,776 - INFO - Epoch [59/200], Train Loss: 0.8965, Val Loss: 0.2648, Time: 2.32s, Batches: 440
2025-05-25 15:19:50,357 - INFO - Epoch [60/200], Train Loss: 0.9070, Val Loss: 0.4323, Time: 2.46s, Batches: 440
2025-05-25 15:19:52,796 - INFO - Epoch [61/200], Train Loss: 0.8822, Val Loss: 0.2532, Time: 2.33s, Batches: 440
2025-05-25 15:19:55,368 - INFO - Epoch [62/200], Train Loss: 0.8333, Val Loss: 0.3354, Time: 2.45s, Batches: 440
2025-05-25 15:19:57,792 - INFO - Epoch [63/200], Train Loss: 0.8419, Val Loss: 0.2318, Time: 2.31s, Batches: 440
2025-05-25 15:20:00,432 - INFO - Epoch [64/200], Train Loss: 0.8136, Val Loss: 0.3436, Time: 2.52s, Batches: 440
2025-05-25 15:20:02,965 - INFO - Epoch [65/200], Train Loss: 0.7901, Val Loss: 0.2722, Time: 2.42s, Batches: 440
2025-05-25 15:20:05,558 - INFO - Epoch [66/200], Train Loss: 0.7555, Val Loss: 0.2466, Time: 2.47s, Batches: 440
2025-05-25 15:20:08,029 - INFO - Epoch [67/200], Train Loss: 0.7643, Val Loss: 0.2423, Time: 2.36s, Batches: 440
2025-05-25 15:20:10,651 - INFO - Epoch [68/200], Train Loss: 0.7329, Val Loss: 0.2109, Time: 2.50s, Batches: 440
2025-05-25 15:20:13,186 - INFO - Epoch [69/200], Train Loss: 0.7281, Val Loss: 0.3473, Time: 2.41s, Batches: 440
2025-05-25 15:20:15,797 - INFO - Epoch [70/200], Train Loss: 0.7033, Val Loss: 0.1922, Time: 2.50s, Batches: 440
2025-05-25 15:20:18,294 - INFO - Epoch [71/200], Train Loss: 0.6914, Val Loss: 0.2049, Time: 2.38s, Batches: 440
2025-05-25 15:20:20,996 - INFO - Epoch [72/200], Train Loss: 0.6836, Val Loss: 0.3501, Time: 2.57s, Batches: 440
2025-05-25 15:20:23,792 - INFO - Epoch [73/200], Train Loss: 0.6770, Val Loss: 0.2680, Time: 2.68s, Batches: 440
2025-05-25 15:20:26,680 - INFO - Epoch [74/200], Train Loss: 0.6580, Val Loss: 0.2109, Time: 2.77s, Batches: 440
2025-05-25 15:20:29,236 - INFO - Epoch [75/200], Train Loss: 0.6572, Val Loss: 0.1988, Time: 2.44s, Batches: 440
2025-05-25 15:20:31,996 - INFO - Epoch [76/200], Train Loss: 0.6526, Val Loss: 0.2494, Time: 2.61s, Batches: 440
2025-05-25 15:20:34,703 - INFO - Epoch [77/200], Train Loss: 0.6074, Val Loss: 0.1729, Time: 2.60s, Batches: 440
2025-05-25 15:20:37,450 - INFO - Epoch [78/200], Train Loss: 0.6157, Val Loss: 0.1865, Time: 2.63s, Batches: 440
2025-05-25 15:20:40,035 - INFO - Epoch [79/200], Train Loss: 0.6074, Val Loss: 0.1780, Time: 2.41s, Batches: 440
2025-05-25 15:20:42,631 - INFO - Epoch [80/200], Train Loss: 0.5957, Val Loss: 0.2186, Time: 2.48s, Batches: 440
2025-05-25 15:20:45,177 - INFO - Epoch [81/200], Train Loss: 0.5964, Val Loss: 0.2237, Time: 2.41s, Batches: 440
2025-05-25 15:20:47,661 - INFO - Epoch [82/200], Train Loss: 0.5808, Val Loss: 0.1473, Time: 2.37s, Batches: 440
2025-05-25 15:20:50,296 - INFO - Epoch [83/200], Train Loss: 0.5604, Val Loss: 0.1786, Time: 2.49s, Batches: 440
2025-05-25 15:20:52,772 - INFO - Epoch [84/200], Train Loss: 0.5754, Val Loss: 0.1850, Time: 2.36s, Batches: 440
2025-05-25 15:20:55,385 - INFO - Epoch [85/200], Train Loss: 0.5495, Val Loss: 0.1512, Time: 2.49s, Batches: 440
2025-05-25 15:20:57,770 - INFO - Epoch [86/200], Train Loss: 0.5558, Val Loss: 0.1482, Time: 2.27s, Batches: 440
2025-05-25 15:21:00,408 - INFO - Epoch [87/200], Train Loss: 0.5501, Val Loss: 0.1527, Time: 2.51s, Batches: 440
2025-05-25 15:21:02,848 - INFO - Epoch [88/200], Train Loss: 0.5398, Val Loss: 0.1477, Time: 2.32s, Batches: 440
2025-05-25 15:21:05,461 - INFO - Epoch [89/200], Train Loss: 0.5350, Val Loss: 0.2669, Time: 2.50s, Batches: 440
2025-05-25 15:21:08,011 - INFO - Epoch [90/200], Train Loss: 0.5041, Val Loss: 0.1645, Time: 2.44s, Batches: 440
2025-05-25 15:21:10,655 - INFO - Epoch [91/200], Train Loss: 0.5257, Val Loss: 0.1876, Time: 2.53s, Batches: 440
2025-05-25 15:21:13,160 - INFO - Epoch [92/200], Train Loss: 0.5186, Val Loss: 0.2170, Time: 2.39s, Batches: 440
2025-05-25 15:21:15,783 - INFO - Epoch [93/200], Train Loss: 0.4963, Val Loss: 0.1995, Time: 2.51s, Batches: 440
2025-05-25 15:21:18,243 - INFO - Epoch [94/200], Train Loss: 0.5017, Val Loss: 0.1607, Time: 2.31s, Batches: 440
2025-05-25 15:21:20,786 - INFO - Epoch [95/200], Train Loss: 0.4998, Val Loss: 0.1272, Time: 2.43s, Batches: 440
2025-05-25 15:21:23,283 - INFO - Epoch [96/200], Train Loss: 0.4729, Val Loss: 0.1320, Time: 2.35s, Batches: 440
2025-05-25 15:21:25,903 - INFO - Epoch [97/200], Train Loss: 0.5051, Val Loss: 0.1273, Time: 2.50s, Batches: 440
2025-05-25 15:21:28,508 - INFO - Epoch [98/200], Train Loss: 0.4953, Val Loss: 0.1330, Time: 2.48s, Batches: 440
2025-05-25 15:21:31,440 - INFO - Epoch [99/200], Train Loss: 0.4730, Val Loss: 0.1341, Time: 2.82s, Batches: 440
2025-05-25 15:21:34,114 - INFO - Epoch [100/200], Train Loss: 0.4623, Val Loss: 0.1327, Time: 2.56s, Batches: 440
2025-05-25 15:21:36,824 - INFO - Epoch [101/200], Train Loss: 0.4893, Val Loss: 0.1741, Time: 2.59s, Batches: 440
2025-05-25 15:21:39,412 - INFO - Epoch [102/200], Train Loss: 0.4652, Val Loss: 0.2053, Time: 2.47s, Batches: 440
2025-05-25 15:21:42,104 - INFO - Epoch [103/200], Train Loss: 0.4706, Val Loss: 0.1206, Time: 2.57s, Batches: 440
2025-05-25 15:21:44,655 - INFO - Epoch [104/200], Train Loss: 0.4511, Val Loss: 0.1311, Time: 2.42s, Batches: 440
2025-05-25 15:21:47,424 - INFO - Epoch [105/200], Train Loss: 0.4550, Val Loss: 0.1261, Time: 2.66s, Batches: 440
2025-05-25 15:21:49,982 - INFO - Epoch [106/200], Train Loss: 0.4476, Val Loss: 0.1330, Time: 2.40s, Batches: 440
2025-05-25 15:21:52,676 - INFO - Epoch [107/200], Train Loss: 0.4701, Val Loss: 0.1484, Time: 2.58s, Batches: 440
2025-05-25 15:21:55,387 - INFO - Epoch [108/200], Train Loss: 0.4250, Val Loss: 0.2354, Time: 2.55s, Batches: 440
2025-05-25 15:21:57,885 - INFO - Epoch [109/200], Train Loss: 0.4497, Val Loss: 0.1245, Time: 2.38s, Batches: 440
2025-05-25 15:22:00,550 - INFO - Epoch [110/200], Train Loss: 0.4317, Val Loss: 0.1764, Time: 2.55s, Batches: 440
2025-05-25 15:22:03,074 - INFO - Epoch [111/200], Train Loss: 0.4343, Val Loss: 0.1575, Time: 2.41s, Batches: 440
2025-05-25 15:22:05,679 - INFO - Epoch [112/200], Train Loss: 0.4113, Val Loss: 0.1065, Time: 2.50s, Batches: 440
2025-05-25 15:22:08,218 - INFO - Epoch [113/200], Train Loss: 0.4288, Val Loss: 0.1855, Time: 2.39s, Batches: 440
2025-05-25 15:22:11,000 - INFO - Epoch [114/200], Train Loss: 0.4347, Val Loss: 0.1223, Time: 2.62s, Batches: 440
2025-05-25 15:22:13,541 - INFO - Epoch [115/200], Train Loss: 0.4398, Val Loss: 0.1182, Time: 2.43s, Batches: 440
2025-05-25 15:22:16,179 - INFO - Epoch [116/200], Train Loss: 0.4206, Val Loss: 0.0957, Time: 2.52s, Batches: 440
2025-05-25 15:22:18,762 - INFO - Epoch [117/200], Train Loss: 0.4112, Val Loss: 0.1158, Time: 2.46s, Batches: 440
2025-05-25 15:22:21,430 - INFO - Epoch [118/200], Train Loss: 0.4226, Val Loss: 0.1325, Time: 2.52s, Batches: 440
2025-05-25 15:22:23,979 - INFO - Epoch [119/200], Train Loss: 0.4049, Val Loss: 0.1006, Time: 2.42s, Batches: 440
2025-05-25 15:22:26,654 - INFO - Epoch [120/200], Train Loss: 0.3953, Val Loss: 0.0979, Time: 2.52s, Batches: 440
2025-05-25 15:22:29,152 - INFO - Epoch [121/200], Train Loss: 0.3958, Val Loss: 0.0972, Time: 2.38s, Batches: 440
2025-05-25 15:22:31,779 - INFO - Epoch [122/200], Train Loss: 0.4004, Val Loss: 0.1200, Time: 2.50s, Batches: 440
2025-05-25 15:22:34,381 - INFO - Epoch [123/200], Train Loss: 0.4030, Val Loss: 0.0913, Time: 2.48s, Batches: 440
2025-05-25 15:22:37,247 - INFO - Epoch [124/200], Train Loss: 0.4046, Val Loss: 0.1778, Time: 2.72s, Batches: 440
2025-05-25 15:22:39,965 - INFO - Epoch [125/200], Train Loss: 0.4047, Val Loss: 0.1308, Time: 2.60s, Batches: 440
2025-05-25 15:22:42,748 - INFO - Epoch [126/200], Train Loss: 0.3903, Val Loss: 0.1434, Time: 2.67s, Batches: 440
2025-05-25 15:22:45,624 - INFO - Epoch [127/200], Train Loss: 0.3914, Val Loss: 0.0919, Time: 2.72s, Batches: 440
2025-05-25 15:22:48,278 - INFO - Epoch [128/200], Train Loss: 0.3969, Val Loss: 0.0944, Time: 2.53s, Batches: 440
2025-05-25 15:22:51,262 - INFO - Epoch [129/200], Train Loss: 0.3852, Val Loss: 0.1749, Time: 2.83s, Batches: 440
2025-05-25 15:22:54,044 - INFO - Epoch [130/200], Train Loss: 0.3855, Val Loss: 0.1750, Time: 2.66s, Batches: 440
2025-05-25 15:22:56,892 - INFO - Epoch [131/200], Train Loss: 0.3589, Val Loss: 0.0856, Time: 2.71s, Batches: 440
2025-05-25 15:22:59,592 - INFO - Epoch [132/200], Train Loss: 0.3880, Val Loss: 0.1234, Time: 2.57s, Batches: 440
2025-05-25 15:23:02,385 - INFO - Epoch [133/200], Train Loss: 0.3891, Val Loss: 0.1003, Time: 2.68s, Batches: 440
2025-05-25 15:23:05,030 - INFO - Epoch [134/200], Train Loss: 0.3752, Val Loss: 0.1161, Time: 2.52s, Batches: 440
2025-05-25 15:23:07,832 - INFO - Epoch [135/200], Train Loss: 0.3755, Val Loss: 0.1042, Time: 2.67s, Batches: 440
2025-05-25 15:23:10,652 - INFO - Epoch [136/200], Train Loss: 0.3756, Val Loss: 0.1791, Time: 2.70s, Batches: 440
2025-05-25 15:23:13,370 - INFO - Epoch [137/200], Train Loss: 0.3677, Val Loss: 0.0962, Time: 2.60s, Batches: 440
2025-05-25 15:23:16,276 - INFO - Epoch [138/200], Train Loss: 0.3608, Val Loss: 0.0864, Time: 2.78s, Batches: 440
2025-05-25 15:23:19,053 - INFO - Epoch [139/200], Train Loss: 0.3774, Val Loss: 0.0909, Time: 2.65s, Batches: 440
2025-05-25 15:23:22,007 - INFO - Epoch [140/200], Train Loss: 0.3730, Val Loss: 0.0792, Time: 2.83s, Batches: 440
2025-05-25 15:23:25,049 - INFO - Epoch [141/200], Train Loss: 0.3646, Val Loss: 0.2809, Time: 2.88s, Batches: 440
2025-05-25 15:23:27,981 - INFO - Epoch [142/200], Train Loss: 0.3624, Val Loss: 0.1051, Time: 2.77s, Batches: 440
2025-05-25 15:23:30,828 - INFO - Epoch [143/200], Train Loss: 0.3669, Val Loss: 0.0972, Time: 2.72s, Batches: 440
2025-05-25 15:23:33,624 - INFO - Epoch [144/200], Train Loss: 0.3445, Val Loss: 0.1913, Time: 2.67s, Batches: 440
2025-05-25 15:23:36,560 - INFO - Epoch [145/200], Train Loss: 0.3641, Val Loss: 0.0841, Time: 2.78s, Batches: 440
2025-05-25 15:23:39,315 - INFO - Epoch [146/200], Train Loss: 0.3514, Val Loss: 0.0830, Time: 2.63s, Batches: 440
2025-05-25 15:23:42,264 - INFO - Epoch [147/200], Train Loss: 0.3603, Val Loss: 0.0945, Time: 2.84s, Batches: 440
2025-05-25 15:23:45,072 - INFO - Epoch [148/200], Train Loss: 0.3459, Val Loss: 0.0974, Time: 2.65s, Batches: 440
2025-05-25 15:23:47,894 - INFO - Epoch [149/200], Train Loss: 0.3758, Val Loss: 0.0755, Time: 2.69s, Batches: 440
2025-05-25 15:23:50,601 - INFO - Epoch [150/200], Train Loss: 0.3612, Val Loss: 0.1244, Time: 2.56s, Batches: 440
2025-05-25 15:23:53,127 - INFO - Epoch [151/200], Train Loss: 0.3428, Val Loss: 0.0773, Time: 2.41s, Batches: 440
2025-05-25 15:23:55,840 - INFO - Epoch [152/200], Train Loss: 0.3457, Val Loss: 0.0702, Time: 2.59s, Batches: 440
2025-05-25 15:23:58,382 - INFO - Epoch [153/200], Train Loss: 0.3446, Val Loss: 0.0863, Time: 2.41s, Batches: 440
2025-05-25 15:24:01,111 - INFO - Epoch [154/200], Train Loss: 0.3334, Val Loss: 0.0789, Time: 2.61s, Batches: 440
2025-05-25 15:24:03,630 - INFO - Epoch [155/200], Train Loss: 0.3522, Val Loss: 0.0688, Time: 2.40s, Batches: 440
2025-05-25 15:24:06,363 - INFO - Epoch [156/200], Train Loss: 0.3414, Val Loss: 0.0988, Time: 2.61s, Batches: 440
2025-05-25 15:24:08,988 - INFO - Epoch [157/200], Train Loss: 0.3352, Val Loss: 0.1786, Time: 2.50s, Batches: 440
2025-05-25 15:24:11,668 - INFO - Epoch [158/200], Train Loss: 0.3346, Val Loss: 0.0732, Time: 2.57s, Batches: 440
2025-05-25 15:24:14,206 - INFO - Epoch [159/200], Train Loss: 0.3315, Val Loss: 0.1128, Time: 2.40s, Batches: 440
2025-05-25 15:24:16,860 - INFO - Epoch [160/200], Train Loss: 0.3361, Val Loss: 0.0756, Time: 2.53s, Batches: 440
2025-05-25 15:24:19,404 - INFO - Epoch [161/200], Train Loss: 0.3292, Val Loss: 0.1152, Time: 2.43s, Batches: 440
2025-05-25 15:24:22,087 - INFO - Epoch [162/200], Train Loss: 0.3355, Val Loss: 0.0826, Time: 2.53s, Batches: 440
2025-05-25 15:24:24,602 - INFO - Epoch [163/200], Train Loss: 0.3530, Val Loss: 0.1878, Time: 2.40s, Batches: 440
2025-05-25 15:24:27,307 - INFO - Epoch [164/200], Train Loss: 0.3323, Val Loss: 0.0796, Time: 2.59s, Batches: 440
2025-05-25 15:24:29,845 - INFO - Epoch [165/200], Train Loss: 0.3222, Val Loss: 0.0857, Time: 2.40s, Batches: 440
2025-05-25 15:24:32,537 - INFO - Epoch [166/200], Train Loss: 0.3281, Val Loss: 0.0889, Time: 2.57s, Batches: 440
2025-05-25 15:24:35,045 - INFO - Epoch [167/200], Train Loss: 0.3259, Val Loss: 0.1170, Time: 2.39s, Batches: 440
2025-05-25 15:24:37,728 - INFO - Epoch [168/200], Train Loss: 0.3307, Val Loss: 0.0833, Time: 2.56s, Batches: 440
2025-05-25 15:24:40,375 - INFO - Epoch [169/200], Train Loss: 0.3131, Val Loss: 0.1285, Time: 2.50s, Batches: 440
2025-05-25 15:24:42,959 - INFO - Epoch [170/200], Train Loss: 0.3444, Val Loss: 0.1016, Time: 2.46s, Batches: 440
2025-05-25 15:24:43,357 - INFO - Optimized LSTM MSE: 0.1156, R2: 0.9986
2025-05-25 15:24:43,680 - INFO - Mô hình LSTM \u0111ã \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i: D:/BaiDoAnChuyenNganh3/NLPResumeRankingAutomatedSystem/model/lstm_model.pth
2025-05-25 15:24:44,131 - INFO - B\u1eaft \u0111\u1ea7u hu\u1ea5n luy\u1ec7n mô hình Transformer v\u1edbi early stopping...
2025-05-25 15:25:21,065 - INFO - Epoch [1/100], Train Loss: 454.2216, Val Loss: 58.3549, Time: 35.75s, Batches: 3519
2025-05-25 15:25:57,662 - INFO - Epoch [2/100], Train Loss: 23.7876, Val Loss: 8.3044, Time: 35.48s, Batches: 3519
2025-05-25 15:26:34,439 - INFO - Epoch [3/100], Train Loss: 6.3514, Val Loss: 4.7355, Time: 35.68s, Batches: 3519
2025-05-25 15:27:16,007 - INFO - Epoch [4/100], Train Loss: 3.4994, Val Loss: 5.9052, Time: 40.32s, Batches: 3519
2025-05-25 15:27:51,467 - INFO - Epoch [5/100], Train Loss: 2.7575, Val Loss: 2.1149, Time: 34.28s, Batches: 3519
2025-05-25 15:28:27,245 - INFO - Epoch [6/100], Train Loss: 2.3493, Val Loss: 1.5165, Time: 34.71s, Batches: 3519
2025-05-25 15:29:02,738 - INFO - Epoch [7/100], Train Loss: 1.8932, Val Loss: 1.3423, Time: 34.46s, Batches: 3519
2025-05-25 15:29:38,863 - INFO - Epoch [8/100], Train Loss: 1.5970, Val Loss: 1.6227, Time: 35.03s, Batches: 3519
2025-05-25 15:30:14,347 - INFO - Epoch [9/100], Train Loss: 1.4187, Val Loss: 0.8714, Time: 34.46s, Batches: 3519
2025-05-25 15:30:51,020 - INFO - Epoch [10/100], Train Loss: 1.2986, Val Loss: 0.7530, Time: 35.52s, Batches: 3519
2025-05-25 15:31:27,398 - INFO - Epoch [11/100], Train Loss: 1.1512, Val Loss: 1.4534, Time: 35.26s, Batches: 3519
2025-05-25 15:32:03,852 - INFO - Epoch [12/100], Train Loss: 0.9863, Val Loss: 1.1310, Time: 35.44s, Batches: 3519
2025-05-25 15:32:40,735 - INFO - Epoch [13/100], Train Loss: 0.9259, Val Loss: 0.6673, Time: 35.74s, Batches: 3519
2025-05-25 15:33:18,260 - INFO - Epoch [14/100], Train Loss: 0.8225, Val Loss: 0.5893, Time: 36.45s, Batches: 3519
2025-05-25 15:33:56,806 - INFO - Epoch [15/100], Train Loss: 0.7980, Val Loss: 0.6496, Time: 37.22s, Batches: 3519
2025-05-25 15:34:34,413 - INFO - Epoch [16/100], Train Loss: 0.7190, Val Loss: 0.4661, Time: 36.55s, Batches: 3519
2025-05-25 15:35:12,899 - INFO - Epoch [17/100], Train Loss: 0.6773, Val Loss: 0.6082, Time: 37.39s, Batches: 3519
2025-05-25 15:35:49,950 - INFO - Epoch [18/100], Train Loss: 0.6404, Val Loss: 0.6115, Time: 35.97s, Batches: 3519
2025-05-25 15:36:27,106 - INFO - Epoch [19/100], Train Loss: 0.5825, Val Loss: 0.6173, Time: 35.96s, Batches: 3519
2025-05-25 15:37:07,684 - INFO - Epoch [20/100], Train Loss: 0.5889, Val Loss: 0.3178, Time: 39.50s, Batches: 3519
2025-05-25 15:37:44,387 - INFO - Epoch [21/100], Train Loss: 0.5463, Val Loss: 0.4284, Time: 35.65s, Batches: 3519
2025-05-25 15:38:22,750 - INFO - Epoch [22/100], Train Loss: 0.5077, Val Loss: 0.3602, Time: 37.18s, Batches: 3519
2025-05-25 15:39:01,219 - INFO - Epoch [23/100], Train Loss: 0.5029, Val Loss: 0.3600, Time: 37.40s, Batches: 3519
2025-05-25 15:39:39,980 - INFO - Epoch [24/100], Train Loss: 0.4739, Val Loss: 0.2525, Time: 37.69s, Batches: 3519
2025-05-25 15:40:18,591 - INFO - Epoch [25/100], Train Loss: 0.4365, Val Loss: 0.5982, Time: 37.44s, Batches: 3519
2025-05-25 15:40:56,782 - INFO - Epoch [26/100], Train Loss: 0.4285, Val Loss: 0.3238, Time: 37.11s, Batches: 3519
2025-05-25 15:41:34,521 - INFO - Epoch [27/100], Train Loss: 0.4242, Val Loss: 0.7782, Time: 36.68s, Batches: 3519
2025-05-25 15:42:13,456 - INFO - Epoch [28/100], Train Loss: 0.3996, Val Loss: 0.4570, Time: 37.86s, Batches: 3519
2025-05-25 15:42:52,902 - INFO - Epoch [29/100], Train Loss: 0.3862, Val Loss: 0.3873, Time: 38.24s, Batches: 3519
2025-05-25 15:43:31,503 - INFO - Epoch [30/100], Train Loss: 0.3807, Val Loss: 0.3996, Time: 37.54s, Batches: 3519
2025-05-25 15:44:09,444 - INFO - Epoch [31/100], Train Loss: 0.3338, Val Loss: 0.3772, Time: 36.84s, Batches: 3519
2025-05-25 15:44:47,110 - INFO - Epoch [32/100], Train Loss: 0.3318, Val Loss: 0.3690, Time: 36.54s, Batches: 3519
2025-05-25 15:45:24,524 - INFO - Epoch [33/100], Train Loss: 0.3633, Val Loss: 0.2725, Time: 36.40s, Batches: 3519
2025-05-25 15:46:02,684 - INFO - Epoch [34/100], Train Loss: 0.2957, Val Loss: 0.2395, Time: 36.93s, Batches: 3519
2025-05-25 15:46:44,194 - INFO - Epoch [35/100], Train Loss: 0.3130, Val Loss: 0.3478, Time: 40.28s, Batches: 3519
2025-05-25 15:47:25,782 - INFO - Epoch [36/100], Train Loss: 0.3182, Val Loss: 0.1874, Time: 40.51s, Batches: 3519
2025-05-25 15:48:08,038 - INFO - Epoch [37/100], Train Loss: 0.2851, Val Loss: 0.3433, Time: 40.98s, Batches: 3519
2025-05-25 15:48:49,631 - INFO - Epoch [38/100], Train Loss: 0.2841, Val Loss: 0.2583, Time: 40.53s, Batches: 3519
2025-05-25 15:49:30,099 - INFO - Epoch [39/100], Train Loss: 0.2810, Val Loss: 0.1994, Time: 39.43s, Batches: 3519
2025-05-25 15:50:10,489 - INFO - Epoch [40/100], Train Loss: 0.2733, Val Loss: 0.2504, Time: 39.29s, Batches: 3519
2025-05-25 15:50:51,488 - INFO - Epoch [41/100], Train Loss: 0.2659, Val Loss: 0.1855, Time: 39.91s, Batches: 3519
2025-05-25 15:51:32,712 - INFO - Epoch [42/100], Train Loss: 0.2539, Val Loss: 0.1859, Time: 39.99s, Batches: 3519
2025-05-25 15:52:14,563 - INFO - Epoch [43/100], Train Loss: 0.2479, Val Loss: 0.1400, Time: 40.72s, Batches: 3519
2025-05-25 15:52:56,421 - INFO - Epoch [44/100], Train Loss: 0.2474, Val Loss: 0.2765, Time: 40.68s, Batches: 3519
2025-05-25 15:53:38,305 - INFO - Epoch [45/100], Train Loss: 0.2508, Val Loss: 0.3088, Time: 40.59s, Batches: 3519
2025-05-25 15:54:18,220 - INFO - Epoch [46/100], Train Loss: 0.2508, Val Loss: 0.3136, Time: 38.70s, Batches: 3519
2025-05-25 15:54:58,865 - INFO - Epoch [47/100], Train Loss: 0.2198, Val Loss: 0.2344, Time: 39.33s, Batches: 3519
2025-05-25 15:55:41,367 - INFO - Epoch [48/100], Train Loss: 0.2146, Val Loss: 0.1395, Time: 41.44s, Batches: 3519
2025-05-25 15:56:20,292 - INFO - Epoch [49/100], Train Loss: 0.2443, Val Loss: 0.1733, Time: 37.82s, Batches: 3519
2025-05-25 15:57:02,276 - INFO - Epoch [50/100], Train Loss: 0.1982, Val Loss: 0.1364, Time: 40.94s, Batches: 3519
2025-05-25 15:57:41,170 - INFO - Epoch [51/100], Train Loss: 0.2122, Val Loss: 0.2247, Time: 37.87s, Batches: 3519
2025-05-25 15:58:20,356 - INFO - Epoch [52/100], Train Loss: 0.1971, Val Loss: 0.2287, Time: 38.17s, Batches: 3519
2025-05-25 15:58:59,120 - INFO - Epoch [53/100], Train Loss: 0.1983, Val Loss: 0.2857, Time: 37.57s, Batches: 3519
2025-05-25 15:59:38,537 - INFO - Epoch [54/100], Train Loss: 0.1920, Val Loss: 0.1642, Time: 38.18s, Batches: 3519
2025-05-25 16:00:20,797 - INFO - Epoch [55/100], Train Loss: 0.1971, Val Loss: 0.3908, Time: 41.10s, Batches: 3519
2025-05-25 16:01:05,433 - INFO - Epoch [56/100], Train Loss: 0.2044, Val Loss: 0.1703, Time: 43.51s, Batches: 3519
2025-05-25 16:01:49,331 - INFO - Epoch [57/100], Train Loss: 0.1941, Val Loss: 0.1345, Time: 42.65s, Batches: 3519
2025-05-25 16:02:32,906 - INFO - Epoch [58/100], Train Loss: 0.1842, Val Loss: 0.1525, Time: 42.46s, Batches: 3519
2025-05-25 16:03:15,856 - INFO - Epoch [59/100], Train Loss: 0.1833, Val Loss: 0.1261, Time: 41.90s, Batches: 3519
2025-05-25 16:03:58,701 - INFO - Epoch [60/100], Train Loss: 0.1812, Val Loss: 0.1348, Time: 41.63s, Batches: 3519
2025-05-25 16:04:41,535 - INFO - Epoch [61/100], Train Loss: 0.1755, Val Loss: 0.1511, Time: 41.65s, Batches: 3519
2025-05-25 16:05:25,564 - INFO - Epoch [62/100], Train Loss: 0.1756, Val Loss: 0.1379, Time: 42.88s, Batches: 3519
2025-05-25 16:06:11,841 - INFO - Epoch [63/100], Train Loss: 0.1717, Val Loss: 0.1292, Time: 45.12s, Batches: 3519
2025-05-25 16:06:59,655 - INFO - Epoch [64/100], Train Loss: 0.1614, Val Loss: 0.1275, Time: 46.44s, Batches: 3519
2025-05-25 16:07:44,350 - INFO - Epoch [65/100], Train Loss: 0.1703, Val Loss: 0.1972, Time: 43.43s, Batches: 3519
2025-05-25 16:08:27,670 - INFO - Epoch [66/100], Train Loss: 0.1596, Val Loss: 0.1026, Time: 42.31s, Batches: 3519
2025-05-25 16:09:11,110 - INFO - Epoch [67/100], Train Loss: 0.1644, Val Loss: 0.1564, Time: 42.26s, Batches: 3519
2025-05-25 16:09:53,564 - INFO - Epoch [68/100], Train Loss: 0.1482, Val Loss: 0.1444, Time: 41.32s, Batches: 3519
2025-05-25 16:10:36,881 - INFO - Epoch [69/100], Train Loss: 0.1755, Val Loss: 0.2231, Time: 42.24s, Batches: 3519
2025-05-25 16:11:19,554 - INFO - Epoch [70/100], Train Loss: 0.1456, Val Loss: 0.2329, Time: 41.38s, Batches: 3519
2025-05-25 16:12:02,084 - INFO - Epoch [71/100], Train Loss: 0.1504, Val Loss: 0.1279, Time: 41.43s, Batches: 3519
2025-05-25 16:12:45,927 - INFO - Epoch [72/100], Train Loss: 0.1432, Val Loss: 0.1763, Time: 42.73s, Batches: 3519
2025-05-25 16:13:30,830 - INFO - Epoch [73/100], Train Loss: 0.1535, Val Loss: 0.1462, Time: 43.72s, Batches: 3519
2025-05-25 16:14:16,125 - INFO - Epoch [74/100], Train Loss: 0.1451, Val Loss: 0.3280, Time: 44.15s, Batches: 3519
2025-05-25 16:15:01,518 - INFO - Epoch [75/100], Train Loss: 0.1408, Val Loss: 0.0978, Time: 44.26s, Batches: 3519
2025-05-25 16:15:45,825 - INFO - Epoch [76/100], Train Loss: 0.1499, Val Loss: 0.1506, Time: 42.82s, Batches: 3519
2025-05-25 16:16:30,328 - INFO - Epoch [77/100], Train Loss: 0.1333, Val Loss: 0.4475, Time: 43.29s, Batches: 3519
2025-05-25 16:17:16,078 - INFO - Epoch [78/100], Train Loss: 0.1437, Val Loss: 0.1000, Time: 44.75s, Batches: 3519
2025-05-25 16:17:57,163 - INFO - Epoch [79/100], Train Loss: 0.1287, Val Loss: 0.2469, Time: 40.07s, Batches: 3519
2025-05-25 16:18:40,239 - INFO - Epoch [80/100], Train Loss: 0.1365, Val Loss: 0.1198, Time: 41.87s, Batches: 3519
2025-05-25 16:19:24,482 - INFO - Epoch [81/100], Train Loss: 0.1195, Val Loss: 0.1045, Time: 43.13s, Batches: 3519
2025-05-25 16:20:09,491 - INFO - Epoch [82/100], Train Loss: 0.1344, Val Loss: 0.0990, Time: 43.87s, Batches: 3519
2025-05-25 16:20:54,868 - INFO - Epoch [83/100], Train Loss: 0.1329, Val Loss: 0.0927, Time: 44.21s, Batches: 3519
2025-05-25 16:21:38,231 - INFO - Epoch [84/100], Train Loss: 0.1217, Val Loss: 0.0747, Time: 42.27s, Batches: 3519
2025-05-25 16:22:21,640 - INFO - Epoch [85/100], Train Loss: 0.1235, Val Loss: 0.1422, Time: 42.30s, Batches: 3519
2025-05-25 16:23:05,061 - INFO - Epoch [86/100], Train Loss: 0.1407, Val Loss: 0.1307, Time: 42.29s, Batches: 3519
2025-05-25 16:23:48,563 - INFO - Epoch [87/100], Train Loss: 0.1062, Val Loss: 0.0829, Time: 42.42s, Batches: 3519
2025-05-25 16:24:32,562 - INFO - Epoch [88/100], Train Loss: 0.1204, Val Loss: 0.0826, Time: 42.90s, Batches: 3519
2025-05-25 16:25:17,946 - INFO - Epoch [89/100], Train Loss: 0.1256, Val Loss: 0.3135, Time: 44.27s, Batches: 3519
2025-05-25 16:26:05,674 - INFO - Epoch [90/100], Train Loss: 0.1172, Val Loss: 0.1334, Time: 46.46s, Batches: 3519
2025-05-25 16:26:54,844 - INFO - Epoch [91/100], Train Loss: 0.1154, Val Loss: 0.0988, Time: 47.98s, Batches: 3519
2025-05-25 16:27:44,635 - INFO - Epoch [92/100], Train Loss: 0.1173, Val Loss: 0.1624, Time: 48.71s, Batches: 3519
2025-05-25 16:28:33,045 - INFO - Epoch [93/100], Train Loss: 0.1162, Val Loss: 0.1116, Time: 47.35s, Batches: 3519
2025-05-25 16:29:20,801 - INFO - Epoch [94/100], Train Loss: 0.1113, Val Loss: 0.0787, Time: 46.49s, Batches: 3519
2025-05-25 16:30:09,525 - INFO - Epoch [95/100], Train Loss: 0.1117, Val Loss: 0.0851, Time: 47.65s, Batches: 3519
2025-05-25 16:30:58,820 - INFO - Epoch [96/100], Train Loss: 0.1109, Val Loss: 0.3219, Time: 48.22s, Batches: 3519
2025-05-25 16:31:49,660 - INFO - Epoch [97/100], Train Loss: 0.1047, Val Loss: 0.0767, Time: 49.65s, Batches: 3519
2025-05-25 16:32:40,990 - INFO - Epoch [98/100], Train Loss: 0.1088, Val Loss: 0.1297, Time: 50.04s, Batches: 3519
2025-05-25 16:33:31,820 - INFO - Epoch [99/100], Train Loss: 0.1081, Val Loss: 0.0729, Time: 49.69s, Batches: 3519
2025-05-25 16:34:19,701 - INFO - Epoch [100/100], Train Loss: 0.1043, Val Loss: 0.0938, Time: 46.77s, Batches: 3519
2025-05-25 16:34:22,466 - INFO - Transformer MSE: 0.0730, R2: 0.9991
2025-05-25 16:34:22,774 - INFO - Mô hình TRANSFORMER \u0111ã \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i: D:/BaiDoAnChuyenNganh3/NLPResumeRankingAutomatedSystem/model/transformer_model.pth
2025-05-25 16:34:23,491 - INFO - Mô hình RANDOM FOREST + XGBOOST + TRANSFORMER \u0111ã \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i: D:/BaiDoAnChuyenNganh3/NLPResumeRankingAutomatedSystem/model/rf_xgb_transformer_model.pth
