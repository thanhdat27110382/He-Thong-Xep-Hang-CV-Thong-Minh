{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc 3 file dataset (thay tên file tương ứng với file của bạn)\n",
    "file1 = 'D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/xulydata2linksclean.xlsx'\n",
    "file2 = 'D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/xulyfinaldata3links.xlsx'  \n",
    "file3 = 'D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/xulyfinalindata3seealllinks.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu từ các file Excel\n",
    "df1 = pd.read_excel(file1)\n",
    "df2 = pd.read_excel(file2)\n",
    "df3 = pd.read_excel(file3)\n",
    "\n",
    "# Gộp 3 dataframe lại thành một\n",
    "df_combined = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Kiểm tra và loại bỏ các bản ghi trùng lặp dựa trên cột 'resume_str'\n",
    "df_unique = df_combined.drop_duplicates(subset=['resume_str'], keep='first')\n",
    "\n",
    "# Sắp xếp lại cột ID theo thứ tự tăng dần, bắt đầu từ 1\n",
    "df_unique = df_unique.reset_index(drop=True)\n",
    "df_unique['ID'] = df_unique.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu kết quả vào file mới (tùy chọn)\n",
    "output_file = 'D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/Gop3filedata.xlsx'\n",
    "df_unique.to_excel(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số bản ghi ban đầu: 1696\n",
      "Tổng số bản ghi sau khi loại bỏ trùng lặp: 1694\n",
      "   ID                                         resume_str              Category\n",
      "0   1  Gerard Levine\\nCertified Public Accountant\\n+1...  Accounting & Finance\n",
      "1   2  Brian Watkins\\nAccounting Assistant\\nbrian.wat...  Accounting & Finance\n",
      "2   3  Roman Arkell Accounting Clerk (781) 984-9624 r...  Accounting & Finance\n",
      "3   4  Lukas Summers\\nlukas.summers@mail.us\\n(646) 62...  Accounting & Finance\n",
      "4   5  Moe Money\\nAccounts Payable Specialist\\n555-69...  Accounting & Finance\n"
     ]
    }
   ],
   "source": [
    "# In ra thông tin để kiểm tra\n",
    "print(f\"Tổng số bản ghi ban đầu: {len(df_combined)}\")\n",
    "print(f\"Tổng số bản ghi sau khi loại bỏ trùng lặp: {len(df_unique)}\")\n",
    "print(df_unique[['ID', 'resume_str', 'Category']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các bản ghi trùng lặp đã được phát hiện và loại bỏ:\n",
      "       ID                                         resume_str  \\\n",
      "5       6  Penny Payments\\npennypaymentszety@gmail.com\\n6...   \n",
      "6       7  Penny Payments\\npennypaymentszety@gmail.com\\n6...   \n",
      "1024  137  Marissa Jenkins 123 Fake Street, City, State, ...   \n",
      "1271  384  Marissa Jenkins 123 Fake Street, City, State, ...   \n",
      "\n",
      "                  Category  \n",
      "5     Accounting & Finance  \n",
      "6     Accounting & Finance  \n",
      "1024               Banking  \n",
      "1271                   Law  \n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra các bản ghi trùng lặp đã bị loại bỏ\n",
    "duplicates = df_combined[df_combined.duplicated(subset=['resume_str'], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Các bản ghi trùng lặp đã được phát hiện và loại bỏ:\")\n",
    "    print(duplicates[['ID', 'resume_str', 'Category']])\n",
    "else:\n",
    "    print(\"Không có bản ghi trùng lặp nào được tìm thấy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số bản ghi ban đầu: 1694\n",
      "Không tìm thấy bản ghi trùng lặp trong cột 'resume_str'.\n",
      "Tổng số bản ghi sau khi loại bỏ trùng lặp: 1694\n",
      "\n",
      "Một số dòng đầu tiên của kết quả:\n",
      "   ID                                         resume_str              Category\n",
      "0   1  Gerard Levine\\nCertified Public Accountant\\n+1...  Accounting & Finance\n",
      "1   2  Brian Watkins\\nAccounting Assistant\\nbrian.wat...  Accounting & Finance\n",
      "2   3  Roman Arkell Accounting Clerk (781) 984-9624 r...  Accounting & Finance\n",
      "3   4  Lukas Summers\\nlukas.summers@mail.us\\n(646) 62...  Accounting & Finance\n",
      "4   5  Moe Money\\nAccounts Payable Specialist\\n555-69...  Accounting & Finance\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file dữ liệu\n",
    "file_path = 'D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/Gop3filedata.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Kiểm tra số lượng bản ghi ban đầu\n",
    "print(f\"Tổng số bản ghi ban đầu: {len(df)}\")\n",
    "\n",
    "# Kiểm tra các bản ghi trùng lặp trong cột 'resume_str'\n",
    "duplicates = df[df.duplicated(subset=['resume_str'], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Các bản ghi trùng lặp trong cột 'resume_str':\")\n",
    "    print(duplicates[['ID', 'resume_str', 'Category']])\n",
    "else:\n",
    "    print(\"Không tìm thấy bản ghi trùng lặp trong cột 'resume_str'.\")\n",
    "\n",
    "# Loại bỏ các bản ghi trùng lặp, giữ lại bản ghi đầu tiên\n",
    "df_unique = df.drop_duplicates(subset=['resume_str'], keep='first')\n",
    "\n",
    "# Sắp xếp lại cột ID theo thứ tự tăng dần, bắt đầu từ 1\n",
    "df_unique = df_unique.reset_index(drop=True)\n",
    "df_unique['ID'] = df_unique.index + 1\n",
    "\n",
    "# Kiểm tra số lượng bản ghi sau khi loại bỏ trùng lặp\n",
    "print(f\"Tổng số bản ghi sau khi loại bỏ trùng lặp: {len(df_unique)}\")\n",
    "\n",
    "# Hiển thị một số dòng đầu tiên của kết quả để kiểm tra\n",
    "print(\"\\nMột số dòng đầu tiên của kết quả:\")\n",
    "print(df_unique[['ID', 'resume_str', 'Category']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu kết quả vào file mới\n",
    "output_file = 'Gop3filedata_unique.xlsx'\n",
    "df_unique.to_excel(output_file, index=False)\n",
    "print(f\"Kết quả đã được lưu vào file: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file dữ liệu\n",
    "file_path = 'D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/DataFinal/GeneralCV_Example.xlsx'\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số bản ghi ban đầu: 3974\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra số lượng bản ghi ban đầu\n",
    "print(f\"Tổng số bản ghi ban đầu: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sắp xếp lại cột ID theo thứ tự tăng dần, bắt đầu từ 1\n",
    "df = df.reset_index(drop=True)\n",
    "df['ID'] = df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả đã được lưu vào file: D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/DataFinal/GeneralCV1_Example.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Lưu kết quả vào file mới\n",
    "output_file = 'D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/DataFinal/GeneralCV1_Example.xlsx'\n",
    "df.to_excel(output_file, index=False)\n",
    "print(f\"Kết quả đã được lưu vào file: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File đã được cập nhật và lưu vào: D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/finalGop3filedata.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Đọc file Excel\n",
    "input_file = \"D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/Gop3filedata.xlsx\"\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Danh sách cập nhật Category\n",
    "category_updates = {\n",
    "    \"Fiber Optics Technician Resume\": \"Engineering & Scientific\",\n",
    "    \"Environmental Engineer Resume\": \"Engineering & Scientific\",\n",
    "    \"NDT Trainee Resume\": \"Engineering & Scientific\",\n",
    "    \"KYC Analyst Resume\": \"Banking\",\n",
    "    \"Caregiver Resume\": \"Healthcare Support\",\n",
    "    \"Operating Room Nurse Resume\": \"Nursing\",\n",
    "    \"Intensive Care Nurse Resume\": \"Nursing\",\n",
    "    \"Nursing Aide And Assistant Resume\": \"Nursing\",\n",
    "    \"Perioperative Nurse Resume\": \"Nursing\",\n",
    "    \"Shift Coordinator Resume\": \"Healthcare Support\",\n",
    "    \"LPN Resume\": \"Nursing\",\n",
    "    \"Labor And Delivery Nurse Resume\": \"Nursing\",\n",
    "    \"OB Gyn Nurse Resume\": \"Nursing\",\n",
    "    \"Pediatric Nurse Resume\": \"Nursing\",\n",
    "    \"Hemodialysis Nurse Resume\": \"Nursing\",\n",
    "    \"Private Duty Nurse Resume\": \"Nursing\",\n",
    "    \"Aesthetic Nurse Resume\": \"Nursing\",\n",
    "    \"Chief Nursing Officer Resume\": \"Nursing\",\n",
    "    \"Oncology Nurse Resume\": \"Nursing\",\n",
    "    \"Public School Nurse Resume\": \"Nursing\",\n",
    "    \"Trauma Nurse Resume\": \"Nursing\",\n",
    "    \"Nursing Assistant Resume\": \"Nursing\",\n",
    "    \"Patient Care Associate Resume\": \"Healthcare Support\",\n",
    "    \"Nursing Unit Clerk Resume\": \"Healthcare Support\",\n",
    "    \"ER Nurse Resume\": \"Nursing\",\n",
    "    \"NICU Nurse Resume\": \"Nursing\",\n",
    "    \"Patient Care Technician Resume\": \"Healthcare Support\",\n",
    "    \"Acute Care Nurse Resume\": \"Nursing\",\n",
    "    \"Geriatric Nurse Practitioner Resume\": \"Nursing\",\n",
    "    \"Pre Post Operating Nurse Resume\": \"Nursing\",\n",
    "    \"Advanced Practice RN Resume\": \"Nursing\",\n",
    "    \"Epidemiologist Resume\": \"Medical\",\n",
    "    \"Political Adviser Resume\": \"Business Operations\",\n",
    "    \"Field Supervisor Resume\": \"Business Operations\",\n",
    "    \"Political Consultant Resume\": \"Business Operations\",\n",
    "    \"Research Analyst Resume\": \"Business Operations\",\n",
    "    \"Economist Resume\": \"Accounting & Finance\"\n",
    "}\n",
    "\n",
    "# Cập nhật cột Category\n",
    "for resume, category in category_updates.items():\n",
    "    # Tìm các dòng có resume_str chứa tên resume\n",
    "    mask = df['resume_str'].str.contains(resume, case=False, na=False)\n",
    "    df.loc[mask, 'Category'] = category\n",
    "\n",
    "# Lưu vào file Excel mới\n",
    "output_file = \"D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/finalGop3filedata.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"File đã được cập nhật và lưu vào: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File đã được cập nhật và lưu tại: D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/FinalGop3filedata.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file Excel\n",
    "file_path = \"D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/Gop3filedata.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Tạo từ điển ánh xạ để đổi tên các giá trị trong cột Category\n",
    "category_mapping = {\n",
    "    \"Fiber Optics Technician Resume\": \"Engineering & Scientific\",\n",
    "    \"Environmental Engineer Resume\": \"Engineering & Scientific\",\n",
    "    \"NDT Trainee Resume\": \"Engineering & Scientific\",\n",
    "    \"KYC Analyst Resume\": \"Banking\",\n",
    "    \"Caregiver Resume\": \"Healthcare Support\",\n",
    "    \"Operating Room Nurse Resume\": \"Nursing\",\n",
    "    \"Intensive Care Nurse Resume\": \"Nursing\",\n",
    "    \"Nursing Aide And Assistant Resume\": \"Nursing\",\n",
    "    \"Perioperative Nurse Resume\": \"Nursing\",\n",
    "    \"Shift Coordinator Resume\": \"Healthcare Support\",\n",
    "    \"LPN Resume\": \"Nursing\",\n",
    "    \"Labor And Delivery Nurse Resume\": \"Nursing\",\n",
    "    \"OB Gyn Nurse Resume\": \"Nursing\",\n",
    "    \"Pediatric Nurse Resume\": \"Nursing\",\n",
    "    \"Hemodialysis Nurse Resume\": \"Nursing\",\n",
    "    \"Private Duty Nurse Resume\": \"Nursing\",\n",
    "    \"Aesthetic Nurse Resume\": \"Nursing\",\n",
    "    \"Chief Nursing Officer Resume\": \"Nursing\",\n",
    "    \"Oncology Nurse Resume\": \"Nursing\",\n",
    "    \"Public School Nurse Resume\": \"Nursing\",\n",
    "    \"Trauma Nurse Resume\": \"Nursing\",\n",
    "    \"Nursing Assistant Resume\": \"Nursing\",\n",
    "    \"Patient Care Associate Resume\": \"Healthcare Support\",\n",
    "    \"Nursing Unit Clerk Resume\": \"Healthcare Support\",\n",
    "    \"ER Nurse Resume\": \"Nursing\",\n",
    "    \"NICU Nurse Resume\": \"Nursing\",\n",
    "    \"Patient Care Technician Resume\": \"Healthcare Support\",\n",
    "    \"Acute Care Nurse Resume\": \"Nursing\",\n",
    "    \"Geriatric Nurse Practitioner Resume\": \"Nursing\",\n",
    "    \"Pre Post Operating Nurse Resume\": \"Nursing\",\n",
    "    \"Advanced Practice RN Resume\": \"Nursing\",\n",
    "    \"Epidemiologist Resume\": \"Medical\",\n",
    "    \"Political Adviser Resume\": \"Business Operations\",\n",
    "    \"Field Supervisor Resume\": \"Business Operations\",\n",
    "    \"Political Consultant Resume\": \"Business Operations\",\n",
    "    \"Research Analyst Resume\": \"Business Operations\",\n",
    "    \"Economist Resume\": \"Accounting & Finance\"\n",
    "}\n",
    "\n",
    "# Thay thế giá trị trong cột Category dựa trên từ điển ánh xạ\n",
    "df['Category'] = df['Category'].replace(category_mapping)\n",
    "\n",
    "# Lưu file Excel mới với các giá trị đã được cập nhật\n",
    "output_file_path = \"D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/FinalGop3filedata.xlsx\"\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"File đã được cập nhật và lưu tại: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số dòng ban đầu: 1694\n",
      "Số dòng sau khi loại bỏ trùng lặp: 1694\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file Excel\n",
    "file_path = \"D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/FinalGop3filedata.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Kiểm tra số dòng ban đầu\n",
    "print(f\"Số dòng ban đầu: {len(df)}\")\n",
    "\n",
    "# Kiểm tra và loại bỏ các dòng trùng lặp dựa trên cột resume_str\n",
    "df_no_duplicates = df.drop_duplicates(subset=['resume_str'], keep='first')\n",
    "\n",
    "# Kiểm tra số dòng sau khi loại bỏ trùng lặp\n",
    "print(f\"Số dòng sau khi loại bỏ trùng lặp: {len(df_no_duplicates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file Excel\n",
    "file_path = \"D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/FinalGop3filedata.xlsx\" \n",
    "try:\n",
    "    df = pd.read_excel(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"Lỗi: Không tìm thấy file. Vui lòng kiểm tra đường dẫn file.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số dòng ban đầu: 1694\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra số dòng ban đầu\n",
    "print(f\"Số dòng ban đầu: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra xem cột resume_str có tồn tại không\n",
    "if 'resume_str' not in df.columns:\n",
    "    print(\"Lỗi: Cột 'resume_str' không tồn tại. Các cột hiện có:\", df.columns)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các dòng trùng lặp trong cột resume_str:\n",
      "        ID                                         resume_str\n",
      "651    652  April Twilling 123 Fake Street, City, State, Z...\n",
      "652    653  Mark Gordon 123 Fake Street, City, State, Zip ...\n",
      "809    810  Susan Courtney 123 Fake Street, City, State, Z...\n",
      "815    816  Sarah Fowler 123 Fake Street, City, State, Zip...\n",
      "834    835  Joe Morali 123 Fake Street, City, State, Zip C...\n",
      "842    843  Brian Westfield 123 Fake Street, City, State, ...\n",
      "912    913  April Twilling 123 Fake Street, City, State, Z...\n",
      "913    914  Mark Gordon 123 Fake Street, City, State, Zip ...\n",
      "1381  1382  Susan Courtney 123 Fake Street, City, State, Z...\n",
      "1387  1388  Sarah Fowler 123 Fake Street, City, State, Zip...\n",
      "1468  1469  Joe Morali 123 Fake Street, City, State, Zip C...\n",
      "1504  1505  Brian Westfield 123 Fake Street, City, State, ...\n",
      "Số dòng trùng lặp: 12\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra trùng lặp trong cột resume_str\n",
    "duplicates = df[df.duplicated(subset=['resume_str'], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Các dòng trùng lặp trong cột resume_str:\")\n",
    "    print(duplicates[['ID', 'resume_str']])\n",
    "    print(f\"Số dòng trùng lặp: {len(duplicates)}\")\n",
    "else:\n",
    "    print(\"Không có dòng nào trùng lặp trong cột resume_str.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file dữ liệu\n",
    "file_path = 'D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/FinalGop3filedata.xlsx'\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số bản ghi ban đầu: 1694\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra số lượng bản ghi ban đầu\n",
    "print(f\"Tổng số bản ghi ban đầu: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các bản ghi trùng lặp trong cột 'resume_str':\n",
      "        ID                                         resume_str  \\\n",
      "651    652  April Twilling 123 Fake Street, City, State, Z...   \n",
      "652    653  Mark Gordon 123 Fake Street, City, State, Zip ...   \n",
      "809    810  Susan Courtney 123 Fake Street, City, State, Z...   \n",
      "815    816  Sarah Fowler 123 Fake Street, City, State, Zip...   \n",
      "834    835  Joe Morali 123 Fake Street, City, State, Zip C...   \n",
      "842    843  Brian Westfield 123 Fake Street, City, State, ...   \n",
      "912    913  April Twilling 123 Fake Street, City, State, Z...   \n",
      "913    914  Mark Gordon 123 Fake Street, City, State, Zip ...   \n",
      "1381  1382  Susan Courtney 123 Fake Street, City, State, Z...   \n",
      "1387  1388  Sarah Fowler 123 Fake Street, City, State, Zip...   \n",
      "1468  1469  Joe Morali 123 Fake Street, City, State, Zip C...   \n",
      "1504  1505  Brian Westfield 123 Fake Street, City, State, ...   \n",
      "\n",
      "                       Category  \n",
      "651     Office & Administrative  \n",
      "652     Office & Administrative  \n",
      "809                     Medical  \n",
      "815                     Medical  \n",
      "834                  Production  \n",
      "842   Retail & Customer Service  \n",
      "912     Office & Administrative  \n",
      "913     Office & Administrative  \n",
      "1381                    Medical  \n",
      "1387                    Medical  \n",
      "1468                 Production  \n",
      "1504  Retail & Customer Service  \n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra các bản ghi trùng lặp trong cột 'resume_str'\n",
    "duplicates = df[df.duplicated(subset=['resume_str'], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Các bản ghi trùng lặp trong cột 'resume_str':\")\n",
    "    print(duplicates[['ID', 'resume_str', 'Category']])\n",
    "else:\n",
    "    print(\"Không tìm thấy bản ghi trùng lặp trong cột 'resume_str'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loại bỏ các bản ghi trùng lặp, giữ lại bản ghi đầu tiên\n",
    "df_unique = df.drop_duplicates(subset=['resume_str'], keep='first')\n",
    "\n",
    "# Sắp xếp lại cột ID theo thứ tự tăng dần, bắt đầu từ 1\n",
    "df_unique = df_unique.reset_index(drop=True)\n",
    "df_unique['ID'] = df_unique.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số bản ghi sau khi loại bỏ trùng lặp: 1688\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra số lượng bản ghi sau khi loại bỏ trùng lặp\n",
    "print(f\"Tổng số bản ghi sau khi loại bỏ trùng lặp: {len(df_unique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Một số dòng đầu tiên của kết quả:\n",
      "   ID                                         resume_str              Category\n",
      "0   1  Gerard Levine\\nCertified Public Accountant\\n+1...  Accounting & Finance\n",
      "1   2  Brian Watkins\\nAccounting Assistant\\nbrian.wat...  Accounting & Finance\n",
      "2   3  Roman Arkell Accounting Clerk (781) 984-9624 r...  Accounting & Finance\n",
      "3   4  Lukas Summers\\nlukas.summers@mail.us\\n(646) 62...  Accounting & Finance\n",
      "4   5  Moe Money\\nAccounts Payable Specialist\\n555-69...  Accounting & Finance\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị một số dòng đầu tiên của kết quả để kiểm tra\n",
    "print(\"\\nMột số dòng đầu tiên của kết quả:\")\n",
    "print(df_unique[['ID', 'resume_str', 'Category']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả đã được lưu vào file: D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/FinalGopData3LinksDone.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Lưu kết quả vào file mới\n",
    "output_file = 'D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/FinalGopData3LinksDone.xlsx'\n",
    "df_unique.to_excel(output_file, index=False)\n",
    "print(f\"Kết quả đã được lưu vào file: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged successfully! The merged file is saved as 'MergedDataset.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two datasets\n",
    "first_dataset = pd.read_excel('D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/job_descriptions.xlsx')  # Replace with the actual path to your first dataset\n",
    "second_dataset = pd.read_excel('D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/GopData/FinalGopData3LinksDone.xlsx')\n",
    "\n",
    "# Merge the datasets by concatenating them\n",
    "merged_dataset = pd.concat([first_dataset, second_dataset], ignore_index=True)\n",
    "\n",
    "# Reset the IDs starting from 1\n",
    "merged_dataset['ID'] = range(1, len(merged_dataset) + 1)\n",
    "\n",
    "# Reorder columns to ensure ID is first\n",
    "merged_dataset = merged_dataset[['ID', 'Resume_str', 'Resume_html', 'Category']]\n",
    "\n",
    "# Save the merged dataset to a new Excel file\n",
    "merged_dataset.to_excel('D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/DataFinal/GeneralCV_Example.xlsx', index=False)\n",
    "\n",
    "print(\"Datasets merged successfully! The merged file is saved as 'MergedDataset.xlsx'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
