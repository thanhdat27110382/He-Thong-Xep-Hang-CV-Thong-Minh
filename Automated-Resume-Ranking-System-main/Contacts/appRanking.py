import os
import joblib
import re
import pandas as pd
from flask import Flask, request, render_template, jsonify
from PyPDF2 import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from nltk.corpus import stopwords
import nltk

# T·∫£i stopwords
nltk.download('stopwords')
stop_words_en = set(stopwords.words('english'))
# Gi·∫£ l·∫≠p stopwords ti·∫øng Vi·ªát n·∫øu kh√¥ng c√≥ file vietnamese.txt
stop_words_vi = set(stopwords.words('vietnamese.txt'))

app = Flask(__name__)

# ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(BASE_DIR, 'model', 'resume_ranking_model.pkl')
UPLOAD_DIR = os.path.join(BASE_DIR, 'uploads')
OUTPUT_PATH = os.path.join(BASE_DIR, '..', 'csvfiles', 'ketquaxephang', 'resume_ranking_results.xlsx')

# T·∫£i m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
try:
    model = joblib.load(MODEL_PATH)
    print(f"ƒê√£ t·∫£i m√¥ h√¨nh t·ª´ {MODEL_PATH}")
except FileNotFoundError:
    print(f"L·ªói: T·ªáp {MODEL_PATH} kh√¥ng t·ªìn t·∫°i.")
    model = None

# ƒê·∫£m b·∫£o th∆∞ m·ª•c uploads t·ªìn t·∫°i
if not os.path.exists(UPLOAD_DIR):
    os.makedirs(UPLOAD_DIR)

def clean_text(text):
    """L√†m s·∫°ch vƒÉn b·∫£n."""
    if not isinstance(text, str):
        text = str(text)
    text = text.lower()
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    words = text.split()
    text = ' '.join(word for word in words if word not in stop_words_en and word not in stop_words_vi)
    return text

def extract_text_from_resume(resume_path):
    """Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ PDF resume."""
    text = ""
    try:
        with open(resume_path, "rb") as file:
            reader = PdfReader(file)
            for page in reader.pages:
                text += page.extract_text() + "\n"
    except Exception as e:
        print(f"L·ªói khi tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ {resume_path}: {e}")
    return clean_text(text.strip())

def calculate_cosine_similarity(resume_text, job_description):
    """T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine."""
    tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
    texts = [job_description, resume_text]
    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)
    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
    score = similarity * 100  # Chu·∫©n h√≥a th√†nh thang 100
    return round(score, 2)

def get_ai_suggestion(score):
    """Tr·∫£ v·ªÅ g·ª£i √Ω AI d·ª±a tr√™n ƒëi·ªÉm s·ªë."""
    if score > 80:
        return "üî• Excellent match! Your resume is well-optimized."
    elif score > 60:
        return "‚úÖ Good match! Consider adding more relevant keywords."
    else:
        return "‚ö° Low match! Try improving your skills section and adding industry-specific terms."

@app.route('/')
def index():
    return render_template('indexRanking.html', results=None, top_match=None)

@app.route('/upload', methods=['POST'])
def upload():
    if 'resumes' not in request.files or 'job_description' not in request.form:
        return jsonify({"error": "Vui l√≤ng cung c·∫•p √≠t nh·∫•t m·ªôt resume v√† m√¥ t·∫£ c√¥ng vi·ªác."}), 400

    resume_files = request.files.getlist('resumes')
    job_description = clean_text(request.form['job_description'])

    if not resume_files or not job_description:
        return jsonify({"error": "Resume ho·∫∑c m√¥ t·∫£ c√¥ng vi·ªác kh√¥ng h·ª£p l·ªá."}), 400

    # Ki·ªÉm tra t·ªïng k√≠ch th∆∞·ªõc v√† ƒë·ªãnh d·∫°ng
    total_size = 0
    max_size = 200 * 1024 * 1024  # 200MB
    results = []

    for resume_file in resume_files:
        if resume_file.filename == '':
            continue
        if not resume_file.filename.endswith('.pdf'):
            return jsonify({"error": f"File {resume_file.filename} kh√¥ng ph·∫£i PDF."}), 400
        total_size += len(resume_file.read())
        resume_file.seek(0)  # Reset con tr·ªè file
        if total_size > max_size:
            return jsonify({"error": "T·ªïng k√≠ch th∆∞·ªõc file v∆∞·ª£t qu√° 200MB."}), 400

        # L∆∞u resume
        resume_path = os.path.join(UPLOAD_DIR, resume_file.filename)
        resume_file.save(resume_path)

        # Tr√≠ch xu·∫•t v√† l√†m s·∫°ch vƒÉn b·∫£n
        resume_text = extract_text_from_resume(resume_path)
        if not resume_text:
            return jsonify({"error": f"Kh√¥ng th·ªÉ tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ {resume_file.filename}."}), 400

        # T√≠nh ƒëi·ªÉm cosine similarity
        score = calculate_cosine_similarity(resume_text, job_description)

        # L∆∞u k·∫øt qu·∫£
        results.append({
            'resume_file': resume_file.filename,
            'score': score,
            'ai_suggestion': get_ai_suggestion(score)
        })

    # S·∫Øp x·∫øp theo ƒëi·ªÉm s·ªë gi·∫£m d·∫ßn
    results = sorted(results, key=lambda x: x['score'], reverse=True)

    # L∆∞u v√†o Excel
    result_df = pd.DataFrame(results)
    if os.path.exists(OUTPUT_PATH):
        try:
            existing_df = pd.read_excel(OUTPUT_PATH)
            result_df = pd.concat([existing_df, result_df], ignore_index=True)
        except Exception as e:
            print(f"L·ªói khi ƒë·ªçc file Excel hi·ªán c√≥: {e}")
    result_df.to_excel(OUTPUT_PATH, index=False)

    # X√°c ƒë·ªãnh top match
    top_match = results[0]['resume_file'] if results else None

    return render_template('indexRanking.html', results=results, top_match=top_match)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)