{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e4d74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import re\n",
    "from openpyxl import Workbook\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, WebDriverException\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08422067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Install selenium-stealth if needed (uncomment to use)\n",
    "# pip install selenium-stealth\n",
    "try:\n",
    "    from selenium_stealth import stealth\n",
    "except ImportError:\n",
    "    stealth = None\n",
    "    print(\"Warning: selenium-stealth not installed. Some anti-bot measures may still block the script.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62cc17fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input Excel file\n",
    "df = pd.read_excel(\"D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/cvgeniusITlink.xlsx\")\n",
    "\n",
    "# Initialize list to store all results\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb277a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text: remove newlines, extra spaces, and special characters\n",
    "def clean_text(text):\n",
    "    # Remove newlines, tabs, and special characters\n",
    "    text = re.sub(r'[\\n\\r\\t]+', ' ', text)\n",
    "    # Remove non-breaking spaces and other special characters\n",
    "    text = re.sub(r'\\xa0', ' ', text)\n",
    "    # Collapse multiple spaces into a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Strip leading/trailing spaces\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53be8aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set up WebDriver with anti-bot measures\n",
    "def setup_driver(max_retries=2):\n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            chrome_options = Options()\n",
    "            # Use real browser (non-headless mode) with visibility\n",
    "            chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\")\n",
    "            chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "            chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "            chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "            chrome_options.add_argument(\"--disable-gpu\")\n",
    "            chrome_options.add_argument(\"--no-sandbox\")\n",
    "            chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "            chrome_options.add_argument(\"--disable-extensions\")\n",
    "            chrome_options.add_argument(\"--disable-infobars\")\n",
    "            \n",
    "            # Set up the driver with the latest ChromeDriver version\n",
    "            driver = webdriver.Chrome(\n",
    "                service=Service(ChromeDriverManager().install()),\n",
    "                options=chrome_options\n",
    "            )\n",
    "            \n",
    "            # Apply stealth settings if available\n",
    "            if stealth:\n",
    "                stealth(driver,\n",
    "                        languages=[\"en-US\", \"en\"],\n",
    "                        vendor=\"Google Inc.\",\n",
    "                        platform=\"Win32\",\n",
    "                        webgl_vendor=\"Intel Inc.\",\n",
    "                        renderer=\"Intel Iris OpenGL Engine\",\n",
    "                        fix_hairline=True,\n",
    "                )\n",
    "            \n",
    "            print(f\"Info: WebDriver initialized successfully on attempt {attempt + 1}\")\n",
    "            return driver\n",
    "        \n",
    "        except WebDriverException as e:\n",
    "            print(f\"Error initializing WebDriver on attempt {attempt + 1}: {str(e)}\")\n",
    "            if attempt == max_retries:\n",
    "                raise Exception(f\"Failed to initialize WebDriver after {max_retries + 1} attempts: {str(e)}\")\n",
    "            time.sleep(2)  # Wait before retrying\n",
    "\n",
    "# Function to handle pop-ups (e.g., cookie banners)\n",
    "def handle_popups(driver, url):\n",
    "    try:\n",
    "        # Look for common cookie banner buttons\n",
    "        accept_button = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept') or contains(text(), 'Agree') or contains(text(), 'OK')]\"))\n",
    "        )\n",
    "        accept_button.click()\n",
    "        print(f\"Info: Closed cookie banner for {url}\")\n",
    "        time.sleep(1)  # Wait for the banner to close\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(f\"Info: No cookie banner found for {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error closing pop-up for {url}: {str(e)}\")\n",
    "\n",
    "# Function to crawl resume content from the specified structure\n",
    "def crawl_resume_content(url, category, max_retries=1):\n",
    "    for attempt in range(max_retries + 1):\n",
    "        driver = None\n",
    "        try:\n",
    "            # Set up WebDriver\n",
    "            driver = setup_driver(max_retries=2)\n",
    "            \n",
    "            # Navigate to the URL\n",
    "            driver.get(url)\n",
    "            print(f\"Info: Successfully loaded {url} on attempt {attempt + 1}\")\n",
    "            \n",
    "            # Wait for the main wrapper to load (timeout set to 20 seconds)\n",
    "            try:\n",
    "                accordion_item = WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"accordion-item.accordion-item-static\"))\n",
    "                )\n",
    "                print(f\"Info: Accordion item detected for {url}\")\n",
    "            except TimeoutException:\n",
    "                # Check for CAPTCHA or anti-bot page\n",
    "                try:\n",
    "                    captcha = driver.find_element(By.XPATH, \"//*[contains(text(), 'CAPTCHA') or contains(text(), 'verify') or contains(text(), 'robot')]\")\n",
    "                    print(f\"Warning: CAPTCHA detected for {url}. Please solve the CAPTCHA manually in the browser window.\")\n",
    "                    time.sleep(30)  # Pause to allow manual CAPTCHA solving\n",
    "                    # Re-check for content after CAPTCHA solving\n",
    "                    accordion_item = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CLASS_NAME, \"accordion-item.accordion-item-static\"))\n",
    "                    )\n",
    "                    print(f\"Info: Accordion item detected after CAPTCHA solving for {url}\")\n",
    "                except (NoSuchElementException, TimeoutException):\n",
    "                    print(f\"Error: Timeout waiting for accordion item for {url} after {attempt + 1} attempts.\")\n",
    "                    if attempt == max_retries:\n",
    "                        driver.quit()\n",
    "                        return []\n",
    "                    continue\n",
    "            \n",
    "            # Handle pop-ups (e.g., cookie banners)\n",
    "            handle_popups(driver, url)\n",
    "            \n",
    "            # Navigate to <div class=\"entry-content\">\n",
    "            try:\n",
    "                entry_content = accordion_item.find_element(By.CLASS_NAME, \"entry-content\")\n",
    "            except NoSuchElementException:\n",
    "                print(f\"Error: Could not find 'entry-content' for {url}.\")\n",
    "                driver.quit()\n",
    "                return []\n",
    "            \n",
    "            # Navigate to <div class=\"copy-div\">\n",
    "            try:\n",
    "                copy_div = entry_content.find_element(By.CLASS_NAME, \"copy-div\")\n",
    "            except NoSuchElementException:\n",
    "                print(f\"Error: Could not find 'copy-div' for {url}.\")\n",
    "                driver.quit()\n",
    "                return []\n",
    "            \n",
    "            # Initialize list to store resume content\n",
    "            resume_content = []\n",
    "            \n",
    "            # Find all direct children that are <p> or <ul> tags\n",
    "            elements = copy_div.find_elements(By.XPATH, \"./*[self::p or self::ul]\")\n",
    "            \n",
    "            for element in elements:\n",
    "                tag_name = element.tag_name\n",
    "                \n",
    "                # Extract <p> (includes content from child tags like <strong>, <em>)\n",
    "                if tag_name == \"p\":\n",
    "                    text = clean_text(element.text)\n",
    "                    if text:\n",
    "                        resume_content.append(text)\n",
    "                \n",
    "                # Extract from <ul> (includes <li> and their child content)\n",
    "                elif tag_name == \"ul\":\n",
    "                    try:\n",
    "                        li_items = element.find_elements(By.TAG_NAME, \"li\")\n",
    "                        for li in li_items:\n",
    "                            text = clean_text(li.text)\n",
    "                            if text:\n",
    "                                resume_content.append(text)\n",
    "                    except NoSuchElementException:\n",
    "                        pass\n",
    "            \n",
    "            # Join all content with a single space\n",
    "            full_content = \" \".join(resume_content)\n",
    "            \n",
    "            # Since CVGenius seems to have only one CV per page, return a single entry\n",
    "            driver.quit()\n",
    "            if full_content:\n",
    "                return [{\"Category\": category, \"Resume\": full_content}]\n",
    "            return []\n",
    "        \n",
    "        except WebDriverException as e:\n",
    "            print(f\"Error on attempt {attempt + 1} for {url}: {str(e)}\")\n",
    "            if attempt == max_retries:\n",
    "                print(f\"Error: Failed to crawl {url} after {max_retries + 1} attempts.\")\n",
    "                if driver:\n",
    "                    driver.quit()\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error on attempt {attempt + 1} for {url}: {str(e)}\")\n",
    "            if attempt == max_retries:\n",
    "                print(f\"Error: Failed to crawl {url} after {max_retries + 1} attempts.\")\n",
    "                if driver:\n",
    "                    driver.quit()\n",
    "                return []\n",
    "        finally:\n",
    "            if driver:\n",
    "                try:\n",
    "                    driver.quit()\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "# Function to process a single row (for parallel execution)\n",
    "def process_row(row):\n",
    "    category = row[\"Category\"]\n",
    "    url = row[\"Resume_link\"]\n",
    "    print(f\"Crawling resume for {category}...\")\n",
    "    resume_contents = crawl_resume_content(url, category, max_retries=1)\n",
    "    return resume_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac653cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling resume for Computer science...\n",
      "Crawling resume for Cyber security...\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/cyber-security-cv on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/computer-science-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/cyber-security-cv\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/computer-science-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/cyber-security-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/computer-science-cv\n",
      "Crawling resume for Data analyst...\n",
      "Crawling resume for Data engineer ...\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/data-analyst-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/data-analyst-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/data-analyst-cv\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/data-engineer-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/data-engineer-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/data-engineer-cv\n",
      "Crawling resume for Data science...\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/data-science-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/data-science-cv\n",
      "Crawling resume for DevOps...\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/data-science-cv\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/devops-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/devops-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/devops-cv\n",
      "Crawling resume for Front-end developer ...\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/front-end-developer-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/front-end-developer-cv\n",
      "Crawling resume for Google...\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/front-end-developer-cv\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/google-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/google-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/google-cv\n",
      "Crawling resume for IT support...\n",
      "Crawling resume for Manual tester...\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/manual-tester-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/manual-tester-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/manual-tester-cv\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/it-support-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/it-support-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/it-support-cv\n",
      "Crawling resume for Programmer...\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/programmer-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/programmer-cv\n",
      "Crawling resume for Network engineer...\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/programmer-cv\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/network-engineer-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/network-engineer-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/network-engineer-cv\n",
      "Crawling resume for Software developer...\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/software-developer-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/software-developer-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/software-developer-cv\n",
      "Crawling resume for Software engineer ...\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/software-engineer-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/software-engineer-cv\n",
      "Crawling resume for Solutions architect...\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/software-engineer-cv\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/solutions-architect-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/solutions-architect-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/solutions-architect-cv\n",
      "Crawling resume for Technical...\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/technical-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/technical-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/technical-cv\n",
      "Crawling resume for Web developer...\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/web-developer-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/web-developer-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/web-developer-cv\n",
      "Crawling resume for Web designer...\n",
      "Info: WebDriver initialized successfully on attempt 1\n",
      "Info: Successfully loaded https://cvgenius.com/cv-examples/web-designer-cv on attempt 1\n",
      "Info: Accordion item detected for https://cvgenius.com/cv-examples/web-designer-cv\n",
      "Info: No cookie banner found for https://cvgenius.com/cv-examples/web-designer-cv\n"
     ]
    }
   ],
   "source": [
    "# Use ThreadPoolExecutor for parallel crawling (2 workers for stability)\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    # Submit all tasks\n",
    "    future_to_row = {executor.submit(process_row, row): row for _, row in df.iterrows()}\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    for future in as_completed(future_to_row):\n",
    "        results = future.result()\n",
    "        all_results.extend(results)\n",
    "        # Small delay to avoid overwhelming the server\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d356c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the results\n",
    "result_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Ensure the DataFrame has the correct columns in the right order\n",
    "result_df = result_df[[\"Category\", \"Resume\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aacc9790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cyber security</td>\n",
       "      <td>PERSONAL STATEMENT Diligent and technically as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computer science</td>\n",
       "      <td>PROFESSIONAL SUMMARY Analytical and solution-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data analyst</td>\n",
       "      <td>PERSONAL STATEMENT Innovative and process-orie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data engineer</td>\n",
       "      <td>PERSONAL STATEMENT Data engineer with 4 years ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data science</td>\n",
       "      <td>PERSONAL STATEMENT Google and IBM certified Da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Category                                             Resume\n",
       "0    Cyber security  PERSONAL STATEMENT Diligent and technically as...\n",
       "1  Computer science  PROFESSIONAL SUMMARY Analytical and solution-o...\n",
       "2      Data analyst  PERSONAL STATEMENT Innovative and process-orie...\n",
       "3    Data engineer   PERSONAL STATEMENT Data engineer with 4 years ...\n",
       "4      Data science  PERSONAL STATEMENT Google and IBM certified Da..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c39e602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling complete. Results saved to Crawled_Resumes.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save to Excel\n",
    "result_df.to_excel(\"D:/BaiDoAnChuyenNganh3/Automated-Resume-Ranking-System-main/csvfiles/crawlcv/NewITData/finalcvgeniusITlink.xlsx\", index=False)\n",
    "print(\"Crawling complete. Results saved to Crawled_Resumes.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
